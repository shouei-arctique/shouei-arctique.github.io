<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>哈希刷题：242，349，1，454</title>
      <link href="/2024/09/20/lc/hash/"/>
      <url>/2024/09/20/lc/hash/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="理论基础">理论基础</h1><p>用Python的defaultdic来构建类似于map的哈希表。需要注意的是对每个key生成dict时value默认是零。</p><h1 id="题目">题目</h1><h2 id="p242">P242</h2><p>给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s的字母异位词。</p><p>示例 1: 输入: s = "anagram", t = "nagaram" 输出: true</p><p>示例 2: 输入: s = "rat", t = "car" 输出: false</p><p>说明: 你可以假设字符串只包含小写字母。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isAnagram</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        cnt=<span class="number">0</span></span><br><span class="line">        <span class="built_in">dict</span>=defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="built_in">dict</span>[<span class="built_in">ord</span>(s[i])]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(t)):</span><br><span class="line">            <span class="built_in">dict</span>[<span class="built_in">ord</span>(t[i])]-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">dict</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">dict</span>[x] !=<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cnt+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> cnt==<span class="built_in">len</span>(<span class="built_in">dict</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>python通过ord()转换字符为ascll码</p><h2 id="p349">P349</h2><p>给定两个数组 nums1 和 nums2 ，返回 它们的交集。输出结果中的每个元素一定是 唯一 的。我们可以不考虑输出结果的顺序。</p><p>示例 1：</p><p>输入：nums1 = [1,2,2,1], nums2 = [2,2] 输出：[2] 示例 2：</p><p>输入：nums1 = [4,9,5], nums2 = [9,4,9,8,4] 输出：[9,4] 解释：[4,9]也是可通过的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">intersection</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        ls=[]</span><br><span class="line">        <span class="built_in">dict</span>=defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        set1=<span class="built_in">set</span>(nums1)</span><br><span class="line">        set2=<span class="built_in">set</span>(nums2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> set1:</span><br><span class="line">            <span class="built_in">dict</span>[x]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> set2:</span><br><span class="line">            <span class="built_in">dict</span>[x]-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">dict</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">dict</span>[x]==<span class="number">0</span>:</span><br><span class="line">                ls.append(x)</span><br><span class="line">        <span class="keyword">return</span> ls</span><br></pre></td></tr></table></figure><h2 id="p1">P1</h2><p>给定一个整数数组 nums 和一个目标值target，请你在该数组中找出和为目标值的那 两个整数，并返回他们的数组下标。</p><p>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。</p><p>示例:</p><p>给定 nums = [2, 7, 11, 15], target = 9</p><p>因为 nums[0] + nums[1] = 2 + 7 = 9</p><p>所以返回 [0, 1]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="type">List</span>=[]</span><br><span class="line">        <span class="built_in">dict</span>=defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">dict</span>[target-nums[i]] !=<span class="number">0</span>:</span><br><span class="line">                <span class="type">List</span>.append(i)</span><br><span class="line">                <span class="type">List</span>.append(<span class="built_in">dict</span>[target-nums[i]])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> i !=<span class="number">0</span> <span class="keyword">and</span> nums[i]+nums[<span class="number">0</span>]==target:</span><br><span class="line">                    <span class="type">List</span>.append(i)</span><br><span class="line">                    <span class="type">List</span>.append(<span class="built_in">dict</span>[target - nums[i]])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="built_in">dict</span>[nums[i]]=i</span><br><span class="line">        <span class="type">List</span>.sort()</span><br><span class="line">        <span class="keyword">return</span> <span class="type">List</span></span><br></pre></td></tr></table></figure><h2 id="p454">P454</h2><p>给你四个整数数组 nums1、nums2、nums3 和 nums4 ，数组长度都是 n，请你计算有多少个元组 (i, j, k, l) 能满足：</p><p>0 &lt;= i, j, k, l &lt; n nums1[i] + nums2[j] + nums3[k] + nums4[l]== 0</p><p>示例 1：</p><p>输入：nums1 = [1,2], nums2 = [-2,-1], nums3 = [-1,2], nums4 = [0,2]输出：2 解释： 两个元组如下： 1. (0, 0, 0, 1) -&gt; nums1[0] + nums2[0]+ nums3[0] + nums4[1] = 1 + (-2) + (-1) + 2 = 0 2. (1, 1, 0, 0) -&gt;nums1[1] + nums2[1] + nums3[0] + nums4[0] = 2 + (-1) + (-1) + 0 = 0 示例2：</p><p>输入：nums1 = [0], nums2 = [0], nums3 = [0], nums4 = [0] 输出：1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">intersection</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        ls=[]</span><br><span class="line">        <span class="built_in">dict</span>=defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        set1=<span class="built_in">set</span>(nums1)</span><br><span class="line">        set2=<span class="built_in">set</span>(nums2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> set1:</span><br><span class="line">            <span class="built_in">dict</span>[x]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> set2:</span><br><span class="line">            <span class="built_in">dict</span>[x]-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">dict</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">dict</span>[x]==<span class="number">0</span>:</span><br><span class="line">                ls.append(x)</span><br><span class="line">        <span class="keyword">return</span> ls</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> Leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>药剂学PPT</title>
      <link href="/2024/09/11/dose/"/>
      <url>/2024/09/11/dose/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>https://pan.baidu.com/s/1YY3_AMfc5ygk2kmSr4urIg?pwd=xray</p>]]></content>
      
      
      <categories>
          
          <category> 製薬のConcerto </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 药剂学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>形式主义的发端-蒙太奇理论</title>
      <link href="/2024/09/11/articles/film2/"/>
      <url>/2024/09/11/articles/film2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="爱森斯坦-蒙太奇理论">爱森斯坦 蒙太奇理论</h1><p>爱森斯坦转行从事艺术时，碰上所谓的结构主义，<strong>从一开始他便认定艺术活动是一种“制造”，或一种建造</strong>。因此在他的理论中，素材的问题就显得至关重要。</p><p>结构主义者从多方面反对写实主义，主张将戏剧的诸多元素抽离出来，依照导演的意图进行再创作。</p><h2 id="灵感源泉">灵感源泉</h2><ul><li><p>歌舞伎夸张、非写实，单看情节或表演无法理解歌舞伎的意义，它的意义包括在作为整体的形式里。</p><p>剧中的一切元素，必须组合起来才能产生意义，就像<strong>灯光，配乐，表演，剧情，甚至字幕都必须相互关联，像是建筑才来哦，最终它们各自的意义包含在座位整体的形式里。</strong></p></li><li><p>俳句 简单意象排列，有吸引力地碰撞。</p><p>强调元素的对位。包括声音————他认为只有音画不同步才能激发思考。</p></li><li><p>皮亚杰研究2-7岁儿童心理学 1）自我中心</p><p>爱森斯坦将观影体验看做一种自我中心的活动。</p><p>2）初级符号感知</p><p>2-7岁的孩子会充分使用象征或符号功能。</p><p>3）蒙太奇思维</p><p>儿童只根据最终状态来判定事物的性质，不考虑过程。爱森斯坦在很多方面假定了对最终状态的关系，反对长镜头。</p><p>4）内在语言</p><p>他发现艺术能通过提供直接经验或交流从而超越后天的逻辑思维方式，创造出最有诗意的效果。</p></li></ul><h2 id="修辞or艺术">修辞or艺术？</h2><p>修辞学是语言和传播的学说，是对演说的目的、方法和效果的研究，可以理解为：为了影响或启蒙的目的，一方对另一方进行的理念灌输。</p><p>伟大的影片不是在为主题造句，而是通过艺术的自主性影响给观众，即是用“蒙太奇”的并置使观众积极地产生联想。</p>]]></content>
      
      
      <categories>
          
          <category> 杂文のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>形式主义的发端-视知觉与心理</title>
      <link href="/2024/09/10/articles/film1/"/>
      <url>/2024/09/10/articles/film1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="导入参考书介绍">导入/参考书介绍</h1><p>达德利·安德鲁《经典电影理论导论》（修订版）后浪出版公司，2018.12。</p><p>大卫·波德维尔《世界电影史》（第二版）北京大学出版社，2014.2。</p><p>罗伯特·斯塔姆《电影理论解读》北京大学出版社，2017.7</p><h2 id="本书的研究方法">本书的研究方法</h2><ul><li>素材：电影的基本素材是什么？</li><li>方法和技巧：什么方法能使这些素材变成有意义的作品，使素材得以超越本身的存在？</li><li>形式和外观：这种超越所能形成的最有意义的形式是什么？</li><li>目的和价值：这个过程对我们的生活有什么价值？</li></ul><h1 id="明斯特伯格爱因汉姆-视知觉与心理">明斯特伯格&amp;爱因汉姆视知觉与心理</h1><p>一开始电影是用来纪实。如何让电影成为艺术？————发现电影与众不同的地方：- 必须把电影从其表达的内容中解放出来 - 抨击银幕写实主义 -拒绝内容对电影的影响，他们 不是原封不动的拍摄。</p><p>明斯特伯格：似动现象，认为电影形成的运动幻想是大脑主动将刺激转化为运动的。把人类的心智作为拍摄者创作的素材(唯心)————即认为电影拍的是什么不重要，重要的是其在人的心中是怎么产生的。</p><p>爱因汉姆：只有当媒介从所有不必要的外部因素中净化出来以后，才能发现自身最有力的特性。<strong>电影的素材便是那些使它不能完美再现现实的因素。</strong></p><p>所以吸引我们的并不是再现的物体，而是艺术家的组织能力。</p><p>当观众看到或找到与大脑的活动相契合的电影或理解方式时，心灵就和外部世界连接在一起了。</p>]]></content>
      
      
      <categories>
          
          <category> 杂文のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基因组学-发展史</title>
      <link href="/2024/09/10/bioinfo/gnmcs1/"/>
      <url>/2024/09/10/bioinfo/gnmcs1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>参考资料：</p><p>https://ngdc.cncb.ac.cn/education/courses/genomics/</p><p>【基因组学 - 中国科学院大学2024】https://www.bilibili.com/video/BV1KE421g7kT?vd_source=1a36db16e3fec3ccbe040303ff015aab</p><h1 id="基因组学发展史">基因组学发展史</h1><h2 id="第一章-基因组学发展史">第一章: 基因组学发展史</h2><h3 id="基本概念">1. 基本概念</h3><ul><li><strong>基因</strong>:核苷酸序列，编码蛋白或RNA产物。是遗传信息的物质基础，控制生物体的性状和功能。</li><li><strong>基因组</strong>:生物体所有遗传物质的总和，包含所有编码和非编码的DNA序列。<ul><li><strong>核基因组</strong>:存在于细胞核中，主要负责生物体大多数功能。</li><li><strong>线粒体基因组</strong>和<strong>叶绿体基因组</strong>:负责细胞能量代谢及光合作用。</li></ul></li><li><strong>基因组学</strong>:以生物体全部基因为研究对象，研究基因组的结构、功能、演化、组装、编辑等方面的学科。目标是系统解析所有基因的功能及其相互作用，揭示基因调控生物发育及演化的规律。</li><li><strong>基因组学和遗传学的区分</strong>：基因组学是全基因组水平，遗传学是单个基因水平；基因组学是研究基因相互作用关系及其环境影响，遗传学是研究基因从父代到子代的遗传机制；基因组学是研究多基因导致的复杂疾病，基因组学是研究单基因遗传及其性质。</li></ul><h3 id="人类基因组计划-human-genome-project-hgp">2. 人类基因组计划(Human Genome Project, HGP)</h3><h4 id="背景与启动">2.1 背景与启动</h4><ul><li><strong>提出背景</strong>:人类基因组计划（HGP）是20世纪末最具影响力的国际科学合作项目之一。1985年提出，1990年正式启动。项目旨在确定人类基因组中所有的基因序列，揭示人类基因的功能及其对健康和疾病的影响。</li><li><strong>合作国家</strong>:美国、英国、法国、德国、日本和中国。中国负责其中1%的任务，具体是测定人类3号染色体短臂上的30Mb区域。</li></ul><h4 id="hgp的目标">2.2 HGP的目标</h4><ul><li><strong>总体目标</strong>:在15年内（1990-2005年）完成人类基因组的测序，包含24条染色体的30亿个核苷酸序列分析。</li><li><strong>主要任务</strong>:<ul><li>测定所有基因的序列，绘制基因图谱。</li><li>分析序列的功能，揭示基因与疾病的关联。</li><li>完成其他模式生物（大肠杆菌、酵母、线虫、果蝇和小鼠）的基因组测序，为人类基因组研究提供参照。</li></ul></li></ul><h4 id="重大里程碑">2.3 重大里程碑</h4><ul><li><strong>1985年</strong>:提出HGP的设想，探讨测定人类全基因组序列的可能性。</li><li><strong>1990年</strong>:人类基因组计划正式启动，资金投入预计达30亿美元。</li><li><strong>1999年</strong>:中国加入计划，负责测定3号染色体短臂上的基因组区域。</li><li><strong>2000年6月26日</strong>:美国总统克林顿宣布人类基因组的“工作框架图”绘制完成。这标志着全球基因组测序工作进入尾声，覆盖了基因组的90%以上。</li><li><strong>2001年</strong>:科学家在《Nature》和《Science》期刊上分别发表了人类基因组草图。</li><li><strong>2003年</strong>:人类基因组计划提前两年完成，生成了“完成图”，覆盖了人类基因组的99%以上。</li></ul><h4 id="技术突破">2.4 技术突破</h4><ul><li><strong>DNA测序技术</strong>:<ul><li>桑格法（Sangersequencing）是早期DNA测序的基础技术，为人类基因组测序奠定了基础。</li><li>吴瑞（RayWu）等科学家发展了早期的测序方法，为解决DNA序列解析问题做出了重要贡献。</li></ul></li></ul><h4 id="数据共享原则">2.5 数据共享原则</h4><ul><li><strong>1997年</strong>: HGP制定了“百慕大原则”（BermudaPrinciples），要求测序数据在生成后24小时内公开。这一原则确保了基因组数据迅速应用于研究和医疗领域。</li></ul><h4 id="hgp的科学与社会影响">2.6 HGP的科学与社会影响</h4><ul><li><strong>科学影响</strong>:<ul><li><strong>解码生命的本质</strong>:通过基因组序列，揭示了人类遗传信息的结构及功能，为理解生命现象（如生长、发育、疾病和衰老等）提供了全新的视角。</li><li><strong>推动学科发展</strong>:基因组学的快速发展，推动了与其相关的多个新兴学科如生物信息学、分子医学和精准医学。</li><li><strong>模式生物的测序</strong>:除了人类基因组，HGP还测序了多种模式生物（如大肠杆菌、酵母、线虫、果蝇、小鼠），这些数据为生命科学研究提供了重要的比较分析基础。</li></ul></li><li><strong>社会与经济影响</strong>:<ul><li><strong>医疗创新</strong>:基因组数据被广泛应用于疾病诊断、药物研发和基因疗法。精准医学的兴起，使得基于个体基因信息的个性化医疗成为现实。</li><li><strong>经济效益</strong>:研究显示，从1988年到2010年间，HGP为美国带来了7960亿美元的经济回报。每1美元的联邦投资，带来了141美元的经济回报。</li></ul></li></ul><h4 id="持续的影响">2.7 持续的影响</h4><ul><li><strong>后基因组时代</strong>:随着HGP的完成，基因组学进入了“后基因组时代”。科学家不仅着眼于解码基因序列，更注重基因组功能的理解、基因调控网络的研究以及复杂疾病的遗传机制。</li><li><strong>1000 Genome Project</strong>:2008年启动，目标是研究全球不同人群的遗传变异，为个性化医疗提供数据支持。</li><li><strong>单倍型图计划</strong>:2003年启动，致力于绘制人类基因组的单倍型图谱，帮助揭示基因变异与疾病的关系。</li></ul><h3 id="基因与基因组的历史">3. 基因与基因组的历史</h3><ul><li><strong>1831-1859年</strong>:查尔斯·达尔文通过《物种起源》奠定了生物进化论的基础。</li><li><strong>孟德尔遗传定律</strong>:孟德尔通过豌豆杂交实验，提出了遗传因子（基因）的概念，建立了遗传学的基础。</li><li><strong>基因的发现</strong>: 丹麦遗传学家威廉·约翰逊（WilhelmJohannsen）在1909年提出“基因”一词，用以描述遗传的基本单位。</li><li><strong>摩尔根的贡献</strong>: 美国生物学家托马斯·摩尔根（ThomasHuntMorgan）通过果蝇实验，描绘了基因在染色体上的位置图，奠定了现代遗传学的基础。</li></ul><h3 id="dna的发现与结构">4. DNA的发现与结构</h3><ul><li><strong>1953年</strong>: 詹姆斯·沃森（JamesWatson）和弗朗西斯·克里克（FrancisCrick）提出了DNA的双螺旋结构模型。</li><li><strong>DNA结构的影响</strong>:DNA双螺旋结构揭示了基因如何通过复制和传递进行遗传信息的传递，为后续的分子生物学研究铺平了道路。</li></ul><h3 id="基因组学的兴起">5. 基因组学的兴起</h3><ul><li><strong>1986年</strong>: 美国遗传学家托马斯·罗德里克（ThomasRoderick）首次提出“基因组学”一词，标志着该学科的正式诞生。</li><li><strong>基因组学与遗传学的区别</strong>:<ul><li><strong>基因组学</strong>:研究整个基因组的结构、功能、演化及其相互作用，探索复杂疾病的遗传机制。</li><li><strong>遗传学</strong>:更注重单个基因的功能、从父代到子代的遗传机制以及单基因遗传疾病。</li></ul></li></ul><h3 id="中国在基因组学中的贡献">6. 中国在基因组学中的贡献</h3><ul><li><strong>1999年</strong>:中国正式加入人类基因组计划，负责测定人类基因组1%的序列。</li><li><strong>华大基因</strong>:1999年成立的北京华大基因中心在基因组学研究中占据重要地位。2003年中国科学院北京基因组研究所的成立也标志着国内基因组学研究进入了新的阶段。</li></ul><h3 id="总结">7. 总结</h3><ul><li><strong>基因</strong>:是产生蛋白或RNA的核苷酸序列，是遗传信息的基本单位。</li><li><strong>基因组</strong>:包含了生物体所有的遗传物质，是控制生物发育和功能的核心。</li><li><strong>基因组学</strong>:伴随人类基因组计划的开展而兴起，推动了生命科学的革命性进展，已成为21世纪生命科学研究的核心领域之一。</li><li><strong>HGP的影响</strong>:人类基因组计划不仅促进了基因组学的快速发展，还推动了精准医学、药物开发、生物信息学等多个相关领域，对全球社会和经济产生了深远影响。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 生信のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物信息学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣-1331</title>
      <link href="/2024/09/02/lc/leetcode_1331/"/>
      <url>/2024/09/02/lc/leetcode_1331/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>给你一个整数数组 arr，请你将数组中的每个元素替换为它们排序后的序号。</p><p>序号代表了一个元素有多大。序号编号的规则如下：</p><p>序号从 1 开始编号。一个元素越大，那么序号越大。如果两个元素相等，那么它们的序号相同。每个数字的序号都应该尽可能地小。</p><p>示例 1：</p><p>输入：arr = [40,10,20,30] 输出：[4,1,2,3] 解释：40 是最大的元素。 10是最小的元素。 20 是第二小的数字。 30 是第三小的数字。 示例 2：</p><p>输入：arr = [100,100,100] 输出：[1,1,1] 解释：所有元素有相同的序号。示例 3：</p><p>输入：arr = [37,12,28,9,100,56,80,5,12] 输出：[5,3,4,2,8,6,7,1,3]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">arrayRankTransform</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        n=<span class="number">1</span></span><br><span class="line">        new_ls=[]</span><br><span class="line">        <span class="built_in">dict</span>=defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        ls=<span class="built_in">list</span>(<span class="built_in">set</span>(arr))</span><br><span class="line">        ls.sort()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> ls:</span><br><span class="line">            <span class="built_in">dict</span>[i]=n</span><br><span class="line">            n+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> arr:</span><br><span class="line">            new_ls.append(<span class="built_in">dict</span>[x])</span><br><span class="line">        <span class="keyword">return</span> new_ls</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> 力扣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣-56</title>
      <link href="/2024/09/02/lc/leetcode_56/"/>
      <url>/2024/09/02/lc/leetcode_56/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] =[starti, endi] 。请你合并所有重叠的区间，并返回一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。</p><p>示例 1：</p><p>输入：intervals = [[1,3],[2,6],[8,10],[15,18]]输出：[[1,6],[8,10],[15,18]] 解释：区间 [1,3] 和 [2,6] 重叠,将它们合并为 [1,6]. 示例 2：</p><p>输入：intervals = [[1,4],[4,5]] 输出：[[1,5]] 解释：区间 [1,4] 和[4,5] 可被视为重叠区间。</p><p>合并区间练习 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">merge</span>(<span class="params">self, intervals: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        intervals.sort()</span><br><span class="line">        res=[intervals[<span class="number">0</span>]]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(intervals)):</span><br><span class="line">            ed=<span class="built_in">len</span>(res)-<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> intervals[i][<span class="number">0</span>]&lt;=res[ed][<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">if</span> res[ed][<span class="number">1</span>]&lt;=intervals[i][<span class="number">1</span>]:</span><br><span class="line">                    res[ed][<span class="number">1</span>]=intervals[i][<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.append(intervals[i])</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 力扣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>偏微分方程数学建模</title>
      <link href="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/"/>
      <url>/2024/09/02/%E6%95%B0%E6%A8%A1/pde/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="引言">引言</h2><p>实际问题 - 确定性问题：1）连续问题 2）离散问题 - 随机性问题</p><p>对于连续问题，可以用常微分方程模型也可以用偏微分方程模型</p><h2 id="偏微分方程模型">偏微分方程模型</h2><p>常见的模型</p><ul><li>1）热传导方程</li></ul><p>研究热量，温度的变化情况</p><p>也可以描述分子扩散的情况</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/1.png"></p><ul><li>2）波动方程</li></ul><p>橡皮筋的波动</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/2.png"></p><ul><li>3）调和方程</li></ul><p>温度不随时间变化而变化</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/3.png"></p><p>Poisson 方程</p><p>引入热源</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/4.png"></p><h3 id="偏微分方程的类型">偏微分方程的类型</h3><ul><li>热传导方程——抛物线方程</li><li>波动方程——双曲线方程</li><li>调和方程——椭圆形方程</li></ul><h3 id="模型的建立微元法">模型的建立——微元法</h3><p>时间微元：[t,t + delta t]</p><p>空间微元：w=[x,x+ delta x] × [y,y+ delta y] × [z,z+ delta z]</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/5.png"></p><h4 id="fourier热传导定律">Fourier热传导定律</h4><p>在时间微元dt内沿面积微元dS的法线方向n流过此面积微元的热量为：</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/6.png"></p><p>梯度即表示与两边温度差成正比</p><p>k为热传导系数</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/7.png"></p><p>统一空间和时间积分：</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/8.png"></p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/9.png"> 面积分变体积分</p><h4 id="热量守恒定律">热量守恒定律</h4><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/10.png"></p><h4 id="定解条件">定解条件</h4><p>初始条件：t=0；u=phi(x,y,z)</p><h5 id="边界条件">边界条件</h5><ul><li>Dirichlet 边界条件(第一类边界条件)</li></ul><p>u(t,x)=myu，myu为边界上的温度</p><ul><li>Neumann边界条件(第二类)</li></ul><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/11.png"></p><ul><li>Robin边界条件(第三类)</li></ul><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/12.png"></p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/13.png"></p><p>理论上来说，给了一种边界条件，那么存在解是唯一的，其他两条边界条件不能随便给。</p><h2 id="数值计算">数值计算</h2><p>偏微分方程的数值计算方法：</p><ul><li>有限差分法</li><li>有限元素法</li></ul><p><strong>有限差分法</strong>就是用差商代替导数，从而将微分方程转换为代数方程组的一种数值计算方法。</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/14.png"></p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/15.png"></p><p>偏微分二阶差商：</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/16.png"></p><p>举例：</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/17.png"> <img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/18.png"> <img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/19.png"> 表示该点的温度</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/20.png">为了知道n+1，我们需要知道n；为了知道n，我们需要知道n—1,从而推到初值。</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/21.png"> <em>显式差分格式</em></p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/22.png"></p><p>利用边界条件 <img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/23.png"> 再利用显式差分格式</p><p>条件稳定： <img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/24.png"></p><p>如果不想受条件稳定限制： <img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/25.png">这时，我们不知道n时刻的温度，所以有3个未知量，不能用显式差分</p><p>我们for(i=1;i＜n;i++)得到n-1个方程，n+1个变量</p><p>所以，我们选择增加方程来求解，即边界条件的方程。</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/26.png"></p><h2 id="线性方程组求解">线性方程组求解</h2><h3 id="高斯消去">高斯消去</h3><h3 id="lu分解">LU分解</h3><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/27.png"></p><p>计算量： - 分解过程O(n^3) - 回代过程O(n^2)</p><h3 id="追赶法">追赶法</h3><p>三对角线性方程组</p><p>O(n)</p><h2 id="赛题">赛题</h2><p>2018A</p><p><img src="/2024/09/02/%E6%95%B0%E6%A8%A1/pde/28.png"></p><!-- ## 摘要作为一种小型的海上浮体，近海海洋浮标相较于大型海上浮式结构更容易受到复杂海洋环境的影响而发生破坏，因此近海海洋浮标标体结构设计研究是当前海洋浮标整体设计中的关键问题也是难点之一。————*先叙述背景，然后此段话引出本文攻克的难点及其意义*- **首先对近海小型海洋浮标标体结构进行概念选型设计**。查阅国内外相关的文献以及先进的研发技术，针对我国近海海域特点，总结出海上小型海洋浮标标体结构设计基本方法，提出一种适用于近海小型海洋浮标标体基本结构设计的分析方法及流程；针对目前近海小型海洋浮标标体结构多样化的特点，基于已有的国内外先进浮标设计型式，从**运动响应**入手，通过仿真分析不同型式标体结构的运动响应，确定适合的标体结构型式- **对选定的近海小型海洋浮标标体结构进行基本设计**。小型海洋浮标标体结构较为紧凑，因此内部搭载仪器的位置分布尤为重要，文章从浮标运动性能入手，定性分析该型海洋浮标布置方案（主要考虑标体吃水深度、重心位置、惯性矩等）对浮标运动性能的影响，确定该型浮标搭载设备布置的设计方案和设计准则；针对近海海域水深较浅以及水深变化较大的特点，对选定的近海小型海洋浮标标体结构进行水深影响分析，确定浮标基本设计中水深对于浮标运动性能的影响；综合上文分析，从而确定浮标标体结构基本设计中布置方案等参数设计的依据- **对选定的近海小型海洋浮标标体结构进行优化设计**。基于搭载设备运行所需求环境条件以及浮标的运动安全性，提出基于 TMD 减振原理的改善浮标横摇运动设计方案以及基于垂荡板的改善浮标垂荡运动的设计方案，并对两种设计方案效果进行校核；并基于上述减摇设计，针对浮标离岸较远，长时间的离岸监测对电力供给要求较高这一问题，提出一种的适用于小型海洋浮标的新型倒钟摆型减摇发电装置## 海洋浮标标体的水动力性能分析理论与方法由于浮标的运动响应主要是由于受到外界环境荷载（主要是波浪荷载）的影响，为了更好地研究标体基本参数对标体运动性能的影响，因此在本文中，在分析浮标标体结构运动性能的基础上，将着重针对标体在波浪环境下水动力参数进行进一步较为详细的分析。对于任何空间中运动的物体而言，其运动可以通过六个正交的方向向量表示。对于海洋浮标而言，其在空间中运动可以从位置与姿态进行描述，其中位置是用来描述海洋浮标在海洋环境中所处的地理位置，包括纵荡、横荡、垂荡三个自由度，其中 x’表示纵荡、y’表示横荡、z’表示垂荡；姿态是用来描述海洋浮标在海洋环境中所呈现的样子，如倾斜、旋转等，包括纵摇、横摇、首摇三个自由度，其姿态可以用坐标系三个坐标轴两两夹角的余弦值组成的姿态矩阵描述，其中 a1 表示纵摇、a2 表示横摇、a3 表示首摇。### 浮标的固有周期根据船舶耐波性理论，浮体自由横摇的近似固有频率为浮标垂荡固有频率计算公式如下通过分析浮标固有周期的计算公式可知，影响浮标横摇和垂荡运动固有周期的主要参数包括转动惯量、排水量、横稳心高以及载重水线面积等，而这些参数的确定通常是通过浮标结构的重量，搭载仪器的重量以及布置来确定的### 水面浮体的稳定性如果海浪正处于浮标中拱状态，gm将会继续降低，甚至成为负值，将危及浮标的安全； gm 值越大，即初稳性越高，浮标抵抗风浪等环境荷载轻浮的能力越强。如果浮标初稳性过大，浮标的回复力矩将显著增大，此时会造成浮标摇摆频率增大，使得浮标在遇到恶劣环境时发生强烈地运动，摇摆幅度大幅增加，降低浮标的运动性能，同时浮标剧烈的运动容易造成搭载仪器的损坏，降低浮标运行的平顺性及操作性能### 三维势流理论### 频域及时域分析计算理论频域分析是对浮体的运动方程进行简写分析或者 Fourier 变换。频域分析忽视了非线性效应，得到线性化的结果。根据牛顿定律，考虑附加质量、阻尼力以及波浪激励力的作用，得到平台的频域运动方程：## 近海小型海洋浮标平台基本参数的设计与分析根据上述近海小型海洋浮标结构设计的基本思路，在海洋浮标标体形式概念设计（标体型式设计）过程中，首先针对目前常见的浮标形式进行对比，通过分析不同型式浮标标体外形对于水动力性能及运动性能的影响，针对浮标这种小型海洋浮体容易受到环境因素的影响横摇而发生倾覆以及波浪等水文信息对于浮标垂荡要求高这两个关注点，采用势流理论分析垂荡及横摇这两者自由度运动响应所对应的频率与波浪谱能量集中频带对应频率相比较，进而定性化的完成浮标标体外形的选型工作；其次分析标体结构中影响布置方案的基本参数（吃水深度、重心位置、惯性矩等）通过上述分析方法，定性化的完成浮标内部搭载仪器的布置。 -->]]></content>
      
      
      <categories>
          
          <category> 数模のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>背景知识-文艺复兴</title>
      <link href="/2024/08/31/tofel/6/"/>
      <url>/2024/08/31/tofel/6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="内容">内容</h2><p>忍者神龟的角色来自文艺复兴。</p><p>文艺复兴是艺术的全盛时期(efflorescence)，主要是视觉系，还有一些文学，重新发掘与罗马和希腊文明相近的观点。</p><p>文艺复兴注重人体，这种古典在建筑上也有体现。文艺复兴还重现了希腊和罗马的写作，以及他们的思想。研究、翻译、注释他们的文字的学者，被称为人道主义者，但这些学者不关注宗教，于是人们以为文艺复兴时期的作家、艺术家暗地里不信宗教——但事实上他们信教，如他们一遍遍刻画的圣母。</p><p>文艺复兴遍布欧洲，但我们主要关注下意大利。是什么促成了意大利的文艺复兴？是钱。意大利有钱是因为两个原因：1）许多城市都是小型工业中心；2）威尼斯和热那亚因为贸易。他们曾经还和奥斯曼做贸易——给意大利带来巨额利益。</p><p>还有一个非欧洲人支持文艺复兴的例子：威尼斯人向奥斯兰出口纺织品。纺织品在佛罗伦萨很好，因为他们用矾（alum）染色是的色泽保持鲜亮，但矾主要在奥斯曼帝国的小亚细亚地区。所以意大利需要奥斯曼的矾，直到托儿法发现了矾，教皇知道后，把独家开矿权，授予给佛罗伦萨的一家，medicis家族，尽管这没切断贸易。</p><p>和伊斯兰的接触还带来最后一个帮助欧洲文艺复兴的方法：许多文艺复兴时期的学者研究的文献都来自穆斯林国家。穆斯林学者一直学习古希腊，特别是托勒密和亚里士多德；穆斯林也影响哥白尼。哥白尼的思想并不是独立的，他收到过伊斯兰的数学论文影响。</p><p>事实上文艺复兴并没有发生。当时的欧洲人并不会意识到自己在亲历文艺复兴历史，它的艺术文学思潮只影响到很少一部分人。文艺复兴的时间跨度很大，几百年间有许多相互独立的事情。</p><h2 id="单词">单词</h2><p>crusade 十字军</p><p>rediscovery 再现</p><p>stinking rich (口语，贬义)特有钱</p><p>arms 武器</p><p>ore 矿石</p><p>lend itself to=be suitable for</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 托福 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Binary Classification with a Bank Churn</title>
      <link href="/2024/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/dnn/"/>
      <url>/2024/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/dnn/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="intro">Intro</h2><p>数据集来自Kaggle的https://www.kaggle.com/competitions/binary-classification-with-a-bank-churn-test/data</p><p>旨在练习DNN的书写</p><p><em>GPT辅助生成注释</em></p><h2 id="code">code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, TensorDataset</span><br><span class="line">​</span><br><span class="line"></span><br><span class="line">/kaggle/<span class="built_in">input</span>/playground-series-s4e1/train.csv</span><br><span class="line">data=pd.read_csv(<span class="string">&#x27;/kaggle/input/playground-series-s4e1/train.csv&#x27;</span>)</span><br><span class="line">data=data.drop([<span class="string">&quot;id&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">data=data.drop([<span class="string">&quot;CustomerId&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">data=data.drop([<span class="string">&quot;Surname&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">​</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">data.iloc[:,<span class="number">1</span>] = LabelEncoder().fit_transform(data.iloc[:,<span class="number">1</span>])</span><br><span class="line">​</span><br><span class="line">data.iloc[:,<span class="number">2</span>] = LabelEncoder().fit_transform(data.iloc[:,<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 假设 data 是已经加载的 DataFrame</span></span><br><span class="line">data.iloc[:, <span class="number">1</span>] = LabelEncoder().fit_transform(data.iloc[:, <span class="number">1</span>])</span><br><span class="line">data.iloc[:, <span class="number">2</span>] = LabelEncoder().fit_transform(data.iloc[:, <span class="number">2</span>])</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 转换数据类型</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> data.columns:</span><br><span class="line">    data[col] = pd.to_numeric(data[col], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line">​</span><br><span class="line"><span class="comment"># 处理缺失值</span></span><br><span class="line">data = data.fillna(<span class="number">0</span>)  <span class="comment"># 或使用 data = data.dropna()</span></span><br><span class="line"><span class="comment"># 创建训练数据</span></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(torch.tensor(data.iloc[:, :-<span class="number">1</span>].values, dtype=torch.float32),torch.tensor(data.iloc[:, -<span class="number">1</span>].values, dtype=torch.float32),test_size=<span class="number">0.3</span>)</span><br><span class="line">​</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Tensor 数据集和数据加载器</span></span><br><span class="line">dataset = TensorDataset(x_train, y_train)</span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">​</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(DNN, self).__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">10</span>, <span class="number">32</span>), nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">32</span>, <span class="number">16</span>), nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">16</span>, <span class="number">8</span>), nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">8</span>, <span class="number">4</span>), nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">4</span>, <span class="number">1</span>),  <span class="comment"># 移除 ReLU</span></span><br><span class="line">            nn.Sigmoid()  <span class="comment"># 添加 Sigmoid 激活</span></span><br><span class="line">        )</span><br><span class="line">​</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br><span class="line">​</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型、损失函数和优化器</span></span><br><span class="line">model = DNN()</span><br><span class="line">loss_fn = nn.BCELoss()  <span class="comment"># 使用二元交叉熵损失</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)  <span class="comment"># 尝试适当的学习率</span></span><br><span class="line">​</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">epochs = <span class="number">20</span></span><br><span class="line">losses = []</span><br><span class="line">add Codeadd Markdown</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;now is epoch:&#x27;</span>, epoch)</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line">    total_predictions = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader:</span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清除梯度</span></span><br><span class="line">        Pred = model(batch_x)  <span class="comment"># 前向传播</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将预测值转换为 0 或 1</span></span><br><span class="line">        Pred_binary = (Pred &gt; <span class="number">0.5</span>).<span class="built_in">float</span>()  <span class="comment"># 使用 Sigmoid 输出的概率进行分类</span></span><br><span class="line">        correct_predictions += (Pred_binary == batch_y).<span class="built_in">sum</span>().item()</span><br><span class="line">        total_predictions += batch_y.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        loss = loss_fn(Pred.view(-<span class="number">1</span>), batch_y)  <span class="comment"># 将 Pred 形状调整为 [batch_size]</span></span><br><span class="line">        epoch_loss += loss.item()  <span class="comment"># 累加损失</span></span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line"></span><br><span class="line">    accuracy = correct_predictions / total_predictions * <span class="number">100</span>  <span class="comment"># 计算准确率</span></span><br><span class="line">    losses.append(epoch_loss / <span class="built_in">len</span>(train_loader))  <span class="comment"># 记录每个epoch的平均损失</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Loss: <span class="subst">&#123;epoch_loss / <span class="built_in">len</span>(train_loader):<span class="number">.4</span>f&#125;</span>, Accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)  <span class="comment"># 打印损失和准确率</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;now is epoch:&#x27;</span>, epoch)</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line">    total_predictions = <span class="number">0</span></span><br><span class="line">​</span><br><span class="line">    <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader:</span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清除梯度</span></span><br><span class="line">        Pred = model(batch_x)  <span class="comment"># 前向传播</span></span><br><span class="line">​</span><br><span class="line">        <span class="comment"># 将预测值转换为 0 或 1</span></span><br><span class="line">        Pred_binary = (Pred &gt; <span class="number">0.5</span>).<span class="built_in">float</span>()  <span class="comment"># 使用 Sigmoid 输出的概率进行分类</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算正确预测的数量</span></span><br><span class="line">        correct_predictions += (Pred_binary.view(-<span class="number">1</span>) == batch_y.view(-<span class="number">1</span>)).<span class="built_in">sum</span>().item()  <span class="comment"># 扁平化比较</span></span><br><span class="line">        total_predictions += batch_y.size(<span class="number">0</span>)</span><br><span class="line">​</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = loss_fn(Pred.view(-<span class="number">1</span>), batch_y)  <span class="comment"># 确保形状匹配</span></span><br><span class="line">        epoch_loss += loss.item()  <span class="comment"># 累加损失</span></span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line">​</span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    accuracy = correct_predictions / total_predictions * <span class="number">100</span>  <span class="comment"># 计算准确率</span></span><br><span class="line">    losses.append(epoch_loss / <span class="built_in">len</span>(train_loader))  <span class="comment"># 记录每个 epoch 的平均损失</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Loss: <span class="subst">&#123;epoch_loss / <span class="built_in">len</span>(train_loader):<span class="number">.4</span>f&#125;</span>, Accuracy: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)  <span class="comment"># 打印损失和准确率</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在测试集上测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">with torch.no_grad():</span><br><span class="line">    pred = model(x_test)  # 进行预测</span><br><span class="line">    pred_binary = (pred &gt; 0.5).float()  # 大于 0.5 设为 1，其他设为 0</span><br><span class="line">​</span><br><span class="line">    # 计算正确预测的数量</span><br><span class="line">    correct = torch.sum(pred_binary.view(-1) == y_test.view(-1))  # 扁平化比较</span><br><span class="line">    total = y_test.size(0)</span><br><span class="line">    </span><br><span class="line">    print(f&#x27;测试集准确度：&#123;100 * correct / total:.2f&#125;%&#x27;)</span><br><span class="line">测试集准确度：78.50%</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> Kaggle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理和特征工程</title>
      <link href="/2024/08/28/data_feature/"/>
      <url>/2024/08/28/data_feature/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="intro">intro</h2><p>一般包自带的数据都是经过筛选，预测效果好，没有缺失等问题。</p><h3 id="数据挖掘的五大流程">数据挖掘的五大流程：</h3><ul><li>获取数据</li><li>数据预处理：让数据适应模型，匹配模型的需求。</li><li>特征工程：将原始数据转换为更能代表预测模型的潜在问题的特征的过程，可以通过挑选最相关的特征，提取特征以及创造特征来实现。其中创造特征又经常以降维算法的方式实现。</li></ul><p>可能面对的问题：特征之间有相关性，特征和标签无关，特征太多或太小，或者干脆就无法表现出应有的数据现象或无法展示数据的真实面貌。</p><p>### sklearn中的数据预处理和特征工程</p><ul><li>模块preprocessing：几乎包含数据预处理的所有内容模块</li><li>模块Impute：填补缺失值专用</li><li>模块feature_selection：包含特征选择的各种方法的实践</li><li>模块decomposition：包含降维算法</li></ul><h2 id="数据预处理">数据预处理</h2><h3 id="数据无量纲化">数据无量纲化</h3><ul><li>梯度和矩阵为核心的算法中(逻辑回归，支持向量机，神经网络)，无量纲化可以加快求解速度；</li><li>距离类模型(K近邻，K-Means聚类)无量纲化可以提升模型精度</li></ul><p>无量纲化包括线性和非线性。</p><p>线性无量纲化包括中心化处理和缩放处理。</p><h4 id="归一化normalization">归一化Normalization</h4><p>归一化服从正态分布。</p><p>在sklearn中，使用preprocessing.MinMaxScaler来实现这个功能。参数feature_range控制目标压缩范围，默认[0,1]</p><h4 id="标准化standardization">标准化Standardization</h4><p>preprocessing.StandardScaler</p><p>对于StandardScaler和MinMaxScaler来说，空值NaN会被当做是缺失值，在fit的时候忽略，在transform的时候保持缺失NaN的状态显示。</p><p>一般选择StandardScaler来进行缩放，MinMaxScaler对异常值敏感。</p><h3 id="代码">代码</h3><h4 id="minmaxscaler">MinMaxScaler</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">data = [[-<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">0.5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">10</span>], [<span class="number">1</span>, <span class="number">18</span>]]</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.DataFrame(data)</span><br><span class="line"><span class="comment">#实现归一化</span></span><br><span class="line">scaler = MinMaxScaler() <span class="comment">#实例化</span></span><br><span class="line">scaler = scaler.fit(data) <span class="comment">#fit，在这里本质是生成min(x)和max(x)</span></span><br><span class="line">result = scaler.transform(data) <span class="comment">#通过接口导出结果result</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">result_ = scaler.fit_transform(data) <span class="comment">#训练和导出结果一步达成</span></span><br><span class="line">scaler.inverse_transform(result) <span class="comment">#将归一化后的结果逆转</span></span><br><span class="line"><span class="comment">#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = [[-<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">0.5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">10</span>], [<span class="number">1</span>, <span class="number">18</span>]]</span><br><span class="line">scaler = MinMaxScaler(feature_range=[<span class="number">5</span>,<span class="number">10</span>]) <span class="comment">#依然实例化</span></span><br><span class="line">result = scaler.fit_transform(data) <span class="comment">#fit_transform一步导出结果result</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="standardscaler">StandardScaler</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">data = [[-<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">0.5</span>, <span class="number">6</span>], [<span class="number">0</span>, <span class="number">10</span>], [<span class="number">1</span>, <span class="number">18</span>]]</span><br><span class="line">scaler = StandardScaler() <span class="comment">#实例化</span></span><br><span class="line">scaler.fit(data) <span class="comment">#fit，本质是生成均值和方差</span></span><br><span class="line">scaler.mean_ <span class="comment">#查看均值的属性mean_</span></span><br><span class="line">scaler.var_ <span class="comment">#查看方差的属性var_</span></span><br><span class="line">x_std = scaler.transform(data) <span class="comment">#通过接口导出结果</span></span><br><span class="line">x_std.mean() <span class="comment">#导出的结果是一个数组，用mean()查看均值</span></span><br><span class="line">x_std.std() <span class="comment">#用std()查看方差</span></span><br><span class="line">scaler.fit_transform(data) <span class="comment">#使用fit_transform(data)一步达成结果</span></span><br><span class="line">scaler.inverse_transform(x_std) <span class="comment">#使用inverse_transform逆转标准化</span></span><br></pre></td></tr></table></figure><h3 id="缺失值">缺失值</h3><p><img src="/2024/08/28/data_feature/data_feature\1.png"></p><p>以泰坦尼克号数据为例：一个数值型，两个字符型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">r&quot;D:\Sklearn\Narrativedata.csv&quot;</span>,index_col=<span class="number">0</span>)<span class="comment">#第一列作为索引不作为数据</span></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">data.info()</span><br><span class="line"><span class="comment">#填补年龄</span></span><br><span class="line">Age = data.loc[:,<span class="string">&quot;Age&quot;</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>) <span class="comment">#sklearn当中特征矩阵必须是二维</span></span><br><span class="line">Age[:<span class="number">20</span>]</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line">imp_mean = SimpleImputer() <span class="comment">#实例化，默认均值填补</span></span><br><span class="line">imp_median = SimpleImputer(strategy=<span class="string">&quot;median&quot;</span>) <span class="comment">#用中位数填补</span></span><br><span class="line">imp_0 = SimpleImputer(strategy=<span class="string">&quot;constant&quot;</span>,fill_value=<span class="number">0</span>) <span class="comment">#用0填补</span></span><br><span class="line">imp_mean = imp_mean.fit_transform(Age) <span class="comment">#fit_transform一步完成调取结果</span></span><br><span class="line">imp_median = imp_median.fit_transform(Age)</span><br><span class="line">imp_0 = imp_0.fit_transform(Age)</span><br><span class="line">imp_mean[:<span class="number">20</span>]</span><br><span class="line">imp_median[:<span class="number">20</span>]</span><br><span class="line">imp_0[:<span class="number">20</span>]</span><br><span class="line"><span class="comment">#在这里我们使用中位数填补Age</span></span><br><span class="line">data.loc[:,<span class="string">&quot;Age&quot;</span>] = imp_median</span><br><span class="line">data.info()</span><br><span class="line"><span class="comment">#使用众数填补Embarked</span></span><br><span class="line">Embarked = data.loc[:,<span class="string">&quot;Embarked&quot;</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">imp_mode=SimpleImputer(strategy=<span class="string">&quot;most_frequent&quot;</span>)</span><br><span class="line">data.loc[:,<span class="string">&quot;Embarked&quot;</span>]=imp_mode.fit_transform(Embarked)</span><br><span class="line">data.info()</span><br></pre></td></tr></table></figure><h3 id="处理分类型特征编码与哑变量">处理分类型特征：编码与哑变量</h3><p>sklearn中必须导入数值型</p><p>文字型转化为数值型</p><h4 id="preprocessing">preprocessing</h4><ul><li>preprocessing.LabelEncoder：标签专用，能够将分类转换为分类数值</li><li>preprocessing.OrdinalEncoder：特征专用，能够将分类特征转换为分类数值</li><li>preprocessing.OneHotEncoder：独热编码，创建哑变量</li></ul><p>不同性质的分类数据： - 取值互相独立 - 有序变量：例如大学、高中、小学- 有距变量：可计算</p><p>OrdinalEncoder用来处理有序变量，对于名义变量，要使用独热编码</p><p><img src="/2024/08/28/data_feature/data_feature\2.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">y = data.iloc[:,-<span class="number">1</span>] <span class="comment">#要输入的是标签，不是特征矩阵，所以允许一维</span></span><br><span class="line">le = LabelEncoder() <span class="comment">#实例化</span></span><br><span class="line">le = le.fit(y) <span class="comment">#导入数据</span></span><br><span class="line">label = le.transform(y)   <span class="comment">#transform接口调取结果</span></span><br><span class="line">le.classes_ <span class="comment">#属性.classes_查看标签中究竟有多少类别</span></span><br><span class="line">label <span class="comment">#查看获取的结果label</span></span><br><span class="line">le.fit_transform(y) <span class="comment">#也可以直接fit_transform一步到位</span></span><br><span class="line">le.inverse_transform(label) <span class="comment">#使用inverse_transform可以逆转</span></span><br><span class="line">data.iloc[:,-<span class="number">1</span>] = label <span class="comment">#让标签等于我们运行出来的结果</span></span><br><span class="line">data.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OrdinalEncoder</span><br><span class="line"><span class="comment">#接口categories_对应LabelEncoder的接口classes_，一模一样的功能</span></span><br><span class="line">data_ = data.copy()</span><br><span class="line">data_.head()</span><br><span class="line">OrdinalEncoder().fit(data_.iloc[:,<span class="number">1</span>:-<span class="number">1</span>]).categories_</span><br><span class="line">data_.iloc[:,<span class="number">1</span>:-<span class="number">1</span>] = OrdinalEncoder().fit_transform(data_.iloc[:,<span class="number">1</span>:-<span class="number">1</span>])</span><br><span class="line">data_.head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">data.head()</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line">X = data.iloc[:,<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">enc = OneHotEncoder(categories=<span class="string">&#x27;auto&#x27;</span>).fit(X)</span><br><span class="line">result = enc.transform(X).toarray()</span><br><span class="line">result</span><br><span class="line"> </span><br><span class="line">OneHotEncoder(categories=<span class="string">&#x27;auto&#x27;</span>).fit_transform(X).toarray()</span><br><span class="line"> </span><br><span class="line">pd.DataFrame(enc.inverse_transform(result))</span><br><span class="line">enc.get_feature_names()</span><br><span class="line">result</span><br><span class="line">result.shape</span><br><span class="line"><span class="comment">#axis=1,表示跨行进行合并，也就是将量表左右相连，如果是axis=0，就是将量表上下相连</span></span><br><span class="line">newdata = pd.concat([data,pd.DataFrame(result)],axis=<span class="number">1</span>)</span><br><span class="line">newdata.head()</span><br><span class="line">newdata.drop([<span class="string">&quot;Sex&quot;</span>,<span class="string">&quot;Embarked&quot;</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">newdata.columns = </span><br><span class="line">[<span class="string">&quot;Age&quot;</span>,<span class="string">&quot;Survived&quot;</span>,<span class="string">&quot;Female&quot;</span>,<span class="string">&quot;Male&quot;</span>,<span class="string">&quot;Embarked_C&quot;</span>,<span class="string">&quot;Embarked_Q&quot;</span>,<span class="string">&quot;Embarked_S&quot;</span>]</span><br><span class="line">newdata.head()</span><br></pre></td></tr></table></figure><h3 id="处理连续型特征二值化与分段">处理连续型特征：二值化与分段</h3><h4 id="preprocessing.binarizer">preprocessing.Binarizer</h4><p>二值化是对文本计数数据的常见操作，分析人员可以决定仅考虑某种现象的存在与否。它还可以用作考虑布尔随机变量的估计器的预处理步骤(eg.使用贝叶斯设置中的伯努利分布建模)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将年龄二值化</span></span><br><span class="line">data_2 = data.copy()</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line">X = data_2.iloc[:,<span class="number">0</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>) <span class="comment">#类为特征专用，所以不能使用一维数组</span></span><br><span class="line">transformer = Binarizer(threshold=<span class="number">30</span>).fit_transform(X)</span><br><span class="line">transformer</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>背景知识-恐龙灭绝</title>
      <link href="/2024/08/28/tofel/5/"/>
      <url>/2024/08/28/tofel/5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="内容">内容</h2><p>恐龙灭绝远比我们想象中复杂。</p><p>首先讲述为什么我们确定小行星撞击(asteroidimpact)是恐龙灭绝的主要原因。6600万年前小行星撞击墨西哥湾。白垩纪(恐龙统治时期)，哺乳动物崛起(古近纪)，造成这一过渡的历史事件叫做白垩纪-第三纪灭绝事件——K-Pg。</p><p>我们不清楚K-Pg产生的具体原因。但我们可以确信：1）气候变化，土壤化学等证据表明气温下降了；有经验的人可以识别出分割开这个事件前后的岩层——白垩纪-古近纪界限。2）突然中出现大量铱（小行星天体上大量存在）.3）灭绝，许多生物从化石记录中消失。</p><p>小行星撞击可以解释上面的现象。切入点是铱：意大利的阿尔瓦雷兹发现铱含量很高。根据含量他们推断出撞击来自于约10km宽的巨型金属类岩石。人们很快发现了其他证据：冲击石英——在K-Pg地带晶体结构重组但这不会出现在地球上。玻陨石——岩石击飞在空中又掉下融化过程中形成。</p><p>但人们找不到理应大小的坑(crater)。1994年他们在墨西哥尤卡坦半岛的沿岸找到了巨坑，还有6600万年前产生的巨大岩石断层。</p><p>有科学家认为恐龙的灭绝很早就开始了，小行星只是收尾。撞击发生在地球历史上最严重的火山活跃时期，火山爆发在卡坦撞击之前，这对气候造成严重影响。还有一些化石表明撞击之前，温度曾极度下降，恐龙一方面不能像哺乳动物一样适应气温变化，另一方面恐龙竞争食物。同时，板块移动，裂谷下降至地幔，海平面也下降，形成"海退"——海岸变平原，湖泊变沙漠，改变海洋深度和温度，形成缺氧死地。</p><p>希克苏鲁伯撞击是压死骆驼的最后一根稻草。</p><h2 id="单词">单词</h2><p>iridium 铱</p><p>magnitude 范围、大小</p><p>core-mantle-crust</p><p>Cretaceous 白垩纪</p><p>Paleogene 早第三纪，古近纪</p><p>careen 横冲直撞</p><p>envision 想象</p><p>game changer 改变形势的产品(或事件)</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 托福 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>矩阵分析-线性空间</title>
      <link href="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/"/>
      <url>/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="线性空间的基维数向量">线性空间的基、维数、向量</h2><p>在V中，若存在n个元素<span class="math inline">\(\alpha_{1}\)</span><span class="math inline">\(,\alpha_{2}……\alpha_{n}\)</span>满足 - <span class="math inline">\(\alpha_{1}\)</span> <span class="math inline">\(,\alpha_{2}……\alpha_{n}\)</span>线性无关 -V中任意<span class="math inline">\(\alpha\)</span>可由<span class="math inline">\(\alpha_{1}\)</span> <span class="math inline">\(,\alpha_{2}……\alpha_{n}\)</span>表示 则<span class="math inline">\(\alpha_{1}\)</span> <span class="math inline">\(,\alpha_{2}……\alpha_{n}\)</span>为V的一个基，n为V的维数。记dimV=n</p><p><span class="math inline">\(\alpha\)</span>=<span class="math inline">\(\alpha_{1}x_1\)</span> <span class="math inline">\(,\alpha_{2}x_2……\alpha_{n}x_3\)</span></p><p>即<span class="math display">\[\alpha=(\alpha_{1},\alpha_{2}……\alpha_{n})\begin{pmatrix}x1 \\x2 \\x3\end{pmatrix}\]</span></p><p>例题： <img src="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/linearspace\1.jpg"></p><h2 id="线性空间的基变换与坐标变换">线性空间的基变换与坐标变换</h2><p>基变换：(<span class="math inline">\(\alpha_{1}\)</span> <span class="math inline">\(,\alpha_{2}……\alpha_{n}\)</span>)→过度矩阵P→<span class="math inline">\(\beta_{1}\)</span> <span class="math inline">\(,\beta_{2}……\beta_{n}\)</span></p><p>基变换公式：B=AP</p><p>坐标变换公式：<span class="math inline">\(Y\)</span>=<span class="math inline">\(P^{-1}X\)</span>。<span class="math inline">\(X\)</span>为原基底下的坐标。</p><p>例题：</p><p><img src="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/linearspace\2.jpg"></p><h2 id="简单基的应用">简单基的应用</h2><p><strong>简单基可将矩阵和多项式转化为向量</strong></p><p>例如<span class="math inline">\(R^{2*2}\)</span>的简单基为：</p><p><span class="math display">\[E_1=\left[\begin{array}{c}1 &amp; 0 \\0 &amp; 0\end{array}\right],E_2=\left[\begin{array}{c}0 &amp; 1 \\0 &amp; 0\end{array}\right],E_3=\left[\begin{array}{c}0 &amp; 0 \\1 &amp; 0\end{array}\right],E_4=\left[\begin{array}{c}0 &amp; 0 \\0 &amp; 1\end{array}\right]\]</span></p><p>例题一：</p><p><img src="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/linearspace\3.jpg"></p><p>例题二：</p><p><img src="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/linearspace\4.jpg"></p><p><img src="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/linearspace\5.jpg"></p><h2 id="线性子空间">线性子空间</h2><p>定理：线性空间V的非空子集W是V的子空间。W对于V中定义的加法与数乘封闭。</p><ul><li>若<span class="math inline">\(\alpha,\beta\)</span>∈W，则<span class="math inline">\(\alpha+\beta\)</span>∈W</li><li>若<span class="math inline">\(\alpha\)</span>∈W，k∈K，则k<span class="math inline">\(\alpha\)</span>∈W</li></ul><h2 id="线性映射">线性映射</h2><p>V自身的线性映射称为线性变换——<span class="math inline">\(T\)</span></p><h3 id="定义">定义</h3><p>若任意<span class="math inline">\(\alpha,\beta\)</span>∈V，k∈K，有 -T(<span class="math inline">\(\alpha+\beta\)</span>)=T(<span class="math inline">\(\alpha\)</span>)+T(<span class="math inline">\(\beta\)</span>) - T(k<span class="math inline">\(\alpha\)</span>)=kT(<span class="math inline">\(\alpha\)</span>)</p><p>例题：</p><p><img src="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/linearspace\6.jpg"></p><h3 id="线性变换的矩阵">线性变换的矩阵</h3><p><span class="math display">\[\begin{equation*}    \begin{bmatrix}    a11 &amp; a12 &amp; \cdots &amp; a1n\\   a21 &amp; a22 &amp; \cdots &amp; a2n\\   \vdots &amp; \vdots &amp;\ddots &amp; \vdots\\   an1 &amp; an2 &amp; \cdots &amp; ann    \end{bmatrix}\end{equation*}=A\]</span>称A为T在基(<span class="math inline">\(\alpha_{1}\)</span><span class="math inline">\(,\alpha_{2}……\alpha_{n}\)</span>)下的矩阵。</p><p>T(<span class="math inline">\(\alpha_{1}\)</span> <span class="math inline">\(,\alpha_{2}……\alpha_{n}\)</span>)=(T(<span class="math inline">\(\alpha_1\)</span>),(<span class="math inline">\(\alpha_2\)</span>)……T(<span class="math inline">\(a_n\)</span>))= <span class="math display">\[(\alpha_{1} ,\alpha_{2}……\alpha_{n})\begin{equation*}    \begin{bmatrix}    a11 &amp; a12 &amp; \cdots &amp; a1n\\   a21 &amp; a22 &amp; \cdots &amp; a2n\\   \vdots &amp; \vdots &amp;\ddots &amp; \vdots\\   an1 &amp; an2 &amp; \cdots &amp; ann    \end{bmatrix}\end{equation*}\]</span></p><p><strong>Y=AX</strong>表示同一组基下<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(T(\alpha)\)</span>的坐标关系。</p><p>同一个T在不同基下的矩阵是相似的。<span class="math inline">\(B=P^{-1}AP\)</span></p><p>例题:</p><p><img src="/2024/08/27/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90(%E8%AE%BA)/linearspace/linearspace\7.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 大学院入試 </tag>
            
            <tag> 矩阵分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生物化学通关指南(56学时)</title>
      <link href="/2024/08/24/biochem/"/>
      <url>/2024/08/24/biochem/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>https://pan.baidu.com/s/1HDHdFKILxQAitvczAk3njA?pwd=xray</p><p>1）答案不全且有错误，仅供参考2）一套生化期末卷来自生物学院，仅供参考，不会也没关系。</p>]]></content>
      
      
      <categories>
          
          <category> 製薬のConcerto </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生物化学 </tag>
            
            <tag> 期末 </tag>
            
            <tag> 合格 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>堆排序</title>
      <link href="/2024/08/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/heapsory/"/>
      <url>/2024/08/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/heapsory/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//对初始序列建立大根堆</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BuildMaxHeap</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> len)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=len/<span class="number">2</span>; i&gt;<span class="number">0</span>; i--)   <span class="comment">//从后往前调整所有非终端结点</span></span><br><span class="line">        <span class="built_in">HeadAdjust</span>(A, i, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*将以k为根的子树调整为大根堆</span></span><br><span class="line"><span class="comment">从最底层的分支结点开始调整*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HeadAdjust</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> k, <span class="type">int</span> len)</span></span>&#123;</span><br><span class="line">    A[<span class="number">0</span>] = A[k];                      <span class="comment">//A[0]暂存子树的根结点</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>*k; i&lt;=len; i*=<span class="number">2</span>)&#123;     <span class="comment">//沿key较大的子结点向下筛选</span></span><br><span class="line">                                      <span class="comment">// i为当前所选根结点的左孩子</span></span><br><span class="line">                                      <span class="comment">//i*=2是为了判断调整后再下一层是否满足大根堆</span></span><br><span class="line">        <span class="keyword">if</span>(i&lt;len &amp;&amp; A[i]&lt;A[i+<span class="number">1</span>])      <span class="comment">//判断：当前所选根结点的左、右结点哪个更大</span></span><br><span class="line">            i++;                      <span class="comment">//取key较大的子结点的下标</span></span><br><span class="line">        <span class="keyword">if</span>(A[<span class="number">0</span>] &gt;= A[i]) </span><br><span class="line">            <span class="keyword">break</span>;                    <span class="comment">//筛选结束：i指向更大的子结点</span></span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            A[k] = A[i];              <span class="comment">//将A[i]调整至双亲结点上</span></span><br><span class="line">            k=i;                      <span class="comment">//修改k值，以便继续向下筛选</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    A[k] = A[<span class="number">0</span>]                       <span class="comment">//被筛选的结点的值放入最终位置</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//交换</span></span><br><span class="line"><span class="type">void</span> <span class="built_in">swap</span>(<span class="type">int</span> &amp;a, <span class="type">int</span> &amp;b)&#123;</span><br><span class="line">    <span class="type">int</span> temp = a;</span><br><span class="line">    a = b;</span><br><span class="line">    b = temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//基于大根堆进行排序</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HeapSort</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> len)</span></span>&#123;</span><br><span class="line">    <span class="built_in">BuildMaxHeap</span>(A, len);          <span class="comment">//初始建堆</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=len; i&gt;<span class="number">1</span>; i--)&#123;      <span class="comment">//n-1趟的交换和建堆过程</span></span><br><span class="line">        <span class="built_in">swap</span>(A[i], A[<span class="number">1</span>]);          <span class="comment">//堆顶元素和堆底元素交换</span></span><br><span class="line">        <span class="built_in">HeadAdjust</span>(A,<span class="number">1</span>,i<span class="number">-1</span>);       <span class="comment">//把剩余的待排序元素整理成堆</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据结构のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>归并排序</title>
      <link href="/2024/08/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/mergesort/"/>
      <url>/2024/08/24/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/mergesort/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="归并排序">归并排序</h2><p>2路归并的“归并树”——倒立的二叉树，树高h，归并排序趟数m =h-1，第h层最多2^(h-1)个结点，则满足n ≤ 2^(h-1)，即h-1 = ⌈log₂n⌉; 结论:n个元素进行2路归并排序，归并趟数 m = ⌈log₂n⌉</p><p>每趟归并时间复杂度为O(n), 算法总时间复杂度为O(nlog₂n);</p><p>空间复杂度为O(n);(归并排序算法可视为本章占用辅助空间最多的排序算法)</p><p>稳定性：归并排序是稳定的</p><p>对于N个元素进行k路归并排序，排序的趟数m满足 k^m = N, m = ⌈logkN⌉</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建辅助数组B</span></span><br><span class="line"><span class="type">int</span> *B=(<span class="type">int</span> *)<span class="built_in">malloc</span>(n*<span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//A[low,...,mid],A[mid+1,...,high] 各自有序，将这两个部分归并</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Merge</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> low, <span class="type">int</span> mid, <span class="type">int</span> high)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> i,j,k;</span><br><span class="line">    <span class="keyword">for</span>(k=low; k&lt;=high; k++)</span><br><span class="line">        B[k] = A[k];           <span class="comment">//将A中所有元素复制到B中</span></span><br><span class="line">    <span class="keyword">for</span>(i=low, j=mid+<span class="number">1</span>, k=i; i&lt;=mid &amp;&amp; j&lt;= high; k++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(B[i]&lt;=B[j])          <span class="comment">//为保证稳定性两个元素相等时，优先使用靠前的那个</span></span><br><span class="line">            A[k]=B[i++];        <span class="comment">//将较小值复制到A中</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            A[k]=B[j++];</span><br><span class="line">    &#125;<span class="comment">//for</span></span><br><span class="line">     </span><br><span class="line">    <span class="comment">//没有归并完的部分复制到尾部，while只会执行一个 </span></span><br><span class="line">    <span class="keyword">while</span>(i&lt;=mid)  A[k++]=B[i++];     <span class="comment">//若第一个表未检测完，复制</span></span><br><span class="line">    <span class="keyword">while</span>(j&lt;=high) A[k++]=B[j++];     <span class="comment">//若第二个表未检测完，复制</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//递归操作</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MergeSort</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> low, <span class="type">int</span> high)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(low&lt;high)&#123;</span><br><span class="line">        <span class="type">int</span> mid = (low+high)/<span class="number">2</span>;    <span class="comment">//从中间划分</span></span><br><span class="line">        <span class="built_in">MergeSort</span>(A, low, mid);    <span class="comment">//对左半部分归并排序</span></span><br><span class="line">        <span class="built_in">MergeSort</span>(A, mid+<span class="number">1</span>, high); <span class="comment">//对右半部分归并排序</span></span><br><span class="line">        <span class="built_in">Merge</span>(A,low,mid,high);     <span class="comment">//归并</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="基数排序">基数排序</h2><p>用于处理链式存储</p><ul><li>数据元素的关键字可以很容易地进行拆分成d组，且d较小；</li><li>每组关键字的取值范围不大，即r较小；</li><li>数据元素个数n较大。</li></ul><p>总排序的时间复杂度为O(d(n+r))</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUMCM2020-A</title>
      <link href="/2024/08/24/%E6%95%B0%E6%A8%A1/2020A/"/>
      <url>/2024/08/24/%E6%95%B0%E6%A8%A1/2020A/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="基于一维热传导方程的回焊炉炉温模型">基于一维热传导方程的回焊炉炉温模型</h1><h2 id="题目类型与评价">题目类型与评价</h2><p>传热问题和多目标规划问题的范文。</p><p>求解过程基本可以复制粘贴到其他传热问题(比如2018A)</p><h2 id="摘要">摘要</h2><p>对于每一个问题，通过“将该问题转换为……”“实质上是……”来进行模型分类和化归。</p><p>关键词：一维热传导方程、遗传算法、多变量非线性规划、分层序列法</p><h2 id="问题重述">问题重述</h2><p>把原题的图的表都复制了一遍</p><h2 id="模型假设">模型假设</h2><p>可以抄知网论文的</p><h2 id="符号说明">符号说明</h2><h2 id="问题分析">问题分析</h2><h3 id="问题一分析">问题一分析</h3><ul><li>合理简化实际情况，列出热传导方程组，确定边界条件。</li><li>采用合理的方法解方程，并分段求出各个温区对应的热学参数，使得模型预测结果与附件所给结果之间的均方根误差最小。</li><li>代入问题一所给的各温区温度和过炉速度，计算炉温曲线。</li></ul><p>画图</p><h3 id="问题二分析">问题二分析</h3><h3 id="问题三分析">问题三分析</h3><p>画图</p><h3 id="问题四分析">问题四分析</h3><h2 id="模型建立">模型建立</h2><p>图示工件和环境的关系</p><h3 id="热传导方程的建立">热传导方程的建立</h3><h3 id="边界条件的确定与模型的建立">边界条件的确定与模型的建立</h3><h2 id="问题解答">问题解答</h2><h3 id="炉内环境温度的计算">炉内环境温度的计算</h3><p>此时炉内温度的分布具有线性形式。因此，我们认为小温区、炉前区域、炉后区域之间的间隙处温度分布是线性的，并认为炉外一切区域的温度都与室内相同。</p><p>可视化实验中的环境温度</p><h3 id="有限差分法解pde方程">有限差分法解PDE方程</h3><p>有限差分法解偏微分方程示意图</p><h3 id="模型热学参数的确定">模型热学参数的确定</h3><p>假设每个区域的k和h都相等，仅考虑a的不同</p><p>模拟数据和实验数据的炉温曲线对比图</p><h3 id="问题一的求解">问题一的求解</h3><p>根据上文计算的……</p><p>经过检验，本题中求得的炉温曲线满足制程界限约束。并按照……写入文件中。</p><p>可视化</p><p><em>温度分布伪彩图</em></p><h3 id="题目二求解">题目二求解</h3><p>1）约束条件公式表达</p><p>2）约束条件说明</p><p>搜索过程可视化</p><p>从图中可以观察到……可近似认为它们是关于过炉速度的单调函数，不存在陷入局部最优非全局最优的情况。</p><h3 id="题目三求解">题目三求解</h3><h4 id="面积计算">面积计算</h4><p>解模函数</p><h4 id="遗传算法">遗传算法</h4><p>图解遗传算法</p><p>为尽可能减少遗传算法结果的不确定性，我们进行了多次独立重复求解。利用MATLAB的遗传算法工具箱编程并调整算法参数，将每次得到的潜在最优解记录在表3中：</p><p>描述面积小的充分条件；解释遗传算法求解结果</p><h3 id="题目四求解">题目四求解</h3><p>刻画曲线对称性偏差的函数</p><p>转化为双目标线性规划问题</p><h4 id="分层序列法">分层序列法</h4><p><strong>摘录</strong>：</p><p>如果目标函数fi具有比fj更高的优先性，那么我们可以采用简单分层序列法。该方法的局限性是，若某一步最优化解是唯一的，其后所有步骤的解也是唯一的，致使之后所有目标函数失去意义。因此，求解较上层优化问题时，需要给予优化结果一定的宽容度。引进一系列充分小的正数lambda1、lambda2……</p><h4 id="接力进化的遗传算法">接力进化的遗传算法</h4><p>可视化对称性比较</p><h2 id="模型总结">模型总结</h2><h3 id="灵敏度">灵敏度</h3><p>改变搜索步长</p><h3 id="优缺点">优缺点</h3><p>多目标规划和传热问题都可以套</p><p><img src="/2024/08/24/%E6%95%B0%E6%A8%A1/2020A/image.png"></p>]]></content>
      
      
      <categories>
          
          <category> 数模のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>交换排序</title>
      <link href="/2024/08/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/exchangesort/"/>
      <url>/2024/08/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/exchangesort/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="冒泡排序">冒泡排序</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(<span class="type">int</span> &amp;a,<span class="type">int</span> &amp;b)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> temp=a;</span><br><span class="line">    a=b;</span><br><span class="line">    b=temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BubbleSort</span><span class="params">(<span class="type">int</span> A[];<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n<span class="number">-1</span>;i++)</span><br><span class="line">        <span class="type">bool</span> flag=<span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=n<span class="number">-1</span>;j&gt;i;j--)</span><br><span class="line">            <span class="keyword">if</span>(A[j<span class="number">-1</span>]&gt;A[j])&#123;</span><br><span class="line">                <span class="built_in">swap</span>(A[j<span class="number">-1</span>],A[j]);</span><br><span class="line">                flag=<span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">         <span class="keyword">if</span>(flag==<span class="literal">false</span>)</span><br><span class="line">            <span class="keyword">return</span>;       <span class="comment">//本趟遍历后没有发生交换，说明表已经有序，可以结束算法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>稳定</p></li><li><p>可用于链表、顺序表</p></li></ul><h2 id="快速排序">快速排序</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Partition</span><span class="params">(<span class="type">int</span> A[];<span class="type">int</span> low;<span class="type">int</span> high)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> pivot=A[low]</span><br><span class="line">    <span class="keyword">while</span>(low&lt;high)&#123;</span><br><span class="line">        <span class="keyword">while</span>(low&lt;high&amp;&amp;A[high]&gt;=pivot) --high;</span><br><span class="line">        A[low]=A[high]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span>(low&lt;high &amp;&amp; A[low]&lt;=pivot)  ++low; </span><br><span class="line">        A[high] = A[low];</span><br><span class="line">    &#125;</span><br><span class="line">    A[low]=pivot;</span><br><span class="line">    <span class="keyword">return</span> low;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">QuickSort</span><span class="params">(<span class="type">int</span> A[];<span class="type">int</span> low;<span class="type">int</span> high)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(low&lt;high)&#123;</span><br><span class="line">        <span class="type">int</span> pivotpos = <span class="built_in">Partition</span>(A,low,high);</span><br><span class="line">        <span class="built_in">QuickSort</span>(A,low,pivotpos<span class="number">-1</span>);</span><br><span class="line">        <span class="built_in">QuickSort</span>(A,pivotpos+<span class="number">1</span>,high);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据结构のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>插入排序</title>
      <link href="/2024/08/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/insertsort/"/>
      <url>/2024/08/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/insertsort/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="算法思想">算法思想</h2><p>每次将一个待排序的记录按其关键字大小插入到前面已排好序的子序列中，直到全部记录插入完成。</p><h2 id="直接插入排序">直接插入排序</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">InsertSort</span><span class="params">(<span class="type">int</span> A[],<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> i,j,temp;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;n;i++)</span><br><span class="line">        <span class="keyword">if</span>(A[i]&lt;A[i<span class="number">-1</span>])&#123;</span><br><span class="line">        temp=A[i];</span><br><span class="line">        <span class="keyword">for</span>(j=i<span class="number">-1</span>;j&gt;=<span class="number">0</span> &amp;&amp; A[j]&gt;temp;j--)</span><br><span class="line">            A[j+<span class="number">1</span>]=A[j];</span><br><span class="line">        A[j+<span class="number">1</span>]=temp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="折半插入排序">折半插入排序</h2><p>用A[0]暂存目标</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">InsertSort</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> n)</span></span>&#123; </span><br><span class="line">    <span class="type">int</span> i,j,low,high,mid;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">2</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        A[<span class="number">0</span>] = A[i];                    <span class="comment">//将A[i]暂存A[0]</span></span><br><span class="line">        low = <span class="number">1</span>; high = i<span class="number">-1</span>;            <span class="comment">//折半查找的范围</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(low&lt;=high)&#123;               <span class="comment">//折半查找</span></span><br><span class="line">            mid = (low + high)/<span class="number">2</span>;       <span class="comment">//取中间点</span></span><br><span class="line">            <span class="keyword">if</span>(A[mid]&gt;A[<span class="number">0</span>])             <span class="comment">//查找左半子表</span></span><br><span class="line">                high = mid - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span>                        <span class="comment">//查找右半子表</span></span><br><span class="line">                low = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(j=i<span class="number">-1</span>; j&gt;high+<span class="number">1</span>;--j)       <span class="comment">//统一后移元素，空出插入位置</span></span><br><span class="line">            A[j+<span class="number">1</span>] = A[j];</span><br><span class="line">        A[high+<span class="number">1</span>] = A[<span class="number">0</span>]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">InsertSort</span>(<span class="params">nums,n</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">        temp=nums[i]</span><br><span class="line">        low=<span class="number">0</span></span><br><span class="line">        high=i-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> low&lt;=high:</span><br><span class="line">            mid=<span class="built_in">int</span>((low+high)/<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> temp&gt;nums[mid]:</span><br><span class="line">                low=mid+<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                high=mid-<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i-<span class="number">1</span>,high,-<span class="number">1</span>):</span><br><span class="line">            nums[j+<span class="number">1</span>]=nums[j]</span><br><span class="line">        nums[high+<span class="number">1</span>]=temp</span><br><span class="line"><span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure><h2 id="希尔排序">希尔排序</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ShellSort</span><span class="params">(<span class="type">int</span> A[];<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> d;</span><br><span class="line">    <span class="keyword">for</span>(d=n/<span class="number">2</span>;d&gt;=<span class="number">1</span>;d=d/<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">1</span>+d;i&lt;=n;i++)</span><br><span class="line">            <span class="keyword">if</span>(A[i]&lt;A[i-d])&#123;</span><br><span class="line">                A[<span class="number">0</span>]=A[i];</span><br><span class="line">                <span class="keyword">for</span>(j=i-d;j&gt;<span class="number">0</span>&amp;&amp;A[<span class="number">0</span>]&lt;A[j];j-=d)</span><br><span class="line">                    A[j+d]=A[j];</span><br><span class="line">                A[j+d]=A[<span class="number">0</span>];</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="算法效率分析">算法效率分析</h3><ul><li><p>空间效率：空间复杂度=O(1)</p></li><li><p>时间效率: 最坏情况下时间复杂度=O(n²)</p></li><li><p>稳定性：希尔排序是一种不稳定的排序方法</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>背景知识-地下水</title>
      <link href="/2024/08/21/tofel/4/"/>
      <url>/2024/08/21/tofel/4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="内容">内容</h2><p>我们能看到的水是地表水，包括河湖泊海洋等，当地下水(groundwater)更多，他们填满地下的岩石和沉积物之间。</p><p>完整的地下水体叫含水层(aquifer)。美国最大的含水层叫做the High PlainAquifer。水位线(water table)下的是饱和含水层(saturated)。</p><p>水循环：一部分流入河流海洋，一部挥发，一部分流入地下。地下水可以待很久。很多地上水来自地下水。当地表低于水位线时，地下水就会流出。地下水会在斜坡出涌出，流出位置就是spring；地表水也可以变成地下水。</p><p>人们从地下抽水，主要用于种植。虽然水循环可以补给含水层，但使用过快，虽然不会永远干涸，但也需要上百上千年才能恢复到健康水位</p><h2 id="单词">单词</h2><p>seep down 渗透</p><p>soak up 吸入液体</p><p>replenish v.补充</p><p>cram v.塞满</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 托福 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jordon标准型求法</title>
      <link href="/2024/08/19/Jordan1/"/>
      <url>/2024/08/19/Jordan1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="求下矩阵的-jordan-标准形和相应的相似变换矩阵">求下矩阵的 Jordan标准形和相应的相似变换矩阵</h2><p>给定矩阵 ( A ) 如下：</p>[ A =<span class="math display">\[\begin{pmatrix}-1 &amp; -2 &amp; 6 \\-1 &amp; 0 &amp; 3 \\-1 &amp; -1 &amp; 4\end{pmatrix}\]</span><p>]</p><p><strong>解：</strong> 因为</p>[ I - A =<span class="math display">\[\begin{pmatrix}\lambda + 1 &amp; 2 &amp; -6 \\1 &amp; \lambda &amp; -3 \\1 &amp; 1 &amp; \lambda - 4\end{pmatrix}\]</span><span class="math display">\[\begin{pmatrix}1 &amp; 0&amp; 0 \\0&amp; \lambda - 1&amp; 0 \\0&amp; 0&amp; (\lambda - 1)^2\end{pmatrix}\]</span><p>]</p><p>行列变换成对角形式</p><p>故</p>[ A J =<span class="math display">\[\begin{pmatrix}1 &amp;0 &amp;0 \\0 &amp; 1 &amp;1 \\0 &amp; 0 &amp; 1\end{pmatrix}\]</span><p>] 两个初等因子<span class="math inline">\(\lambda - 1\)</span>和<span class="math inline">\((\lambda - 1)^2\)</span>其中<span class="math inline">\((\lambda -1)^2\)</span>是重根，所以相应对角线上还有个1</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>背景知识-TPO38L4(气态行星)</title>
      <link href="/2024/08/18/tofel/3/"/>
      <url>/2024/08/18/tofel/3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="内容">内容</h2><p>首先，复习太阳的形成。太阳的disk里面的dust，grain ofrock，metal碰撞持续，形成mini-planets和proto-planets——这个过程叫做accretion。</p><p>两个部分：内accretion环和外accretion环。内环：物体变大，重力场变强，加速accretion，吸引小物体，最终得到自己的orbit。这就是内层的rocky行星的形成。</p><p>然后，气体行星形成的区别。由于离日远，水和氨都是固态结冰的。 coreaccretion theory：固体核吸引气体并被其环绕 disk instabilitytheory：没有固体核，大部分是气体。外部重力场不稳固。随着时间的推移，灰尘和气体合并向中心坍塌，重力吸引更多的气体和尘粒。</p><h3 id="注意点">注意点：</h3><ul><li>一定要理清每层之间相互作用</li><li>What means后面很重要</li><li>老师如果提问给学生，学生的回答很重要 ## 单词</li></ul><p>recap 重温 disk 圆盘 accretion 堆积物，渐增 coalesce 合并</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 托福 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUMCM2020-B</title>
      <link href="/2024/08/17/%E6%95%B0%E6%A8%A1/2020B/"/>
      <url>/2024/08/17/%E6%95%B0%E6%A8%A1/2020B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="题目类型与评价">题目类型与评价</h2><p>暴力</p><p>部分表述太主观了。</p><h2 id="摘要">摘要</h2><p>关键词：动态规划、统计分析、随机模拟、静态博弈</p><h2 id="问题重述">问题重述</h2><h2 id="模型假设">模型假设</h2><p>小标题＋说明假设目的</p><h2 id="图动态规划模型">图动态规划模型</h2><ul><li>证明必经过功能点</li><li>动态规划思想来源</li><li>状态空间分析</li><li>状态转移方程</li><li>算法实现<strong>并对伪代码解释说明</strong>（论文中加入模型思路的伪代码并解释是个不错的思路）</li><li>复杂度分析 ## 问题一 先用动态规划求解出最佳策略</li></ul><h3 id="策略变化分析"><strong>策略变化分析</strong></h3><p>分析了最高得分随截止日期增加的上升情况，并分析其与是否采矿的关系。</p><p>结论：截止天数较少时最优策略倾向于节约资源开支，直接到达终点。20天即之后到达的情况才会考虑挖矿并在村庄购买资源补充。</p><h3 id="第二关">第二关</h3><p>同理</p><h3 id="一般情况下最优策略">一般情况下最优策略</h3><ul><li>到达终点处时玩家的资源恰好耗尽</li><li>起点处在保证生存的情况下多买食物 计算<strong>携带效率</strong></li></ul><h3 id="玩家每次移动总会与目的地的最短距离缩小">玩家每次移动总会与目的地的最短距离缩小</h3><h2 id="问题二">问题二</h2><h3 id="基于完全统计">基于完全统计</h3><p>完全遍历1024种情况</p><h4 id="确定路线">确定路线</h4><p>不挖矿</p><h4 id="确定行走-停留方式">1确定行走-停留方式</h4><ul><li>晴朗移动</li><li>高温停留</li><li>高温移动</li></ul><h4 id="购买方式确定">2购买方式确定</h4><p>计算n个最优解的食物和水的购买均值和标准差，从而得到优秀购买区间</p><p>并可视化</p><h5 id="购买方式分析">购买方式分析</h5><p>两种资源均值大致相等，这说明大部分的优秀策略都选择了购买尽量等量的水和食物。结合天气情况解释，并和一作比较。</p><h5 id="购买量分析">购买量分析</h5><h4 id="搜索空间确定">搜索空间确定</h4><h4 id="方案评价模型">方案评价模型</h4><h3 id="第三关结果呈现">第三关结果呈现</h3><h3 id="第四关简化">第四关简化</h3><p>1）起点到决策点采用第三关 2）村/矿山到终点采用第三关</p><h3 id="天气等效模型">天气等效模型</h3><p>晴朗和沙暴天按5:1进行等效为高温天</p><h3 id="解答与分析">解答与分析</h3><p>分析购买策略-&gt;路径推理-&gt;路径一的优势分析</p><h2 id="静态博弈模型问题三策略分析与设计">静态博弈模型：问题三策略分析与设计</h2><h3 id="两人单价博弈">两人单价博弈</h3><h4 id="思路分析">思路分析</h4><p>混合策略满足纳什均衡</p><h4 id="博弈收益表的计算">博弈收益表的计算</h4><h4 id="最优纯策略和最优混合策略">最优纯策略和最优混合策略</h4><p>纯策略S6最优</p><h4 id="允许交流">允许交流</h4><p>一人S1，一人S3。比不交流更优。</p><h3 id="三人多阶段博弈">三人多阶段博弈</h3><p>多阶段博弈的关键是寻找到纳什均衡点，因为纳什均衡点才能稳定存在，同时意味着每个玩家都有比较好的受益。</p><h3 id="两玩家高温天抵达同一地点博弈">两玩家高温天抵达同一地点博弈</h3><h3 id="两玩家高温天抵达同一座矿山博弈">两玩家高温天抵达同一座矿山博弈</h3><h3 id="两玩家高温天抵达村庄博弈">两玩家高温天抵达村庄博弈</h3><h2 id="模型总结">模型总结</h2><h3 id="灵敏度分析">灵敏度分析</h3><p>居然没做图</p><h3 id="总结与感想">总结与感想</h3><h4 id="摘抄">摘抄</h4><p>本文我们对穿越沙漠游戏的策略进行了由浅入深的分析，对于越来越复杂的问题也有确定性策略求解转化为带有随机性，局部性优化，并利用各种评价方法进行讨论分析。</p><p>其实该问题本身的递进过程就是对一定的现实背景进行建模，我们在这二次建模的过程中也充分感受到数学各个分支的基本思想之间存在着广泛联系，可能就会在某个有趣的问题上汇合。只有创造性的思维加上扎实的理论，计算基本功才能较好地处理一个实际问题。</p>]]></content>
      
      
      <categories>
          
          <category> 数模のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>背景知识-太阳系</title>
      <link href="/2024/08/15/tofel/2/"/>
      <url>/2024/08/15/tofel/2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="内容">内容</h2><p>太阳系在约45亿年前形成。星际间的气体和尘埃碰撞形成了太阳系星云(solarnebula)————内中的材料撞击形成了太阳系。</p><p>太阳系位于银河系中的猎户座星团(Orion starcluster)。银河系里只有15%的恒星拥有行星系统。</p><p>八个行星可以分为两类：类地(Terrestrial)和类木(Jovian)</p><p>类地：包括水星，金星，地球和火星 - 由岩石类组成 - 表面是固体 -没有环状带 - 很少或没有卫星 - 相对较小最小、离太阳最近的是水星。金星是最热的。火星可能在37亿年前支持生命活动，当时他表面多水、大气潮湿</p><p>类木：分为气体巨星(木星和土星)和冰巨星(天王星和海王星)</p><p>四个类木行星都有很多个卫星，有环状带，没有固体表面。最大的类木行星式木星。土星是第二大，其环状带宽至地月距，厚度却只有一公里。冥王星侧边旋转。海王星最冷。</p><p>围绕在类地行星的是小行星带，充满太阳系形成的剩余物体，从尘埃到最大的物体(矮星谷神星)</p><p>围绕在类木行星的是柯伊伯带(Kuiper Belt)，是很多彗星的诞生地。</p><p>柯伊伯带外面是奥尔特云(Oortcloud),冰碎片组成的巨大球体。是太阳系的边界——太阳的重力和物理影响消失</p><h2 id="单词">单词</h2><p>Mercury Venus Mars Jupiter Saturn Uranus Neptune the Milky Waygalaxy银河系 Orion star cluster猎户座星团 Terrestrial planets类地行星Jovian planets类木行星 Pluto冥王星 kuiper belt柯伊伯带 remnant残余</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 托福 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣-55</title>
      <link href="/2024/08/15/lc/leetcode_55/"/>
      <url>/2024/08/15/lc/leetcode_55/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>给你一个非负整数数组 nums ，你最初位于数组的 第一个下标。数组中的每个元素代表你在该位置可以跳跃的最大长度。</p><p>判断你是否能够到达最后一个下标，如果可以，返回 true ；否则，返回false 。</p><p>示例 1：</p><p>输入：nums = [2,3,1,1,4] 输出：true 解释：可以先跳 1 步，从下标 0到达下标 1, 然后再从下标 1 跳 3 步到达最后一个下标。 示例 2：</p><p>输入：nums = [3,2,1,0,4] 输出：false 解释：无论怎样，总会到达下标为 3的位置。但该下标的最大跳跃长度是 0 ，所以永远不可能到达最后一个下标。</p><p>dp:On^2/On 居然一上来就想着倒着跳www <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">canJump</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dekiru</span>(<span class="params">n</span>):</span><br><span class="line">            <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            cout = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> nums[<span class="built_in">max</span>(n-i-<span class="number">1</span>,<span class="number">0</span>)] &gt;= i+<span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> dekiru(n-i-<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    cout+=<span class="number">1</span>       </span><br><span class="line">                <span class="keyword">if</span> cout == n +<span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> dekiru(<span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure> 贪心：On/O1<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">canJump</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> nums == [<span class="number">0</span>]: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        maxDist = <span class="number">0</span></span><br><span class="line">        end_index = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i, jump <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            <span class="keyword">if</span> maxDist &gt;= i <span class="keyword">and</span> i+jump &gt; maxDist:</span><br><span class="line">                maxDist = i+jump</span><br><span class="line">                <span class="keyword">if</span> maxDist &gt;= end_index:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">canJump</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> k = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &gt; k) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            k = <span class="built_in">max</span>(k, i + nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 力扣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>背景知识-书写的艺术</title>
      <link href="/2024/08/13/tofel/1/"/>
      <url>/2024/08/13/tofel/1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="内容">内容</h2><h3 id="起源">起源</h3><p>书写第一次大规模使用可以追溯回古代苏美尔(ancientSumer)。神殿(temple)对写作的起源有重大影响。苏美尔是第一批大城市的起源，这些城市信仰着同一批神，从而形成洲(state)。神殿不只是祭拜的地方，还是一个仓库，里面储存着大量财富。需要有人来记录货物进出神殿。人们开始创造一套公认的符号标志。 ### 发展人们意识到符号不只代表概念，也代表符号本身；同时，苏美尔语中单词都是单音节的，所以很容易从符号联系到单词并联系到发音。</p><p>在书写方式上：从左向右写，这样不会擦掉刚写的。</p><p>最初的图片，以及衍生出的象形文字(pictograms)消失，变成了楔形印记(wedge-shaped)。文字写在黏土上，火烧不会销毁他们，反而让书写更加坚固</p><h2 id="单词">单词</h2><p>cuneiform 楔形文字 communicate ideas over the gulf of space and time穿越时空的鸿沟交流思想<br>scribe 抄写员 veneration (书面语)崇敬 good times/lean times时节好/歹</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 托福 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-欧拉法</title>
      <link href="/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/Euler/"/>
      <url>/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/Euler/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="欧拉法">欧拉法</h2><p>考虑初值问题： <span class="math display">\[\frac{dy}{dx} = y - \frac{2x}{y}, \quad y(0) = 1\]</span> 我们将使用欧拉法来近似求解这个问题。</p><p>设步长为 <span class="math inline">\(h\)</span>，例如 <span class="math inline">\(h = 0.1\)</span>。初始条件为 <span class="math inline">\(y(0) = 1\)</span>，计算到 <span class="math inline">\(x = 1\)</span>。</p><p>欧拉法的迭代公式为： [ y_{n+1} = y_n + h f(x_n, y_n) ] 其中，函数<span class="math inline">\(f(x_n, y_n)\)</span> 是给定的导数表达式： [f(x_n, y_n) = ]</p><p>根据欧拉法，我们可以进行以下迭代：</p><p>计算 <span class="math inline">\(x_{n+1} = x_n + h\)</span>。 计算<span class="math inline">\(y_{n+1} = y_n + h \cdot (y_n -\frac{2x_n}{y_n})\)</span>。</p><p>假设初始条件为 <span class="math inline">\(x_0 = 0\)</span> 和 <span class="math inline">\(y_0 = 1\)</span>，步长为 <span class="math inline">\(h = 0.1\)</span>。我们计算前几个步长的结果： <span class="math display">\[\begin{align*}x_1 &amp;= x_0 + h = 0 + 0.1 = 0.1 \\y_1 &amp;= y_0 + h \cdot \left( y_0 - \frac{2x_0}{y_0} \right) = 1 + 0.1\cdot \left( 1 - \frac{2 \cdot 0}{1} \right) = 1 + 0.1 \cdot 1 = 1.1\end{align*}\]</span> <span class="math display">\[\begin{align*}x_2 &amp;= x_1 + h = 0.1 + 0.1 = 0.2 \\y_2 &amp;= y_1 + h \cdot \left( y_1 - \frac{2x_1}{y_1} \right) = 1.1 +0.1 \cdot \left( 1.1 - \frac{2 \cdot 0.1}{1.1} \right) \approx 1.1 + 0.1\cdot \left( 1.1 - 0.1818 \right) \approx 1.1 + 0.1 \cdot 0.9182 \approx1.1918\end{align*}\]</span> ··· ## 改进欧拉法 <span class="math inline">\(y&#39;+y=0\)</span> <span class="math inline">\(y_{0}=1\)</span> 解： <span class="math inline">\(y_{n+1}=y_n+h/2(-y_n-y*_{n+1})\)</span>其中<span class="math inline">\(y*_{n+1}=y_n+hf(x_n,y_n)\)</span> 所以<span class="math inline">\(y_{n+1}=(1-h+h^{2}/2)y_n\)</span> 迭代：<span class="math inline">\(y_{n+1}=(1-h+h^{2}/2)^ny_0\)</span></p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
            <tag> 大学院入試 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-龙格库塔法</title>
      <link href="/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/RK/"/>
      <url>/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/RK/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="四阶龙格-库塔法">四阶龙格-库塔法</h2><p>标准四阶龙格-库塔法（Runge-Kuttamethod）是一种用于数值解常微分方程（ODE）的高精度方法。下面是四阶龙格-库塔法的公式和解题流程。</p><h3 id="四阶龙格-库塔法的公式">四阶龙格-库塔法的公式</h3><p>四阶龙格-库塔法的迭代公式为：</p><ol type="1"><li><strong>计算中间值</strong>:<ul><li>( k_1 = h f(x_n, y_n) )</li><li>( k_2 = h f(x_n + , y_n + ) )</li><li>( k_3 = h f(x_n + , y_n + ) )</li><li>( k_4 = h f(x_n + h, y_n + k_3) )</li></ul></li><li><strong>更新公式</strong>: [ y_{n+1} = y_n + (k_1 + 2k_2 + 2k_3 +k_4) ]</li></ol><h3 id="解题流程">解题流程</h3><ol type="1"><li><strong>定义问题</strong>:<ul><li>给定初值问题： [ = f(x, y), y(x_0) = y_0 ]</li></ul></li><li><strong>选择步长 ( h )</strong>:<ul><li>选择适当的步长 ( h )（例如，( h = 0.1 )）</li></ul></li><li><strong>初始化</strong>:<ul><li>设置初始条件 ( x_0 ) 和 ( y_0 )</li><li>计算到 ( x_n ) 的范围</li></ul></li><li><strong>迭代计算</strong>:<ul><li>对每个 ( x_n ) 使用龙格-库塔公式计算 ( y_{n+1} )</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
            <tag> 大学院入試 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-追赶法</title>
      <link href="/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/chase/"/>
      <url>/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/chase/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>对于爪形矩阵的LU分解</p><p><span class="math display">\[\begin{pmatrix}b_1 &amp; c_1 &amp; 0 &amp; \cdots &amp; 0 \\a_2 &amp; b_2 &amp; c_2 &amp; \cdots &amp; 0 \\0 &amp; a_3 &amp; b_3 &amp; \cdots &amp; 0 \\\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; c_{n-1} \\0 &amp; 0 &amp; 0 &amp; a_n &amp; b_n \\\end{pmatrix}\begin{pmatrix}x_1 \\x_2 \\x_3 \\\vdots \\x_n \\\end{pmatrix}=\begin{pmatrix}d_1 \\d_2 \\d_3 \\\vdots \\d_n \\\end{pmatrix}\]</span></p><p><span class="math display">\[\textbf{前向消去:}\alpha_1 = \frac{c_1}{b_1}, \quad \beta_1 = \frac{d_1}{b_1}\]</span> <span class="math display">\[\alpha_i = \frac{c_i}{b_i - a_i \alpha_{i-1}}, \quad \beta_i = \frac{d_i- a_i \beta_{i-1}}{b_i - a_i \alpha_{i-1}}, \quad (i = 2, 3, \dots, n)\]</span> <span class="math display">\[\textbf{回代:}x_n = \beta_n, \quad x_i = \beta_i - \alpha_i x_{i+1}, \quad (i = n-1,n-2, \dots, 1)\]</span> 求解顺序为：<span class="math display">\[\alpha_{1}-&gt;\beta_{1}-&gt;\alpha_{2}-&gt;\beta_{2}-&gt;\alpha_{3}……\]</span></p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
            <tag> 大学院入試 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-迭代</title>
      <link href="/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/diedai/"/>
      <url>/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/diedai/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>例题： <span class="math display">\[\begin{bmatrix}8 &amp; -3 &amp; 2 \\4 &amp; 11&amp; -1 \\6&amp;3&amp;12\end{bmatrix}\begin{pmatrix}    x_{1}\\    x_{2}\\    x_{3}\end{pmatrix}=\begin{pmatrix}    20\\33\\36\end{pmatrix}\]</span></p><p>精确解：x*=(3,2,1)'</p>可以记作： [ A = ] 其中， [ A =<span class="math display">\[\begin{bmatrix}8 &amp; -3 &amp; 2 \\4 &amp; 11 &amp; -1 \\6 &amp; 3 &amp; 12\end{bmatrix}\]</span>, =<span class="math display">\[\begin{pmatrix}x_1 \\x_2 \\x_3\end{pmatrix}\]</span>, =<span class="math display">\[\begin{pmatrix}20 \\33 \\36\end{pmatrix}\]</span><p>]</p><h3 id="雅可比迭代法">雅可比迭代法</h3>首先将矩阵 <span class="math inline">\(A\)</span> 分解为对角矩阵 <span class="math inline">\(D\)</span>、下三角矩阵 <span class="math inline">\(L\)</span> 和上三角矩阵 <span class="math inline">\(U\)</span>： [ A = D + L + U ] 其中， [ D =<span class="math display">\[\begin{bmatrix}8 &amp; 0 &amp; 0 \\0 &amp; 11 &amp; 0 \\0 &amp; 0 &amp; 12\end{bmatrix}\]</span>, L =<span class="math display">\[\begin{bmatrix}0 &amp; 0 &amp; 0 \\4 &amp; 0 &amp; 0 \\6 &amp; 3 &amp; 0\end{bmatrix}\]</span>, U =<span class="math display">\[\begin{bmatrix}0 &amp; -3 &amp; 2 \\0 &amp; 0 &amp; -1 \\0 &amp; 0 &amp; 0\end{bmatrix}\]</span><p>]</p><p>雅可比迭代法的迭代公式为： [ ^{(k+1)} = D^{-1} ( - (L + U)^{(k)}) ]### 高斯-赛德尔迭代法</p><p>高斯-赛德尔迭代法的矩阵形式为： [ ^{(k+1)} = (D + L)^{-1} ( -U^{(k)}) ]</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
            <tag> 大学院入試 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-Langrange插值</title>
      <link href="/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/langrange/"/>
      <url>/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/langrange/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="n1">n=1</h2><p><span class="math display">\[P_1(x) = y_0 \cdot \frac{x - x_1}{x_0 - x_1} + y_1 \cdot \frac{x -x_0}{x_1 - x_0}\]</span> ## n=2 <span class="math display">\[P_2(x) = y_0 \cdot \frac{(x - x_1)(x - x_2)}{(x_0 - x_1)(x_0 - x_2)}+ y_1 \cdot \frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)}+ y_2 \cdot \frac{(x - x_0)(x - x_1)}{(x_2 - x_0)(x_2 - x_1)}\]</span> ## 一般情况 <span class="math display">\[P_n(x) = \sum_{i=0}^{n} y_i \cdot \prod_{\substack{0 \leq j \leq n \\ j\neq i}} \frac{x - x_j}{x_i - x_j}\]</span></p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
            <tag> 大学院入試 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-最小二乘法</title>
      <link href="/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/lsm/"/>
      <url>/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/lsm/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="最小二乘拟合多项式">最小二乘拟合多项式</h1><p><span class="math display">\[\varphi_{0}=1,\varphi_{1}=x,\varphi_{2}=x^2,……\varphi_{n}=x^n\]</span> ## 例题 <span class="math display">\[x \quad -3\quad-2\quad-1\quad0\quad1\quad2\quad3\quad4\]</span> <span class="math display">\[f(x)\quad-3.2\quad-2.1\quad-1.2\quad0.1\quad0.9\quad2.1\quad3.3\quad4\]</span> 试用y=ax+b拟合</p><h2 id="题解">题解</h2><p><span class="math display">\[\begin{bmatrix}(\varphi_{0},\varphi_{0}) &amp; (\varphi_{0},\varphi_{1}) \\(\varphi_{1},\varphi_{0}) &amp; (\varphi_{1},\varphi_{1})\end{bmatrix}\begin{pmatrix}    a_{0}\\    a_{1}\end{pmatrix}=\begin{pmatrix}    (f,\varphi_{0})\\    (f,\varphi_{1})\end{pmatrix}\]</span> <span class="math display">\[\varphi_{0}=(1,1,1,1,1,1,1,1,1)&#39;\]</span> <span class="math display">\[\varphi_{1}=(-3,-2,-1,0,1,2,3,4)&#39;\]</span> <span class="math display">\[f=(-3.2,-2.1,-1.2,0.1,0.9,2.1,3.3,4)&#39;\]</span></p><p><span class="math display">\[a_{0}=a,a_{1}=b\]</span> 可得： <span class="math display">\[\begin{bmatrix}8 &amp; 4 \\4 &amp; 44\end{bmatrix}\begin{pmatrix}    a\\    b\end{pmatrix}=\begin{pmatrix}    3.9\\    46\end{pmatrix}\]</span> 解得</p><p>a=1.048810，b=-0.036905</p><p>二次拟合即3by3 * 3by1=3by1，其中<span class="math inline">\(\varphi_{2}\)</span>为每个x的平方组成的列向量</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
            <tag> 大学院入試 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-牛顿法</title>
      <link href="/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/newton/"/>
      <url>/2024/08/11/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/newton/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p><span class="math display">\[x_{k+1}=x_{k}-f(x_{k})/f&#39;(x_{k})\]</span> eg.用牛顿迭代法来求解<span class="math inline">\(x=e^{-x}\)</span>在0.5附近的根</p><p>解： <span class="math inline">\(f(x)=x-e^{-x}\)</span> <span class="math inline">\(x_{0}=0.5\)</span> <span class="math inline">\(x_{1}=0.5-(0.5-e^{-0.5})/(1+e^{-0.5})=0.56631\)</span><span class="math inline">\(x_{2}=0.56631-(0.56631-e^{-0.56631})/(1+e^{-0.56631})\)</span>· · · <span class="math inline">\(x_{n}=……\)</span></p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
            <tag> 大学院入試 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KMP</title>
      <link href="/2024/08/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/kmp/"/>
      <url>/2024/08/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/kmp/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">getNext</span><span class="params">(<span class="type">int</span> next[],string s)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> j=<span class="number">0</span>;</span><br><span class="line">    next[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;s.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">        <span class="keyword">while</span>( j&gt;<span class="number">0</span> &amp;&amp; s[j]!=s[i])&#123;</span><br><span class="line">            j=next[j<span class="number">-1</span>];</span><br><span class="line">            <span class="comment">//next[i]=j;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(s[j]==s[i])&#123;</span><br><span class="line">            j++;</span><br><span class="line">            next[i]=j;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    string s;</span><br><span class="line">    <span class="built_in">getline</span>(cin,s);</span><br><span class="line">    <span class="type">int</span> next[s.<span class="built_in">size</span>()];</span><br><span class="line">    <span class="keyword">if</span>(s.<span class="built_in">size</span>()==<span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">getNext</span>(next,s);</span><br><span class="line">    <span class="type">int</span> j=<span class="number">0</span>;</span><br><span class="line">    string S;</span><br><span class="line">    <span class="built_in">getline</span>(cin,S);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;S.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">        <span class="keyword">while</span>(j&gt;<span class="number">0</span>&amp;&amp;S[i]!=s[j]) j=next[j<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">if</span>(S[i]==s[j]) j++;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(j==s.<span class="built_in">size</span>()) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据结构のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUMCM2023-A092</title>
      <link href="/2024/08/07/%E6%95%B0%E6%A8%A1/2023A092/"/>
      <url>/2024/08/07/%E6%95%B0%E6%A8%A1/2023A092/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="题目类型与评价">题目类型与评价</h1><p>物理建模</p><p>值得学习公式的阐述</p><p>论文的结构和书写上来看，本文很出色的一点是<em>结果分析</em>，分别从三个点进行结果分析，不仅提高论文的解释性，而且做到承上启下————比如第二问的定日镜同心圆分布直接引出第三问的建模思路。# 摘要 优点都比较普遍。</p><p>摘录一段体现题解之间逻辑性的句子： - 相较于问题二，问题三中各个定日镜的尺寸和安装高度并不统一，决策变量的数量进一步增多，为了简化模型，我们参考问题二中求得的结论，认为在问题三中定日镜仍按照同心圆的方式进行排布……</p><h2 id="关键词">关键词</h2><p>光学效率 蒙特卡洛算法 单目标优化 遗传算法 年平均输出热功率 # 问题重述# 模型假设 # 符号说明 # 问题分析 # 模型的建立与求解 ##问题一模型的建立与求解 又重复说了一遍问题分析的部分+流程图 ###定日镜场年平均输出热功率模型 写上名词解释</p><ul><li>法向量-&gt;定日镜的俯仰角和方位角</li><li>阴影遮蔽效率：塔与集热器；定日镜之间：入射和反射</li></ul><h4 id="阴影遮蔽计算">阴影遮蔽计算</h4><p>由镜面坐标系转化为镜场坐标系，再从地面坐标系转换成定日镜所在平面镜的坐标系，即可计算。</p><p>离散化处理定日镜 A #### 集热器截断效率 - 锥形光束中入射光线的单位向量- 锥形光束中反射光线的直线方程 - 集热器接收范围Dr所在的平面方程 -判断集热器是否接收反射光线 - 计算截断效率 ### 模型的求解 蒙特卡罗求解### 结果分析 #### 月平均 考虑到定日镜与吸热塔的距离等因素 ####不同定光镜年平均 从内到外层趋势描述；同一层描述</p><ul><li>通过分析上图18，我们发现对于最内层的定日镜而言，其平均光学效率的分布近似于正弦分布，且位于北方的定日镜光学效率整体较高，在序号15处即在正北方向处达到最大。而在东西方向上，平均光学效率呈对称分布，对整体光学效率的影响相互抵消。我们由此推测，如果需要对定日镜的分布进行优化，应将定日镜尽可能摆放在吸热塔的北方。</li><li>为了进一步验证该结论，我们选取了春分日 3 月 21 日上午 10点时，所有定日镜的年平均光学效率在地面二维坐标系上的分布情况，如下图。</li></ul><h4 id="灵敏性分析">灵敏性分析</h4><h2 id="问题二模型的建立与求解">问题二模型的建立与求解</h2><p>单目标规划</p><h3 id="规划变量与约束条件">规划变量与约束条件</h3><ul><li>吸收塔的位置坐标通过可视化东西方向平移和南北方向平移来给出坐标约束条件</li><li>定日镜尺寸</li><li>定日镜安装高度</li><li>定日镜个数</li><li>定日镜位置</li><li>额定年平均输出热功率 ### 求解 遗传算法 ### 结果分析太精彩了，完美的承上启下。这分点思路以及可视化比A127好多了。 ####对定日镜分布的分析 #### 对月平均光学效率的分析 大致重复第一问的分析 ####对不同定日镜的年平均光学效率的分析 ####年均光学效率及输出功率相较于第一问的优化率 ## 问题三模型的建立与求解思路基本同前，扩充了部分约束条件</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数模のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUMCM2023-C228</title>
      <link href="/2024/08/05/%E6%95%B0%E6%A8%A1/2023C228/"/>
      <url>/2024/08/05/%E6%95%B0%E6%A8%A1/2023C228/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="题目类型与评价">题目类型与评价</h1><p>商品价格预测与优化问题</p><p>本篇论文语言犀利且自成一派；有很多创新的切入点：比如以需求弹性代替传统的斯皮尔曼相关性分析；相关经济学说辞值得积累。</p><p>同时LSTM和多目标遗传算法的代码也值得积累。 # 摘要关键词：ACF自相关函数，FP-Growt 关联度分析，LSTM 模型VIKOR评价，NSGAII算法</p><h1 id="数据预处理">数据预处理</h1><p>可能是史上最佳数据预处理之一。有理有据，细致入微。所有C题的数据处理都可以学习模仿。</p><p>甚至还为数据预处理部分画了个一览图。 ## 数据整合 ## 数据分析 ##异常值处理 ## 无关值处理 # 问题一的模型建立与求解 ## 问题聚焦将分布规律问题拆解为时间的基于分布规律与基于销售的分布规律；基于时间的分析又分为销售总量、各品类、单品。## 时间分布规律 作图分析、周期性判定(ACF)、时间序列分解。</p><p>对于销售总量又分为年总量，周总量，日总量，结合实际情况充分解释规律。## 各品类分布规律 结合需求弹性叙述： -对于常见食用单品，作为生活刚需，需求弹性往往较低，但是对药用类以及礼品类商品，需求弹性往往较高，顾客购买量往往随外部因素影响变化较大。## 各单品销量分布规律 前面将单品分成三类，在此部分的解释性上极其优越。## 销量分布规律 从销量占比和销售模式方面分析</p><p>不仅比较各种类的占比(饼状图),还比较了高销售额的占比，长尾效应。</p><h2 id="相互关系">相互关系</h2><p><strong>时间序列问题相关性分析</strong>模版：</p><p>由于各品类销售量的数据为时间序列，直接进行相关性计算容易受时间上的宏观因素影响，并不能判断两种单品之间销量的关系。因此本文选择偏相关性分析确定两种品类之间的相互关系。### 偏相关性分析模型 ### FP-Growth 关联分析模型 ### 相互关系的探究结果 -品种之间：偏相关性分析模型 - 单品之间：FP-Growth 关联分析模型</p><h1 id="问题二的模型建立与求解">问题二的模型建立与求解</h1><p><strong>由于题中所给的三年销量为时间序列数据，其变化随时间、社会经济等因素变化程度十分明显，直接对销量与定价的关系进行相关性分析难以得出正确的结论。</strong></p><p>转而分析价格弹性</p><h2 id="lstm">LSTM</h2><p>此模型超参数和代码可以直接保存。备用。</p><p>得到结果并做统计分析。 - 观察上表发现各品类的进价预测效果 R 方达到0.75 以上；同时 RMSE 与 MAE的值相对于预测结果小一个数量级，因此本文认为该模型结果较好。 -观察上表发现进价预测效果 R 方达到 0.6 以上，最高达到 0.96 较为接近1；同时RMSE 与 MAE的值相对于预测结果小一个数量级，因此本文认为该模型结果较好。</p><h2 id="商超补货与定价策略研究">商超补货与定价策略研究</h2><h3 id="修正函数">修正函数</h3><h3 id="最优化模型确立">最优化模型确立</h3><p>确定了目标函数和约束条件 ### GBest PSO 求解模型 #问题三模型的建立与求解 ## 未来 1 天相关数据的确定删除总销量小的单品；加权平均得到预测值；VIKOR方法对需求度进行评价，删除后五位需求度单品。-由于单品在短时间内的销量与成本的变化无明显趋势，且无明显的变化规律，数据波动呈现随机性的特征，因此本问直接通过加权平均作为各单品在7 月 1 日的销量与成本预测结果。 ## 商超补货与定价策略研究双优化目标的决策模型建立</p><p>多目标遗传算法(代码也可以直接保存，适合多目标优化问题套用)</p><h2 id="问题四">问题四</h2><p>语文建模</p><p>商品定价类问题可以参考表述</p><h2 id="模型鲁棒性检验">模型鲁棒性检验</h2><p>对LSTM模型进行鲁棒性检验</p><h2 id="lstm代码">LSTM代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3 LSTM 预测模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4 &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">6</span> <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="number">7</span> <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="number">8</span> <span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line"><span class="number">9</span> <span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM, Dense</span><br><span class="line"></span><br><span class="line"><span class="number">10</span> <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="number">11</span> <span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, mean_absolute_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="number">12</span> <span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"></span><br><span class="line"><span class="number">13</span> <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="number">14</span> plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">15</span> plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="number">17</span> file_path = <span class="string">&quot;./out/result.csv&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="number">18</span> df = pd.read_csv(file_path)</span><br><span class="line"></span><br><span class="line"><span class="number">19</span> <span class="built_in">print</span>(df.head(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">20</span> df[<span class="string">&#x27;销售日期&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;销售日期&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="number">21</span> df.set_index(<span class="string">&#x27;销售日期&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">22</span> list_test = [<span class="string">&#x27;花叶类&#x27;</span>, <span class="string">&#x27;花菜类&#x27;</span>, <span class="string">&#x27;水生根茎类&#x27;</span>, <span class="string">&#x27;茄类&#x27;</span>, <span class="string">&#x27;辣椒类&#x27;</span>, <span class="string">&#x27;食用菌&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">23</span></span><br><span class="line"><span class="number">24</span> i = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="number">25</span> <span class="built_in">print</span>(i)</span><br><span class="line"></span><br><span class="line"><span class="number">26</span> df = df[df[<span class="string">&#x27;品类&#x27;</span>] == list_test[i]]</span><br><span class="line"></span><br><span class="line"><span class="number">27</span> <span class="comment"># 数据归一化</span></span><br><span class="line"></span><br><span class="line"><span class="number">28</span> scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">29</span> scaled_data = scaler.fit_transform(df[<span class="string">&#x27;批发价格 (元/千克)&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">30</span> train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(scaled_data) * <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">31</span> train = scaled_data[<span class="number">0</span>:train_size, :]</span><br><span class="line"></span><br><span class="line"><span class="number">32</span></span><br><span class="line"><span class="number">33</span> <span class="comment"># 转换数据格式为符合 LSTM 输入要求</span></span><br><span class="line"></span><br><span class="line"><span class="number">34</span> <span class="keyword">def</span> <span class="title function_">create_dataset</span>(<span class="params">dataset, look_back=<span class="number">1</span></span>):</span><br><span class="line"></span><br><span class="line"><span class="number">35</span> dataX, dataY = [], []</span><br><span class="line"></span><br><span class="line"><span class="number">36</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset) - look_back - <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line"><span class="number">51</span></span><br><span class="line"><span class="number">37</span> a = dataset[i:(i + look_back), <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">38</span> dataX.append(a)</span><br><span class="line"></span><br><span class="line"><span class="number">39</span> dataY.append(dataset[i + look_back, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="number">40</span> <span class="keyword">return</span> np.array(dataX), np.array(dataY)</span><br><span class="line"></span><br><span class="line"><span class="number">41</span></span><br><span class="line"><span class="number">42</span></span><br><span class="line"><span class="number">43</span> look_back = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="number">44</span> trainX, trainY = create_dataset(train, look_back)</span><br><span class="line"></span><br><span class="line"><span class="number">45</span> pre_X = train[-<span class="number">30</span>:]</span><br><span class="line"></span><br><span class="line"><span class="number">46</span> pre_X = [item <span class="keyword">for</span> sublist <span class="keyword">in</span> pre_X <span class="keyword">for</span> item <span class="keyword">in</span> sublist]</span><br><span class="line"></span><br><span class="line"><span class="number">47</span> pre_X = np.array([[pre_X]])</span><br><span class="line"></span><br><span class="line"><span class="number">48</span> trainX = np.reshape(trainX, (trainX.shape[<span class="number">0</span>], <span class="number">1</span>, trainX.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="number">49</span></span><br><span class="line"><span class="number">50</span> <span class="comment"># 构建 LSTM 模型</span></span><br><span class="line"></span><br><span class="line"><span class="number">51</span> model = Sequential()</span><br><span class="line"></span><br><span class="line"><span class="number">52</span> model.add(LSTM(<span class="number">6</span>, input_shape=(<span class="number">1</span>, look_back)))</span><br><span class="line"></span><br><span class="line"><span class="number">53</span> model.add(Dense(<span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">54</span> model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">55</span> history = model.fit(trainX, trainY, epochs=<span class="number">50</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">56</span></span><br><span class="line"><span class="number">57</span> trainPredict = model.predict(trainX)</span><br><span class="line"></span><br><span class="line"><span class="number">58</span> trainPredict = scaler.inverse_transform(trainPredict)</span><br><span class="line"></span><br><span class="line"><span class="number">59</span> trainY = scaler.inverse_transform([trainY])</span><br><span class="line"></span><br><span class="line"><span class="number">60</span></span><br><span class="line"><span class="number">61</span> pre_Y = model.predict(pre_X)</span><br><span class="line"></span><br><span class="line"><span class="number">62</span> pre_Y = scaler.inverse_transform(pre_Y)</span><br><span class="line"></span><br><span class="line"><span class="number">63</span></span><br><span class="line"><span class="number">64</span> <span class="comment"># 计算 R 方、MSE、RMSE 和 MAE</span></span><br><span class="line"></span><br><span class="line"><span class="number">65</span> mse = mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="number">66</span> rmse = sqrt(mse)</span><br><span class="line"></span><br><span class="line"><span class="number">67</span> mae = mean_absolute_error(trainY[<span class="number">0</span>], trainPredict[:, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="number">68</span> r2 = r2_score(trainY[<span class="number">0</span>], trainPredict[:, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="number">69</span> <span class="built_in">print</span>(<span class="string">f&#x27;R2: <span class="subst">&#123;r2&#125;</span>, MSE: <span class="subst">&#123;mse&#125;</span>, RMSE: <span class="subst">&#123;rmse&#125;</span>, MAE: <span class="subst">&#123;mae&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">70</span></span><br><span class="line"><span class="number">71</span> <span class="built_in">print</span>(<span class="string">f&quot; 预测未来七天<span class="subst">&#123;list_test[i]&#125;</span>的销量：<span class="subst">&#123;pre_Y[<span class="number">0</span>, :]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">72</span></span><br><span class="line"><span class="number">73</span> <span class="comment"># 创建一个 figure 和 axes 对象</span></span><br><span class="line"></span><br><span class="line"><span class="number">74</span> fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">75</span> ax.plot(trainY[<span class="number">0</span>], label=<span class="string">f&#x27;<span class="subst">&#123;list_test[i]&#125;</span> 实际进价&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">76</span> ax.plot(trainPredict[:, <span class="number">0</span>], label=<span class="string">f&#x27;<span class="subst">&#123;list_test[i]&#125;</span> 实际进价&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">77</span> ax.set_xlabel(<span class="string">&#x27;Time&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">78</span> ax.set_ylabel(<span class="string">&#x27;Value&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">79</span> ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="number">80</span> ax.set_title(<span class="string">f&#x27;<span class="subst">&#123;list_test[i]&#125;</span> LSTM 预测结果图&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">81</span> ax.grid()</span><br><span class="line"></span><br><span class="line"><span class="number">82</span> beautiful(ax)</span><br><span class="line"></span><br><span class="line"><span class="number">52</span></span><br><span class="line"><span class="number">83</span> fig.savefig(<span class="string">f&quot;./rst2/<span class="subst">&#123;list_test[i]&#125;</span>Loss.png&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">84</span> fig.show()</span><br><span class="line"></span><br><span class="line"><span class="number">85</span></span><br><span class="line"><span class="number">86</span> <span class="comment"># 创建一个新的 figure 和 axes 对象</span></span><br><span class="line"></span><br><span class="line"><span class="number">87</span> fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="number">88</span> loss_history = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="number">89</span> ax.plot(loss_history, label=<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">90</span> ax.set_xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">91</span> ax.set_ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">92</span> ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="number">93</span> ax.set_title(<span class="string">&#x27;Loss Over Training Epochs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">94</span> ax.grid()</span><br><span class="line"></span><br><span class="line"><span class="number">95</span> beautiful(ax)</span><br><span class="line"></span><br><span class="line"><span class="number">96</span> fig.savefig(<span class="string">f&quot;./rst2/<span class="subst">&#123;list_test[i]&#125;</span>LSTM 预测结果图.png&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="number">97</span> fig.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数模のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUMCM2023-B226</title>
      <link href="/2024/08/04/%E6%95%B0%E6%A8%A1/2023B226/"/>
      <url>/2024/08/04/%E6%95%B0%E6%A8%A1/2023B226/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="题目类型与评价">题目类型与评价</h1><p>几何建模。画图和写公式，对论文手来说是个挑战</p><p>值得学习的点:</p><ul><li>公式和图画的很完整，比B311要好很多</li><li>贪心算法和模拟退火对比分析</li><li>测线可视化后的解释性极强 # 摘要</li><li>针对问题后面，先“对于……”以明确问题</li><li>每问之间有“参考第（）问”体现每问之间的解题逻辑连续性</li><li><strong>加重</strong>标出使用的方法与模型，以及求得的数据 ## 关键词多波束测线布设、目标优化模型、最小二乘法、贪心算法、模拟退火仿真 #问题重述 # 问题分析模型算法加重标出，用“即可得到……”表示问题解决；不写结果与讨论 ##问题一的分析建系，几何关系，先得到海水深度、覆盖宽度和重叠率的表达式，再带入参数得到结果## 问题二的分析 由问题一的模型，…… ## 问题三的分析从测线方向和测线间距两个方面考虑；单目标优化，先考虑边界的覆盖情况，然后基于贪心算法逐步优化求解第二、第三条测线；最后模拟退火仿真## 问题四的分析为保证测量的完整性和效率，测线扫描形成的条带要尽量覆盖整片海域；相邻条带重叠率在 20%以下为宜；测线长度应尽量短。</li></ul><p>根据等深线对海域进行划分；最小二乘法确定坡面方程 # 模型假设从探测船和声波的角度去考虑 # 符号说明 # 模型的建立与求解 ## 问题一 ###原理说明 ### 三维空间直角坐标系的建立以海域中心点为坐标原点O，以测量船的行驶方向（测 线方向）为 x轴，以测线间距的分布方向为 y 轴，以海水深度方向为 z 轴，建立三维空间直角坐标系O(x, y,z)如下，问题一建模都在此坐标系中进行。 ### 计算#### 海水深度 相似三角形，其实就是三角函数 #### 覆盖度正弦定理，自己推了一下没问题，所以先求出海水深度是必要的。 #### 重叠率三角形AGF和CG'I相似也可以推出来 ### 带入数据求解 结果分析 -海水深度：增大和减小的趋势，幅度 -覆盖宽度：分析重叠率的分布，大于小于0；对效率的进行评价 ###控制变量法研究角度，间距对覆盖率和重叠率的影响可视化。适合复杂物理方程的(填表)题目 ## 问题二三维空间两个面的交线方程求法：法向量叉乘，得到点向式方程</p><p>求出AB向量，得航线与海底夹角————化归为第一问</p><p>在结合第一问得出覆盖宽度 ## 问题三 ###证明测线平行等深线方向是最佳方向 面积计算比较 ###基于单目标优化确定测线位置 目标函数：希望测线总长度最短；min nl</p><p>约束条件： -全覆盖可以理解为所有测线的覆盖宽度之和大于等于该海域东西宽度，由于相邻条带之间有重叠，重叠部分需要减去- 重叠率要求 ### 求解 #### 贪心算法 流程图；结果填表；测线分布图</p><p>并分析测线分布，同时结合问题一的背景 #### 模拟退火 模拟退火的步骤</p><p>得到结果，并和贪心的结果进行对比(绝对误差，相对误差)</p><h3 id="开角坡度的灵敏度分析">开角、坡度的灵敏度分析</h3><h2 id="问题四">问题四</h2><h3 id="可视化">可视化</h3><p>先说明划分原因：若采用该海 域的平均水深，在海水深度较小处会出现漏测现象，降低探测质量；在海水深度较大处会导致相邻条带之间重叠率过大，降低探测效率。为了尽可能地覆盖整个待测海域，且测量效率较高，选择合理的测线 间隔至关重要</p><h3 id="确定坡面方程">确定坡面方程</h3><p>最小二乘法 ### 单目标优化 以测线的总长度最小为优化目标 ###求解最佳测线布设方案 #### 各划分区域坡面方程的确定 流程图</p><p>并没有说明求得到方程结果 #### 确定最优测线布设对矩形区域进行再划分</p><p>求解并可视化测线分布，分析测线密度与地形的关系</p><h1 id="模型评价">模型评价</h1><h1 id="参考文献">参考文献</h1><ul><li>[9] 姜启源 谢金星 叶俊. 数学模型[M]. 4 版. 北京：高等教育出版社.2011 1.</li><li>[10]司守奎 孙兆亮. 数学建模算法与应用[M]. 2 版.北京：国防工业出版社. 2017 几乎是必引</li></ul><h2 id="支撑材料">支撑材料</h2><p>先展示源代码的目录(名字)和数据</p><p>代码要说明是用来求什么的</p>]]></content>
      
      
      <categories>
          
          <category> 数模のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数值分析-矩阵LU分解</title>
      <link href="/2024/08/02/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/LU/"/>
      <url>/2024/08/02/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90/LU/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="问题引入">问题引入</h1><p>求解：Ax=b</p><p>其中A为矩阵，x和b均为向量。 # LU引入 - Ly=b - Ux=y即A=LU，通过求解LU即可求得x和b。 # 求解 A=LU <span class="math display">\[A = \begin{bmatrix}a_{11} &amp; a_{12} &amp; a_{13}&amp;……&amp;a_{1n} \\a_{21} &amp; a_{22} &amp; a_{23}&amp;……&amp;a_{2n} \\a_{31} &amp; a_{32} &amp; a_{33}&amp;……&amp;a_{3n} \\……\\a_{n1}&amp;a_{n2}&amp;a_{n3}&amp;……&amp;a_{nn}\end{bmatrix}\]</span></p><p>设矩阵 (A) 的 LU 分解为 (A = LU)，其中： <span class="math display">\[L = \begin{bmatrix}1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\l_{21} &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\l_{31} &amp; l_{32} &amp; 1 &amp; \cdots &amp; 0 \\\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\l_{n1} &amp; l_{n2} &amp; l_{n3} &amp; \cdots &amp; 1\end{bmatrix},\quadU = \begin{bmatrix}u_{11} &amp; u_{12} &amp; u_{13} &amp; \cdots &amp; u_{1n} \\0 &amp; u_{22} &amp; u_{23} &amp; \cdots &amp; u_{2n} \\0 &amp; 0 &amp; u_{33} &amp; \cdots &amp; u_{3n} \\\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\0 &amp; 0 &amp; 0 &amp; \cdots &amp; u_{nn}\end{bmatrix}\]</span></p><p>其中U的第一行和A的第一行相等，L的第一列等于A的第一列除以u11(也就是a11)依次求出L和U。随后便可求出y和x</p>]]></content>
      
      
      <categories>
          
          <category> 修考のFantasia </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性代数 </tag>
            
            <tag> 数值分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUMCM2021-B007</title>
      <link href="/2024/08/02/%E6%95%B0%E6%A8%A1/2021B007/"/>
      <url>/2024/08/02/%E6%95%B0%E6%A8%A1/2021B007/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="题目类型与评价">题目类型与评价</h1><p>多因素回归分析的典范。</p><p>值得学习的点： - 多元回归模型和偏最小二乘回归分析的对比建模 -方差分析并加入交互项提升对某因素的敏感度 - 均匀设计结合实际 # 摘要论文的摘要部分对关键词进行了加重，突出了使用的模型方法与其作用意义；每个问题分段，但每问之间的叙述有逻辑性。## 关键词 多元回归模型，偏最小二乘回归分析，最优化，方差分析，均匀设计## 摘录 - 引入方差分析探究多自变量之间的<strong>交互作用</strong> #问题提出 ## 背景分析 ## 问题重述 # 问题分析每一小问在重复问题的基础上分小标题阐述 ## 问题一：关系分析类问题，首先皮尔逊相关性分析，然后绘制折线图，同时非线性和线性拟合，确定函数关系(二次函数)；第二部分确定两个指标为与时间有关的变量，同时对无关产物聚类。## 问题二：对不同组合催化剂、温度、以及生成物的比率设置赋予变量值，进行多元线性回归；为了验证因变量之间也存在影响，进行偏最小二乘的回归分析。对比选择回归方程。### 摘录 - 得到的回归方程就可以作为〇〇对指标的量化分析。 ## 问题三：根据C4烯烃的计算式，因约束条件不充分，无法求解最优值；对多自变量进行方差分析，得到了温度与Co负载量以及乙醇浓度的组合交互时对因变量也产生一定的影响。将其作为注意力自变量加入自变量中，SPSS拟合。## 问题四：均匀设计实验法。依据问题二剔除相关性低的自变量，根据安全原则剔除危险组合，<strong>并以问题三的最后结果代替</strong># 模型假设 # 符号说明 # 模型建立 ## 问题一的求解与分析简要说明解题逻辑和使用方法，可以不写出数据与分析结果。 ### 数据预处理分类；然后给出代表性的图片；写出分类依据 ### 问题一(1)的模型建立与求解首先画出流程图。 #### 相关性分析本文首先通过计算皮尔逊相关系数，求得……</p><p>公式要标出x和y在题目中的含义。</p><p>21组数据中有19组的Pearson相关系数大于0.9，……，极强相关性。</p><p>列表说明 #### 非线性回归强相关性+正相关趋势，所以采用非线性回归方式拟合。分别利用<em>线性方程，S型曲线，二次曲线</em>进行你和，以催化剂分组，得到21张拟合图像</p><p>展示两幅并说明R方相差不大 #### 相关性检验 对比选择R方较大者 ###问题一(2)的模型建立与求解 #### 数据预处理考虑到变量冗余，可以将相关性高的分为一类，对……进行降维处理。</p><p>分析系谱图可以发现，我们可以将……作为次要附加产物，将……作为主要附加产物，从而实现数据的降维。因此在……中，我们只需要考虑两类生成物对……的影响即可</p><p>可视化时间对乙醇转化率，C4烯烃选择性，主要附加产物，次要附加产物，收率影响。并分析趋势。</p><p>SPSS拟合并分析 ## 问题二的求解与分析 流程图(这个图画的好好) ###数据预处理 将装料比拆分为两个质量，得到5个自变量。</p><p>说明并舍弃石英砂这组变量。</p><p>列表说明因变量和自变量的选择。 ### 模型建立和误差分析对两个指标分别进行方差齐次检验，列表说明。均大于0.05即认为是其次的。因此进一步进行单因素方差分析，得到单因素方差分析表：</p><p>主体间效应检验</p><p>说明各自变量贡献……因此我们可以进行回归分析模型的建立。 ###建立多元回归模型 方程说明，偏回归系数……，与x1……无相关性，随机误差项。#### 求解回归系数分析 #### 误差分析 0.796和0.709的R方可以算好的了？</p><p>残差统计表，并画出P-P图</p><p>由表……的残差分布图，残差最大值均在25左右，且标准化残差都集中分布在直线附近，可以认为标准化残差满足正态分布，误差通过，建立的回归方程合理且误差较小。### 偏最小二乘法回归模型（主成分分析？上文利用……分别建立了……的多元线性回归模型，而在……背景下的多因变量问题中，因变量之间很有可能产生相互影响，针对本题……的因变量，我们通过偏最小二乘法来改进原有的分析方法，探究多因变量的分析，在原有的基础上探究因变量之间是否存在影响。</p><h3 id="数据标准化">数据标准化</h3><h3 id="求相关系数矩阵">求相关系数矩阵</h3><p>列出矩阵，并解释分析 ## 模型解释 预测图和直方图</p><p>对各个变量的解释能力进行说明 ## 问题三的求解与分析为了……(题目重述)我们首先根据化学反应得出直接因素，又基于问题二的结论得出自变量之间的影响关系，建立单目标优化模型；对多个自变量进行方差分析，对原有模型进行改进从而在两种温度条件下进行全局最优的求解，以获得……</p><p>流程图</p><h3 id="模型建立">模型建立</h3><h4 id="数据处理">数据处理</h4><p>对109组C4烯烃收率进行排序，确定阈值为1%，筛选；对一些效果不佳的数据进行剔除#### 约束条件的确立 自变量x的左右区间 #### 基于多元线性回归的模型优化参照问题二，SPSS对收率进行数据拟合</p><p>R方大于0.7，很高！</p><p>求解。 #### 优化机理分析(<strong>重点</strong>)根据问题二的方差分析，得知交互项的作用。将交互作用部分作为相互作用因子，令……x6，x7，x8，再用SPSS拟合(目的为增强温度的影响)</p><p>Case1：在相同实验条件下……</p><p>Case2：在温度限制的条件下…… ## 问题四的求解与分析为了(实验目的),本文在实验设计时选择均匀设计的方法。</p><p>相比于正交设计，均匀设计……</p><p>参考前面的问题，将回归系数接近0的自变量x4删除，在设计时着重研究其他4种自变量与C4烯烃收率的关系。</p><p>选取五种因素水平，观察各自变量的系数，系数大的步进小(温度),系数小的步进大。</p><p>删除最高水平组，防止化学反应过于剧烈，改为问题三的结果(注意与前实验重复的数据要对调)</p><h2 id="灵敏度分析">灵敏度分析</h2><h2 id="模型的评价与推广">模型的评价与推广</h2><h3 id="优点">优点</h3><ul><li>方差分析将有助于探究自变量之间的相互作用，从而探究更深层次自变量之间的联系，以此将存在相互作用关系的每一组变量存为新的一个变量，反过来作为多元函数中的一员，提供更好的拟合效果。</li><li>偏最小二乘法和多元线性回归两者相结合进行对比分析，可以探究多个因变量之间是否存在着更深层次的联系，更有利于……的数据拟合，使其得到更为准确的拟合方程，探究实验物之间的联系，对实验结果进行预测。### 缺点</li><li>基于多元线性回归于方差分析的……模型中，各个组成部分的权重的确定仍然是按照变量贡献率特点进行分析，并无一个完整的体系，含有一定的主观性。</li><li>在聚类分析时，只是单纯的量化考虑了数值上的聚类，而忽略了…… ###推广</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数模のSymphony </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数模 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pre in Cambridge</title>
      <link href="/2024/07/25/pre_cambridge/"/>
      <url>/2024/07/25/pre_cambridge/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> esm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义位置编码类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-torch.log(torch.tensor(<span class="number">10000.0</span>)) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        pe = self.pe[:x.size(<span class="number">0</span>), :].to(x.device)  <span class="comment"># 确保位置编码在同一设备上</span></span><br><span class="line">        x = x + pe</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment"># 定义一个Transformer模型，包括自注意力层和FFN层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProteinTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model=<span class="number">1280</span>, nhead=<span class="number">4</span>, num_encoder_layers=<span class="number">1</span>, dim_feedforward=<span class="number">5120</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ProteinTransformer, self).__init__()</span><br><span class="line">        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward)</span><br><span class="line">        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src</span>):</span><br><span class="line">        output = self.transformer_encoder(src)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_esm1b_model</span>():</span><br><span class="line">    model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()</span><br><span class="line">    <span class="keyword">return</span> model, alphabet</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_embeddings</span>(<span class="params">sequence, model, alphabet, device</span>):</span><br><span class="line">    batch_converter = alphabet.get_batch_converter()</span><br><span class="line">    data = [(<span class="string">&quot;protein1&quot;</span>, sequence)]</span><br><span class="line">    _, _, batch_tokens = batch_converter(data)</span><br><span class="line">    batch_tokens = batch_tokens.to(device)  <span class="comment"># 确保batch_tokens在同一设备上</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        results = model(batch_tokens, repr_layers=[<span class="number">33</span>], return_contacts=<span class="literal">False</span>)</span><br><span class="line">    token_representations = results[<span class="string">&quot;representations&quot;</span>][<span class="number">33</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 去掉batch维度，只保留原始序列长度的嵌入</span></span><br><span class="line">    embedding = token_representations.squeeze(<span class="number">0</span>)</span><br><span class="line">    original_length = <span class="built_in">len</span>(sequence)</span><br><span class="line">    embedding = embedding[:original_length, :]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> embedding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    esm_model, alphabet = load_esm1b_model()</span><br><span class="line">    esm_model = esm_model.to(device)  <span class="comment"># 将模型移动到同一设备上</span></span><br><span class="line">    sequence = <span class="string">&quot;MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAKLFAIK&quot;</span><span class="comment"># 输入蛋白质序列</span></span><br><span class="line">    embeddings = extract_embeddings(sequence, esm_model, alphabet, device).to(device)    <span class="comment"># 从ESM-1b模型提取嵌入</span></span><br><span class="line">    pos_encoder = PositionalEncoding(d_model=embeddings.size(<span class="number">1</span>), max_len=embeddings.size(<span class="number">0</span>)).to(device)    <span class="comment"># 初始化位置编码</span></span><br><span class="line">    embeddings_with_pos = pos_encoder(embeddings.unsqueeze(<span class="number">1</span>))   <span class="comment"># 应用位置编码</span></span><br><span class="line">    transformer_model = ProteinTransformer().to(device)<span class="comment"># 初始化Transformer模型</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        transformed_embeddings = transformer_model(embeddings_with_pos)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Transformed Embedding Matrix Shape:&quot;</span>, transformed_embeddings.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Transformed Embedding Matrix:&quot;</span>, transformed_embeddings)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Transformed Embedding Matrix Shape: torch.Size([40, 1, 1280])</span><br><span class="line">Transformed Embedding Matrix: tensor([[[-0.9183,  0.8383, -0.5008,  ...,  0.8783, -0.6543,  0.4944]],</span><br><span class="line"></span><br><span class="line">        [[ 0.3480, -1.0895,  0.5983,  ...,  0.7502, -0.7020,  0.1589]],</span><br><span class="line"></span><br><span class="line">        [[ 0.5885, -2.2407,  0.2032,  ...,  0.7158, -0.7832,  0.8766]],</span><br><span class="line"></span><br><span class="line">        ...,</span><br><span class="line"></span><br><span class="line">        [[-0.8607,  0.1170, -1.3206,  ...,  0.8361, -0.3275,  0.9041]],</span><br><span class="line"></span><br><span class="line">        [[-0.1696,  0.6289, -0.8771,  ...,  1.0834, -0.2475,  0.9045]],</span><br><span class="line"></span><br><span class="line">        [[ 0.6635, -0.5849,  0.3174,  ...,  0.9572, -0.4215,  1.1555]]],</span><br><span class="line">       device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣-136</title>
      <link href="/2024/07/25/lc/leetcode_136/"/>
      <url>/2024/07/25/lc/leetcode_136/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        ls=[]</span><br><span class="line">        x=<span class="number">0</span></span><br><span class="line">        counter=defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            counter[num] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> counter[num]&gt;<span class="number">1</span>:</span><br><span class="line">                ls.append(num)      </span><br><span class="line">        nls= <span class="built_in">list</span>(<span class="built_in">set</span>(nums)-<span class="built_in">set</span>(ls))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> nls:</span><br><span class="line">            x=i</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>题解：<strong>异或运算</strong> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        x = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:  <span class="comment"># 1. 遍历 nums 执行异或运算</span></span><br><span class="line">            x ^= num      </span><br><span class="line">        <span class="keyword">return</span> x;         <span class="comment"># 2. 返回出现一次的数字 x</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 力扣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>流畅的Python(一)</title>
      <link href="/2024/07/09/fluent_1/"/>
      <url>/2024/07/09/fluent_1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>参考资料： <a href="https://zh.z-lib.gs/book/5007162/9b61f2/%E6%B5%81%E7%95%85%E7%9A%84python-fluent-python-clear-concise-and-effective-programming.html">book</a><a href="https://www.bilibili.com/video/BV1Me4y157cB?vd_source=1a36db16e3fec3ccbe040303ff015aab">video</a>### 列表推导 生成一个循环列表 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br></pre></td></tr></table></figure></p><p>生成一个双循环列表 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a=[(i,j) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">list</span>(<span class="string">&#x27;ABCD&#x27;</span>)]</span><br><span class="line">等价于</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">list</span>(<span class="string">&#x27;ABCD&#x27;</span>):</span><br><span class="line">        a.append((i,j))</span><br></pre></td></tr></table></figure> 生成(0,2,4,6,8) <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=[i*<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br></pre></td></tr></table></figure>替代filter筛选循环 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>) <span class="keyword">if</span> i &lt; <span class="number">3</span>]</span><br></pre></td></tr></table></figure> ### 生成器表达式 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gen</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">yield</span> n</span><br><span class="line">    <span class="keyword">yield</span> n+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">g=gen(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> g:</span><br><span class="line">    <span class="built_in">print</span>(g)</span><br><span class="line"></span><br><span class="line">每调用一次gen函数，依次得到一个<span class="keyword">yield</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">生成器表达式</span><br><span class="line">g = (i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#只是生成了一个生成器，内存大小不随range改变，只有当调用个时才会生产yield</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> g:</span><br><span class="line">    <span class="built_in">print</span>(g)</span><br><span class="line"></span><br></pre></td></tr></table></figure> ### 解包和拆包 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = (<span class="number">20</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">a1,a2=a——标准的元组解包</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">divmod</span>(*a))<span class="comment">#省去显示拆包</span></span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a1,*rest=<span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>)</span><br><span class="line"><span class="comment">#a1为第一个元素，剩下的放在rest里面，为列表</span></span><br><span class="line">a1,*rest,a2=<span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>)</span><br><span class="line"><span class="comment">#a1,a2单独，剩下的放rest列表</span></span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">嵌套解包</span><br><span class="line">city=[(<span class="string">&#x27;Hangzhou&#x27;</span>,<span class="string">&#x27;Zhejiang&#x27;</span>,(<span class="string">&#x27;0571&#x27;</span>,<span class="string">&#x27;310000&#x27;</span>)),(<span class="string">&#x27;Guangdong&#x27;</span>,<span class="string">&#x27;Guangzhou&#x27;</span>,(<span class="string">&#x27;0755&#x27;</span>,<span class="string">&#x27;210000&#x27;</span>))]</span><br><span class="line"><span class="keyword">for</span> name,prov,(code,postcode) <span class="keyword">in</span> city:</span><br><span class="line">    <span class="built_in">print</span>(postcode)</span><br></pre></td></tr></table></figure>### 序列的增量赋值 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line">b=<span class="built_in">range</span>(<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line">a=a+b</span><br><span class="line">&gt;&gt;&gt;返回的<span class="built_in">list</span>为新地址，和原本a的不一样</span><br><span class="line"></span><br><span class="line">a+=b</span><br><span class="line">&gt;&gt;&gt;返回的<span class="built_in">list</span>为原来的旧地址，和原本a一样</span><br><span class="line"></span><br></pre></td></tr></table></figure>若a和b都为元组，则无论是+=还是+都是新地址，因为元组本身就是不可改变的，不能直接在指向旧地址的a后面延长。</p>]]></content>
      
      
      <categories>
          
          <category> PythonのEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣-2909</title>
      <link href="/2024/07/08/lc/leetcode_2909/"/>
      <url>/2024/07/08/lc/leetcode_2909/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>给你一个下标从 0 开始的整数数组 nums 。</p><p>如果下标三元组 (i, j, k) 满足下述全部条件，则认为它是一个 山形三元组：</p><p>i &lt; j &lt; k nums[i] &lt; nums[j] 且 nums[k] &lt; nums[j] 请你找出nums 中 元素和最小 的山形三元组，并返回其 元素和。如果不存在满足条件的三元组，返回 -1 。</p><p>示例 1：</p><p>输入：nums = [8,6,1,5,3] 输出：9 解释：三元组 (2, 3, 4)是一个元素和等于 9 的山形三元组，因为： - 2 &lt; 3 &lt; 4 - nums[2] &lt;nums[3] 且 nums[4] &lt; nums[3] 这个三元组的元素和等于 nums[2] + nums[3]+ nums[4] = 9 。可以证明不存在元素和小于 9 的山形三元组。 示例 2：</p><p>输入：nums = [5,4,8,7,10,2] 输出：13 解释：三元组 (1, 3, 5)是一个元素和等于 13 的山形三元组，因为： - 1 &lt; 3 &lt; 5 - nums[1]&lt; nums[3] 且 nums[5] &lt; nums[3] 这个三元组的元素和等于 nums[1] +nums[3] + nums[5] = 13 。可以证明不存在元素和小于 13 的山形三元组。 示例3：</p><p>输入：nums = [6,5,4,3,4,5] 输出：-1 解释：可以证明 nums中不存在山形三元组。</p><h3 id="暴力超时">暴力超时</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minimumSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        lst=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(j + <span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">                    <span class="keyword">if</span> nums[i] &lt; nums[j] <span class="keyword">and</span> nums[k] &lt; nums[j]:</span><br><span class="line">                        <span class="built_in">sum</span> = nums[i] + nums[j] + nums[k]</span><br><span class="line">                        lst.append(<span class="built_in">sum</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(lst) &gt; <span class="number">0</span>:</span><br><span class="line">            ans = <span class="built_in">min</span>(lst)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ans = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure><h3 id="枚举中间数">枚举中间数</h3><p>这种三元组的题目，通常是枚举中间的数。 枚举 nums[j]，我们需要求出 j左边所有元素的最小值和右边所有元素的最小值。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minimumSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        suf = [<span class="number">0</span>] * n</span><br><span class="line">        suf[-<span class="number">1</span>] = nums[-<span class="number">1</span>]  <span class="comment"># 后缀最小值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">2</span>, <span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            suf[i] = <span class="built_in">min</span>(suf[i + <span class="number">1</span>], nums[i])</span><br><span class="line"></span><br><span class="line">        ans = inf</span><br><span class="line">        pre = nums[<span class="number">0</span>]  <span class="comment"># 前缀最小值</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> pre &lt; nums[j] &gt; suf[j + <span class="number">1</span>]:  <span class="comment"># 山形</span></span><br><span class="line">                ans = <span class="built_in">min</span>(ans, pre + nums[j] + suf[j + <span class="number">1</span>])  <span class="comment"># 更新答案</span></span><br><span class="line">            pre = <span class="built_in">min</span>(pre, nums[j])</span><br><span class="line">        <span class="keyword">return</span> ans <span class="keyword">if</span> ans &lt; inf <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 力扣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣-283</title>
      <link href="/2024/07/08/lc/leetcode_283/"/>
      <url>/2024/07/08/lc/leetcode_283/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>给定一个数组 nums，编写一个函数将所有 0移动到数组的末尾，同时保持非零元素的相对顺序。</p><p>请注意 ，必须在不复制数组的情况下原地对数组进行操作。</p><p>示例 1:</p><p>输入: nums = [0,1,0,3,12] 输出: [1,3,12,0,0] 示例 2:</p><p>输入: nums = [0] 输出: [0]</p><p>Python和双指针都忘得差不多了w <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">moveZeroes</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        l=<span class="built_in">len</span>(nums)</span><br><span class="line">        ls=[]</span><br><span class="line">        zero=[]</span><br><span class="line">        count=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> x==<span class="number">0</span>:</span><br><span class="line">                zero.append(count)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(zero) &gt; <span class="number">0</span>:</span><br><span class="line">                j = zero[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> j&gt;=<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l):</span><br><span class="line">                <span class="keyword">if</span> nums[i] != <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> j &lt; i:</span><br><span class="line">                        a = nums[i]</span><br><span class="line">                        nums[i] = <span class="number">0</span></span><br><span class="line">                        nums[j] = a</span><br><span class="line">                        j = i</span><br><span class="line">                        ls.append(i)</span><br><span class="line">                <span class="keyword">elif</span> nums[i] == <span class="number">0</span>:</span><br><span class="line">                    ls.append(i)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(ls) &gt; <span class="number">0</span> <span class="keyword">and</span> j &gt;= ls[<span class="number">0</span>]:</span><br><span class="line">                    j = ls[<span class="number">0</span>]</span><br><span class="line">                    ls.pop(<span class="number">0</span>)</span><br><span class="line">        </span><br></pre></td></tr></table></figure>直接原地remove，但不知道为什么力扣上过不了样例，pycharm上可以。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">moveZeroes</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        cnt=<span class="number">0</span></span><br><span class="line">        ls=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">            ls.append(i)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> nums[i]==<span class="number">0</span>:</span><br><span class="line">                ls.remove(<span class="number">0</span>)</span><br><span class="line">                cnt+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cnt):</span><br><span class="line">            ls.append(<span class="number">0</span>)</span><br><span class="line">        nums=ls.copy()</span><br></pre></td></tr></table></figure></p><p>题解：被自己蠢到了w <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moveZeroes</span>(<span class="params">self, nums</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">:type nums: List[int]</span></span><br><span class="line"><span class="string">:rtype: None Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> nums:</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 第一次遍历的时候，j指针记录非0的个数，只要是非0的统统都赋给nums[j]</span></span><br><span class="line">j = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(nums)):</span><br><span class="line"><span class="keyword">if</span> nums[i]:</span><br><span class="line">nums[j] = nums[i]</span><br><span class="line">j += <span class="number">1</span></span><br><span class="line"><span class="comment"># 非0元素统计完了，剩下的都是0了</span></span><br><span class="line"><span class="comment"># 所以第二次遍历把末尾的元素都赋为0即可</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(j,<span class="built_in">len</span>(nums)):</span><br><span class="line">nums[i] = <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 力扣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>力扣-447</title>
      <link href="/2024/07/07/lc/leetcode_447/"/>
      <url>/2024/07/07/lc/leetcode_447/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>给定平面上 n 对 互不相同 的点 points ，其中 points[i] = [xi, yi]。回旋镖 是由点 (i, j, k) 表示的元组 ，其中 i 和 j 之间的欧式距离和 i 和k 之间的欧式距离相等（需要考虑元组的顺序）。</p><p>返回平面上所有回旋镖的数量。</p><p>示例 1： 输入：points = [[0,0],[1,0],[2,0]] 输出：2解释：两个回旋镖为 [[1,0],[0,0],[2,0]] 和 [1,0],[2,0],[0,0]</p><p>示例 2： 输入：points = [[1,1],[2,2],[3,3]] 输出：2</p><p>示例 3： 输入：points = [[1,1]] 输出：0 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numberOfBoomerangs</span>(<span class="params">self, points: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x1, y1 <span class="keyword">in</span> points:</span><br><span class="line">            distance_count = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">            <span class="keyword">for</span> x2, y2 <span class="keyword">in</span> points:</span><br><span class="line">                d = (x2 - x1) ** <span class="number">2</span> + (y2 - y1) ** <span class="number">2</span></span><br><span class="line">                distance_count[d] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> distance_count.values():</span><br><span class="line">                <span class="keyword">if</span> count &gt; <span class="number">1</span>:</span><br><span class="line">                    ans += count * (count - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>defaultdict()，字典</p><p>这里的defaultdict(function_factory)构建的是一个类似dictionary的对象，其中keys的值，自行确定赋值，但是values的类型，是function_factory的类实例，而且具有默认值。比如default(int)则创建一个类似dictionary对象，里面任何的values都是int的实例，而且就算是一个不存在的key,d[key] 也有一个默认值，这个默认值是int()的默认值0.</p>]]></content>
      
      
      <categories>
          
          <category> 力扣のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
            <tag> Leetcode </tag>
            
            <tag> 力扣 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构绪论</title>
      <link href="/2024/07/07/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ds_1/"/>
      <url>/2024/07/07/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ds_1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>数据结构是<strong>一门研究非数值计算的程序设计问题中的操作对象，以及它们之间的关系和操作等相关问题的学科</strong>## 基本概念 -1.数据：数据是信息的载体，是描述客观事物属性的数、字符以及所有能输入到计算机中并被程序识别和处理的符号的集合。-2.数据元素：数据元素是数据的基本单位，通常作为一个整体进行考虑和处理。一个数据元素可由若干<strong>数据项</strong>组成，数据项是构成数据元素的不可分割的最小单位。例如，学生记录就是一个数据元素，它由学号、姓名、性别等数据项组成。- 3.数据对象:数据对象是具有相同性值的数据元素的集合，是数据的一个子集。## 逻辑结构和存储结构 ### 逻辑结构 是指数据对象中数据元素之间的相互关系- 集合结构 - 线性结构 - 树形结构 - 图形结构 ### 物理结构是指数据的逻辑结构在计算机中的存储形式 -1.顺序存储结构：把逻辑上相邻的元素存储在物理位置也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现-2.链式存储结构：逻辑上相邻的元素在物理位置上可以不相邻，借助指示元素存储地址的指针来表示元素之间的逻辑关系-3.索引存储：在存储元素信息的同时，还建立附加的索引表，索引表中的每项称为索引项，索引项的一般形式是（关键字，地址）-4.散列存储：根据元素的关键字直接计算出该元素的存储地址，又称哈希（Hash）存储。## 算法的基本概念 ### 算法的特性： -有穷性：一个算法必须总在执行有穷步之后结束，且每一步都可在有穷时间内完成。-确定性：算法中每条指令必须有确定的含义，对于相同的输入只能得到相同的输出。- 可行性：算法中描述的操作都可以通过已经实现的基本运算执行有限次来实现。- 输入：一个算法有零个或多个输入，这些输入取自于某个特定的对象的集合。 -输出：一个算法有一个多个输出，这些输出是与输入有着某种特定关系的量。 ###算法设计要求 - 正确性：算法应能够正确的求接问题。 -可读性：算法应具有良好的可读性，以帮助人们理解。-健壮性：输入非法数据时，算法能适当地做出反应或进行处理，而不会产生莫名奇妙地输出结果。-效率与低存储量需求：效率是指算法执行的时间，存储量需求是指算法执行过程中所需要的最大存储空间，这两者都与问题的规模有关。## 算法的时间复杂度一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数f(n)，算法的时间量度记作T(n)=O(n)，它表示随问题规模n的增大而增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称时间复杂度。随着n的增大，T(n)增长最慢的算法为最优算法。单纯的分支结构，时间复杂度也是O(1) - 线性阶 - 平方阶 - 对数阶<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> count = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (count &lt; n);</span><br><span class="line">&#123;count = count * <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*2^x = n*/</span></span><br></pre></td></tr></table></figure> O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(<span class="math inline">\(n^{2}\)</span>)&lt;O(<span class="math inline">\(n^3\)</span>) &lt;O(<span class="math inline">\(2^n\)</span>) &lt;O(n!) &lt;O(<span class="math inline">\(n^n\)</span>)</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch深度学习实践</title>
      <link href="/2024/07/06/pytorch_dl/"/>
      <url>/2024/07/06/pytorch_dl/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="overview">1、overview</h1><h2 id="how-to-develop-learning-system">How to develop learningsystem?</h2><ul><li>基于规则的系统： 输入 -&gt; 手工设计程序 -&gt; 输出</li><li>传统机器学习 输入 -&gt; 手工设计特征 -&gt; 映射 -&gt; 输出</li><li>表示学习 特征不再手工提取</li></ul><p>深度学习: 输入-&gt;简单特征-&gt;特征提取器-&gt;映射输出 (End2End:模型可以直接利用输入数据而不需要其他处理)</p><h2 id="神经网络简史">神经网络简史</h2><h2 id="why-pytorch">Why PyTorch</h2><ul><li>Dynamical</li></ul><p>1）More flexible 2）Easy to debug 3）Intuitive and cleaner code</p><ul><li>More neural networkic</li></ul><p>Write code as network works/ AutoGrad for forward or backward.</p><h1 id="线性模型">2、线性模型</h1><p>DataSet(数据集) -&gt; Model(模型) -&gt; Training(训练) -&gt;inferring(推理)</p><h2 id="例子引入">1 例子引入</h2><p>已知数据集学习时间x[1，2，3] 成绩y[2，4，6]，测试数据集x=4,y=?</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">此时数据集分为训练数据集和测试数据集</span><br><span class="line">一般情况下为了避免过拟合，会将测试数据集的一部分作为开发（验证）数据集，用来验证模型的准确程度</span><br><span class="line"></span><br><span class="line">监督学习：有标签的数据学习，根据输入值和输出值对模型进行调整；利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的过程</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="线性模型-1">2 线性模型</h2><p>获取最优的线性模型：因为此时数据集较少采用简单的线性模型。随机选取w以后，计算损失值，然后不停调整w的值（在某个范围内穷举）使得损失值最小</p><figure><img src="https://img-blog.csdnimg.cn/226bbe04d53f4c8a9ab2157dc0e5e627.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><p>Training Loss针对一个样本</p><p>Mean Square Error（MSE平均平方误差）针对整个训练集</p><figure><img src="https://img-blog.csdnimg.cn/06e0a52f3fbe44ea831f2701cbab6e9d.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><h1 id="gradient_descent梯度下降法">3 Gradient_Descent(梯度下降法)</h1><p>利用了贪心的思想，查找当前下降最快的位置</p><p>梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，要想快速下山就要寻找最陡峭的地方。首先以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着下降方向走一步，然后又继续以当前位置为基准，再找最陡峭的地方，再走直到最后到达最低处；同理上山也是如此，只是这时候就变成梯度上升算法了</p><p>梯度下降的基本过程就和下山的场景很类似。</p><p>首先，我们有一个可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度，然后朝着梯度相反的方向，就能让函数值下降的最快！因为梯度的方向就是函数之变化最快的方向(在后面会详细解释)</p><p>所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是场景中测量方向的手段。那么为什么梯度的方向就是最陡峭的方向呢？</p><p>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率</p><p>在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向</p><p>到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，所以我们只要沿着梯度的方向一直走，就能走到局部的最低点</p><h2 id="梯度下降">梯度下降</h2><p>在线性模型中采用了穷举法，但是对于数据集较大的时候穷举不可行，因此提出梯度下降进行优化。</p><p>随机选取一个点，计算梯度，并朝着函数值下降最快的方向走，并且更新w值。</p><figure><img src="https://img-blog.csdnimg.cn/32591d19b95d4c029eeb08bcf36c9788.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><figure><img src="https://img-blog.csdnimg.cn/bdb1737314e949b0beab5dd8e6447833.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><p>代码：</p><figure><img src="https://img-blog.csdnimg.cn/9c8d679fdde249659c3ab81ecf1c34e4.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><h2 id="随机梯度下降sdg">随机梯度下降SDG</h2><p>梯度下降法遇到鞍点无法跳出，但是随机梯度下降可能会跳跃鞍点</p><p>SGD算法是从样本中随机抽出一组，训练后按梯度更新一次，然后再抽取一组，再更新一次，在样本量及其大的情况下，可能不用训练完所有的样本就可以获得一个损失值在可接受范围之内的模型了。</p><p>这里的随机是指每次迭代过程中，样本都要被随机打乱，打乱是有效减小样本之间造成的参数更新抵消问题。</p><figure><img src="https://img-blog.csdnimg.cn/bf61bc059c7246a088740f1e798de3e7.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><hr><p>对梯度下降和随机梯度下降综合一下获取更好的性能</p><p>对数据进行分组mini-batch：组内梯度下降，组间随机梯度下降</p><hr><h2 id="mini-batch">Mini batch</h2><p>为了提高效率，我们可以把样本分成等量的子集。例如我们把100万样本分成1000份， 每份1000个样本， 这些子集就称为minibatch。mini-batch的大小一般取2的n次方</p><p>然后我们分别用一个for循环遍历这1000个子集。针对每一个子集做一次梯度下降。然后更新参数w和b的值。接着到下一个子集中继续进行梯度下降。这样在遍历完所有的mini batch之后我们相当于在梯度下降中做了1000次迭代。我们将遍历一次所有样本的行为叫做一个 epoch，也就是一个世代。 在minibatch下的梯度下降中做的事情其实跟fullbatch一样，只不过我们训练的数据不再是所有的样本，而是一个个的子集。这样在mini batch我们在一个epoch中就能进行1000次的梯度下降，而在fullbatch中只有一次。 这样就大大的提高了我们算法的运行速度。</p><h1 id="梯度下降-1">梯度下降</h1><p>简单线性模型的完整计算图</p><figure><img src="https://img-blog.csdnimg.cn/831b68ae99444138855de2b5cf49830c.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x_data = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">y_data = [<span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>]</span><br><span class="line"></span><br><span class="line">w = torch.Tensor([<span class="number">1.0</span>]) <span class="comment">#梯度计算用tensor类型</span></span><br><span class="line">w.requires_grad = <span class="literal">True</span> <span class="comment">#声明w是要计算梯度的</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x*w <span class="comment">#tensor</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">x,y</span>)</span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="keyword">return</span> (y_pred - y)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="built_in">zip</span>(x_data, y_data):</span><br><span class="line">        l = loss(x,y) <span class="comment">#注意l为tensor，不能直接加减得到loss，可以.item()</span></span><br><span class="line">        l.backward()</span><br><span class="line">        w.data = w.data - <span class="number">0.01</span>*w.grad.data</span><br><span class="line"></span><br><span class="line">        w.grad.data.zero_() <span class="comment">#清零导数，下次重新训练</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="pytorch实现线性回归">Pytorch实现线性回归</h1><h2 id="prepare-dataset">1.Prepare dataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>],[<span class="number">2.0</span>],[<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">2.0</span>],[<span class="number">4.0</span>],[<span class="number">6.0</span>]])</span><br></pre></td></tr></table></figure><h2 id="design-model-using-class">2.Design model using Class</h2><p><strong>重点</strong>：构造计算图</p><h2 id="construct-loss-and-optimizer">Construct loss and optimizer</h2><h2 id="training-cycle">Training cycle</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x_data = torch.Tensor([[<span class="number">1.0</span>],[<span class="number">2.0</span>],[<span class="number">3.0</span>]])</span><br><span class="line">y_data = torch.Tensor([[<span class="number">2.0</span>],[<span class="number">4.0</span>],[<span class="number">6.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性回归模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearModel</span>(torch.nn.Module): <span class="comment"># 从module继承类</span></span><br><span class="line">     <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">     <span class="comment"># super调用父类构造</span></span><br><span class="line">         <span class="built_in">super</span>(LinearModel,self).__init__()</span><br><span class="line">         self.linear = torch.nn.Linear(<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># （1,1）输入1维，输出也是1维</span></span><br><span class="line"></span><br><span class="line">     <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>): <span class="comment">#只能写forward</span></span><br><span class="line">         y_pred = self.linear(x) <span class="comment"># 实现一个可调用的对象 __call__</span></span><br><span class="line">         <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = LinearModel() <span class="comment"># callable</span></span><br><span class="line"></span><br><span class="line">criterion = torch.nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>) <span class="comment"># MSEloss继承自nn.module</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):  <span class="comment"># 迭代100次</span></span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred,y_data) <span class="comment"># 前馈</span></span><br><span class="line">    <span class="built_in">print</span>(epoch,loss.item()) <span class="comment">#此处要用loss.item() </span></span><br><span class="line">    <span class="comment">#loss是个对象，调用时会自动调用__str__()函数，不会产生计算图</span></span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度归零</span></span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step() <span class="comment"># 更新</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w=&#x27;</span>,model.linear.weight.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b=&#x27;</span>,model.linear.bias.item())</span><br><span class="line"></span><br><span class="line">x_test = torch.Tensor([[<span class="number">4.0</span>]])</span><br><span class="line">y_test = model(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y_pred=&#x27;</span>,y_test.data)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="逻辑回归">逻辑回归</h2><p>处理二分类问题</p><figure><img src="/2024/07/06/pytorch_dl/image-6.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="comment">#包含了许多函数，sigmoid tanh relu</span></span><br><span class="line"></span><br><span class="line">x_data = torch.tensor([[<span class="number">1.0</span>],[<span class="number">2.0</span>],[<span class="number">3.3</span>]])</span><br><span class="line">y_data = torch.tensor([[<span class="number">0.0</span>],[<span class="number">0.0</span>],[<span class="number">1.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#设计模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegressionModel</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LogisticRegressionModel,self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">model = LogisticRegressionModel()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失和优化器</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred,y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch,loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><p>每天默写一遍（</p><h2 id="多维输入">多维输入</h2><p>矩阵是空间变换的函数，所以可以改变维度神经网络是寻找一种非线性的空间变换的函数linear可以做到空间维度的变换</p><figure><img src="/2024/07/06/pytorch_dl/image-7.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;your\path\diabetes.csv.gz&#x27;</span>,delimiter=<span class="string">&#x27;,&#x27;</span>,dtype = np.float32) <span class="comment">#32位浮点数</span></span><br><span class="line">x_data = torch.from_numpy(xy[:,:-<span class="number">1</span>]) <span class="comment"># 最后一列不要</span></span><br><span class="line">y_data = torch.from_numpy(xy[:,[-<span class="number">1</span>]]) <span class="comment"># 只要最后一列 []保证得到矩阵</span></span><br><span class="line"><span class="comment">#-------------------------#准备数据集</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model,self).__init__()</span><br><span class="line">        <span class="comment"># 不同的地方就是多次降维</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>,<span class="number">6</span>) <span class="comment">#8维到6维</span></span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>,<span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 添加非线性的变化，此处是nn下的sigmoid，是一个模块</span></span><br><span class="line">        <span class="comment"># 把此处sigmoid作为一个运算模块，继承自module，不需要传参，只构建一个</span></span><br><span class="line">        <span class="comment"># 与functional下的没有区别</span></span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line">        self.activate = torch.nn.ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="comment"># x = self.sigmoid(self.linear1(x))</span></span><br><span class="line">        <span class="comment"># x = self.sigmoid(self.linear2(x))</span></span><br><span class="line">        <span class="comment"># x = self.sigmoid(self.linear3(x))</span></span><br><span class="line">        x = self.activate(self.linear1(x))</span><br><span class="line">        x = self.activate(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"><span class="comment">#----------------------------------------#创建模型</span></span><br><span class="line"></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"><span class="comment"># 损失函数有所不同，BCE是二分类交叉熵，MSE是均方误差</span></span><br><span class="line"><span class="comment"># loss是否乘1/N，影响学习率的取值</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment">#-----------------------------------#构造损失函数和优化器</span></span><br><span class="line"></span><br><span class="line">epoch_x = []</span><br><span class="line">loss_y = []</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="comment">#前馈</span></span><br><span class="line">    y_pred = model(x_data) <span class="comment"># 所有数据</span></span><br><span class="line">    loss = criterion(y_pred,y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch,loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#画epoch-loss图，x和y轴的数据</span></span><br><span class="line">    epoch_x.extend(epoch)</span><br><span class="line">    loss_y.extend(loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#反馈</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#更新</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"><span class="comment">#---------------------------------------#训练周期</span></span><br><span class="line"><span class="comment"># 画图</span></span><br><span class="line">plt.plot(epoch_x, loss_y)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="创建数据集">创建数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataset是抽象类，不能实例化，只能继承dataset类以后才能实例化</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.创建数据集</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiabetesDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath</span>):</span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">        <span class="comment"># xy是n行9列,shape得到的[N,9]元组,shape[0]得到的是N</span></span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># 数据全部都读进来了，需要哪一条数据直接索引即可</span></span><br><span class="line">        <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = DiabetesDataset(<span class="string">&#x27;D:\桌面文件\深度学习\刘二大人\PyTorch深度学习实践\diabetes.csv.gz&#x27;</span>)</span><br><span class="line"><span class="comment"># DataLoader构造加载器</span></span><br><span class="line">train_loader = DataLoader(dataset=dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.创建模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.构造损失函数和优化器</span></span><br><span class="line">criterion = torch.nn.BCELoss(size_average=<span class="literal">True</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.训练周期</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 外层循环</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">        <span class="comment"># train_loader得到的(x,y)元组放入data，从0开始</span></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># data_x,data_y</span></span><br><span class="line">            inputs, labels = data</span><br><span class="line">            <span class="comment"># 前馈</span></span><br><span class="line">            y_hat = model(inputs)</span><br><span class="line">            loss = criterion(y_hat, labels)</span><br><span class="line">            <span class="built_in">print</span>(epoch, i, loss.item())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># 更新权重</span></span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="多分类">多分类</h2><p>Softmax层：求指数，然后除以求和求加权注意：交叉熵损失前计算出的结果不需要softmax激活</p><figure><img src="/2024/07/06/pytorch_dl/image-9.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><p><img src="/2024/07/06/pytorch_dl/image-10.png" alt="alt text"> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">y = torch.LongTensor([<span class="number">0</span>])</span><br><span class="line">z = torch.Tensor([[<span class="number">0.2</span>,<span class="number">0.1</span>,-<span class="number">0.1</span>]])</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">loss=criterion(z,y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms  <span class="comment"># 针对图像处理</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F  <span class="comment"># 使用ReLU</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim  <span class="comment"># 优化器</span></span><br><span class="line"><span class="comment">#数据集准备</span></span><br><span class="line">batch_size=<span class="number">64</span></span><br><span class="line"><span class="comment"># transform pytorch读图像时，神经网络希望输入比较小，</span></span><br><span class="line"><span class="comment"># pillow把图像转化为图像张量，单通道转化为多通道</span></span><br><span class="line">transform=transforms.Compose([transforms.ToTensor(),<span class="comment"># 转化成张量</span></span><br><span class="line"> transforms.Normalize((<span class="number">0.1307</span>,),(<span class="number">0.3081</span>,))])<span class="comment"># normalize归一化，(均值，标准差)</span></span><br><span class="line"><span class="comment"># transform放到数据集里是为了对第i个数据集直接操作</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>,</span><br><span class="line">                               train=<span class="literal">True</span>,</span><br><span class="line">                               download=<span class="literal">True</span>,</span><br><span class="line">                               transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">                              train=<span class="literal">False</span>,</span><br><span class="line">                              download=<span class="literal">True</span>,</span><br><span class="line">                              transform=transform)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,</span><br><span class="line">                         shuffle=<span class="literal">False</span>,</span><br><span class="line">                         batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment">#构造模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(model,self).__init__()</span><br><span class="line">        self.l1 = torch.nn.Linear(<span class="number">784</span>,<span class="number">512</span>)</span><br><span class="line">        self.l2=torch.nn.Linear(<span class="number">512</span>,<span class="number">256</span>)</span><br><span class="line">        self.l3=torch.nn.Linear(<span class="number">256</span>,<span class="number">128</span>)</span><br><span class="line">        self.l4=torch.nn.Linear(<span class="number">128</span>,<span class="number">64</span>)</span><br><span class="line">        self.l5=torch.nn.Linear(<span class="number">64</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">784</span>)  <span class="comment"># view改变张量的形式，把（N,1,28,28）变成二阶,-1表示0维度的数字不变</span></span><br><span class="line">        x=F.relu(self.l1(x))</span><br><span class="line">        x=F.relu(self.l2(x))</span><br><span class="line">        x=F.relu(self.l3(x))</span><br><span class="line">        x=F.relu((self.l4(x)))</span><br><span class="line">        <span class="keyword">return</span> self.l5(x) <span class="comment">#最后一层不激活</span></span><br><span class="line"></span><br><span class="line">model=Model()</span><br><span class="line"><span class="comment"># 3.损失函数和优化器</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()  <span class="comment"># 交叉熵损失</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)  <span class="comment"># 用带冲量的</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.训练周期+测试集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_size, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data  <span class="comment"># x，y</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 在优化器优化之前，进行权重清零;</span></span><br><span class="line"></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()  <span class="comment"># 累计loss</span></span><br><span class="line">        <span class="keyword">if</span> batch_size % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_size + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 不需要计算梯度</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            <span class="comment"># 求每一行最大值的下标，返回最大值，和下标</span></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)  <span class="comment"># batch_size</span></span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()  <span class="comment"># 比较下标与预测值是否接近，求和表示猜对了几个</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br></pre></td></tr></table></figure></p><h2 id="卷积basic">卷积(basic)</h2><p><img src="/2024/07/06/pytorch_dl/image-11.png" alt="alt text"> padding <img src="/2024/07/06/pytorch_dl/image-12.png" alt="alt text"> stride <img src="/2024/07/06/pytorch_dl/image-13.png" alt="alt text"> pooling池化 <img src="/2024/07/06/pytorch_dl/image-14.png" alt="alt text"> 简单CNN <img src="/2024/07/06/pytorch_dl/image-15.png" alt="alt text"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim  <span class="comment"># (可有可无)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;KMP_DUPLICATE_LIB_OK&#x27;</span>] = <span class="string">&#x27;TRUE&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#数据集准备同之前</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#数据集准备</span></span><br><span class="line">batch_size=<span class="number">64</span></span><br><span class="line"><span class="comment"># transform pytorch读图像时，神经网络希望输入比较小，</span></span><br><span class="line"><span class="comment"># pillow把图像转化为图像张量，单通道转化为多通道</span></span><br><span class="line">transform=transforms.Compose([transforms.ToTensor(),<span class="comment"># 转化成张量</span></span><br><span class="line"> transforms.Normalize((<span class="number">0.1307</span>,),(<span class="number">0.3081</span>,))])<span class="comment"># normalize归一化，(均值，标准差)</span></span><br><span class="line"><span class="comment"># transform放到数据集里是为了对第i个数据集直接操作</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>,</span><br><span class="line">                               train=<span class="literal">True</span>,</span><br><span class="line">                               download=<span class="literal">True</span>,</span><br><span class="line">                               transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist/&#x27;</span>,</span><br><span class="line">                              train=<span class="literal">False</span>,</span><br><span class="line">                              download=<span class="literal">True</span>,</span><br><span class="line">                              transform=transform)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,</span><br><span class="line">                         shuffle=<span class="literal">False</span>,</span><br><span class="line">                         batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResidualBlock, self).__init__()</span><br><span class="line">        self.channels = channels</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(channels, channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(channels, channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = F.relu(self.conv1(x))</span><br><span class="line">        y = self.conv2(y)</span><br><span class="line">        <span class="keyword">return</span> F.relu(x + y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net,self).__init__()</span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">1</span>,<span class="number">16</span>,kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2=nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling=nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc=nn.Linear(<span class="number">320</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        batch_size=x.size(<span class="number">0</span>)</span><br><span class="line">        x=F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x=x.view(batch_size,-<span class="number">1</span>)</span><br><span class="line">        x=self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"><span class="comment"># 表示把整个模型涉及到的权重迁移到GPU</span></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_index, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># 迁移至GPU(模型数据要在同一块显卡上)</span></span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">        y_hat = model(inputs)</span><br><span class="line">        loss = criterion(y_hat, labels)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_size % <span class="number">10</span> == <span class="number">9</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_index + <span class="number">1</span>, running_loss / <span class="number">300</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> (images, labels) <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = images.to(device), labels.to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, pred = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (pred == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;accuracy on test set: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line">    <span class="keyword">return</span> correct / total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    epoch_list = []</span><br><span class="line">    acc_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        acc = test()</span><br><span class="line">        epoch_list.append(epoch)</span><br><span class="line">        acc_list.append(acc)</span><br><span class="line"></span><br><span class="line">    plt.plot(epoch_list, acc_list)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h2 id="resnet">ResNet</h2><p><img src="/2024/07/06/pytorch_dl/image-16.png" alt="alt text"> 以往的网络模型是这种PlainNet形式：输入数据x，经过WeightLayer(可以是卷积层，也可以是池化或者线性层)，再通过激活函数加入非线性影响因素，最后输出结果H(x)；这种方式使得H(x)对x的偏导数的值分布在（0,1）之间，这在反向传播、复合函数的偏导数逐步累乘的过程中，必然会导致损失函数L对x的偏导数的值，趋近于0，而且，网络层数越深，这种现象就会越明显，最终导致最开始的（也就是靠近输入的）层没有获得有效的权重更新，甚至模型失效；</p><p>ResNet采用了一个非常巧妙的方式解决了H(x)对x的偏导数的值分布在（0,1）之间这个问题：在以往的框架中，加入一个跳跃，再原有的网络输出F(x)的基础上，将输入x累加到上面，这样一来，在最终输出H(x)对输入数据x求偏导数的时候，这个结果就会分布在（1,2）之间，这样就不怕网络在更新权重梯度累乘的过程中，出现乘积越来越趋于0而导致的梯度消失问题；</p><figure><img src="/2024/07/06/pytorch_dl/image-17.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><p>注意：resblock前后的输入和输出的纬度要一样</p><figure><img src="/2024/07/06/pytorch_dl/image-18.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><figure><img src="/2024/07/06/pytorch_dl/image-19.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><h2 id="rnnbasic">RNN(basic)</h2><figure><img src="/2024/07/06/pytorch_dl/image-20.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><figure><img src="/2024/07/06/pytorch_dl/image-21.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 参数设置</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">2</span></span><br><span class="line"><span class="comment">#比rnncell多一个numlayers</span></span><br><span class="line">num_layers = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">cell = torch.nn.RNN(input_size = input_size,hidden_size=hidden_size,</span><br><span class="line">                        num_layers = num_layers)</span><br><span class="line"></span><br><span class="line"><span class="comment">#(seq,batch,features)</span></span><br><span class="line"><span class="comment"># 指明维度</span></span><br><span class="line">inputs = torch.randn(seq_len,batch_size,input_size)</span><br><span class="line">hidden = torch.zeros(num_layers,batch_size,hidden_size)</span><br><span class="line"></span><br><span class="line">out,hidden = cell(inputs,hidden)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Ouput size&#x27;</span>,out.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Output:&#x27;</span>,out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;gidden size&#x27;</span>,hidden.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;hidden:&#x27;</span>,hidden)</span><br></pre></td></tr></table></figure><p>hallo-&gt;ohlol <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用RNN</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">4</span></span><br><span class="line">num_layers = <span class="number">1</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">5</span></span><br><span class="line"><span class="comment"># 准备数据</span></span><br><span class="line">idx2char = [<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]</span><br><span class="line">x_data = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]  <span class="comment"># hello</span></span><br><span class="line">y_data = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>]  <span class="comment"># ohlol</span></span><br><span class="line"></span><br><span class="line">one_hot_lookup = [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]]  <span class="comment"># 分别对应0,1,2,3项</span></span><br><span class="line">x_one_hot = [one_hot_lookup[x] <span class="keyword">for</span> x <span class="keyword">in</span> x_data]  <span class="comment"># 组成序列张量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x_one_hot:&#x27;</span>, x_one_hot)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造输入序列和标签</span></span><br><span class="line">inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size, input_size)</span><br><span class="line">labels = torch.LongTensor(y_data)  <span class="comment"># labels维度是: (seqLen * batch_size ，1)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># design model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, batch_size, num_layers=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.rnn = torch.nn.RNN(input_size=self.input_size,</span><br><span class="line">                                hidden_size=self.hidden_size,</span><br><span class="line">                                num_layers=self.num_layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)</span><br><span class="line">        out, _ = self.rnn(<span class="built_in">input</span>, hidden)</span><br><span class="line">        <span class="comment"># 为了能和labels做交叉熵，需要reshape一下:(seqlen*batchsize, hidden_size),即二维向量，变成一个矩阵</span></span><br><span class="line">        <span class="keyword">return</span> out.view(-<span class="number">1</span>, self.hidden_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Model(input_size, hidden_size, batch_size, num_layers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss and optimizer</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(), lr=<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train cycle</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    epoch_list = []</span><br><span class="line">    loss_list = []</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># inputs维度是: (seqLen, batch_size, input_size) labels维度是: (seqLen * batch_size * 1)</span></span><br><span class="line">        <span class="comment"># outputs维度是: (seqLen, batch_size, hidden_size)</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        _, idx = outputs.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">        idx = idx.data.numpy()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Predicted: &#x27;</span>, <span class="string">&#x27;&#x27;</span>.join([idx2char[x] <span class="keyword">for</span> x <span class="keyword">in</span> idx]), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;,Epoch [%d/20] loss=%.3f&#x27;</span> % (epoch + <span class="number">1</span>, loss.item()))</span><br><span class="line">        epoch_list.append(epoch)</span><br><span class="line">        loss_list.append(loss.item())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(epoch_list, loss_list)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初识FASTA</title>
      <link href="/2024/07/06/bioinfo/fasta/"/>
      <url>/2024/07/06/bioinfo/fasta/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="参考资料">参考资料：</h1><ul><li>https://blog.csdn.net/sunchengquan/article/details/85007698?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172023585616800226561313%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=172023585616800226561313&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2<sub>all</sub>top_positive~default-1-85007698-null-null.142<sup>v100</sup>pc_search_result_base8&amp;utm_term=fasta&amp;spm=1018.2226.3001.4187</li><li>https://zhuanlan.zhihu.com/p/34195790</li></ul><h1 id="什么是fasta格式">1.什么是FASTA格式</h1><p>在生物信息学中，FASTA格式是一种用于记录核酸序列或肽序列的文本格式，其中的核酸或氨基酸均以单个字母编码呈现。该格式同时还允许在序列之前定义名称和编写注释。这一格式最初由FASTA软件包定义，但现今已是生物信息学领域的一项标准。</p><p>FASTA格式是BLAST组织数据的基本格式，无论是数据库还是查询序列，还是各种生物的基因组序列数据也都是用FASTA格式进行存储的，大多数情况都使用FASTA格式。另外，FASTA简明的格式降低了序列操纵和分析的难度，令序列可被文本处理工具和诸如Python、Ruby和Perl等脚本语言处理。(来自维基百科)</p><h1 id="组成">2.组成</h1><ul><li>1.描述行 (The description line, Defline, Header or Identifier line):以一个大于号("&gt;")开头，内容可以随意，但<em>不能有重复</em>，相当于身份识别信息。</li><li>序列行 (SequenceLine)：一行或多行的核苷酸序列或肽序列，其中碱基对或氨基酸使用单字母代码表示。<strong>注意：在FASTA格式文件中，内容中间不允许有空行，建议所有文本行的长度小于 80个字符，序列超过80个字符的部分紧跟着换到下一行。</strong></li></ul><p>打印fasta</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">!cat ./data/AY810830.fasta</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cat</span>(<span class="params">file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    读入FASTA格式的文件</span></span><br><span class="line"><span class="string">    :param file: FASTA格式的文件</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(file):</span><br><span class="line">        <span class="built_in">print</span>(line.strip())</span><br><span class="line"></span><br><span class="line">cat(<span class="string">&quot;./data/test1.fa&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;NM_001011874 gene=Xkr4 CDS=<span class="number">151</span>-<span class="number">2091</span></span><br><span class="line">gcggcggcgggcgagcgggcgctggagtaggagctggggagcggcgcggccggggaaggaagccagggcg</span><br><span class="line">&gt;NM_001195662 gene=Rp1 CDS=<span class="number">55</span>-<span class="number">909</span></span><br><span class="line">AGGTCTCACCCAAAATGAGTGACACACCTTCTACTAGTTTCTCCATGATTCATCTGACTTCTGAAGGTCA</span><br><span class="line">&gt;NM_011283 gene=Rp1 CDS=<span class="number">128</span>-<span class="number">6412</span></span><br><span class="line">AATAAATCCAAAGACATTTGTTTACGTGAAACAAGCAGGTTGCATATCCAGTGACGTTTATACAGACCAC</span><br><span class="line">&gt;NM_0112835 gene=Rp15 CDS=<span class="number">128</span>-<span class="number">6412</span></span><br><span class="line">AATAAATCCAAAGACATTTGTTTACGTGAAACAAGCAGGTTGCATATCCAGTGACGTTTATACAGACCAC</span><br><span class="line">&gt;NM_001011874 gene=Xkr4 CDS=<span class="number">151</span>-<span class="number">2091</span></span><br><span class="line">gcggcggcgggcgagcgggcgctggagtaggagctggggagcggcgcggccggggaaggaagccagggcg</span><br><span class="line">aggcgaggaggtggcgggaggaggagacagcagggacaggTGTCAGATAAAGGAGTGCTCTCCTCCGCTG</span><br><span class="line">CCGAGGCATCATGGCCGCTAAGTCAGACGGGAGGCTGAAGATGAAGAAGAGCAGCGACGTGGCGTTCACC</span><br><span class="line">CCGCTGCAGAACTCGGACAATTCGGGCTCTGTGCAAGGACTGGCTCCAGGCTTGCCGTCGGGGTCCGGAG</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>把每条FASTA序列连成一行然后输出 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">formatFasta</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    把每条FASTA序列连成一行然后输出</span></span><br><span class="line"><span class="string">    :param filename: 文件名</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    alist = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(filename):</span><br><span class="line">        <span class="keyword">if</span> line[<span class="number">0</span>] == <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">            lineL = line.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> alist:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(alist))</span><br><span class="line">                alist = []</span><br><span class="line">            name = lineL[<span class="number">0</span>]</span><br><span class="line">            <span class="built_in">print</span>(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            alist.append(line.strip())</span><br><span class="line">    <span class="comment">#不要忘了最后一个序列</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(alist))</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&quot;./data/test2.fa&quot;</span></span><br><span class="line">formatFasta(filename)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;NM_0112835</span><br><span class="line">AATAAATCCAAAGACATTTGTTTACGTGAAACAAGCAGGTTGCATATCCAGTGACGTTTATACAGACCACACAAACTATTTACTCTTTTCTTCGTAAGGAAAGGTTCAACTTCTGGTCTCACCCAAAATGAGTGACACACCTTCTACTAGTTTCTCCATGATTCATCTGACTTCTGAAGGTCAAGTTCCTTCCCCTCGCCATTCAAATATCACTCATCCTGTAGTGGCTAAACGCATCAGTTTCTATAAGAGTGGAGACCCACAGTTTGGCGGCGTTCGGGTGGTGGTCAACCCTCGTTCCTTTAAGACTTTTGACGCTCTGCTGGACAGTTTATCCAGGAAGGTACCCCTGCCCTTTGGGGTAAGGAACATCAGCACGCCCCGTGGACGACACAGCATCACCAGGCTGGAGGAGCTAGAGGACGGCAAGTCTTATGTGTGCTCCCACAATAAGAAGGTGCTGCCAGTTGACCTGGACAAGGCCCGCAGGCGCCCTCGGCCCTGGCTGAGTAGTCGCTCCATAAGCACGCATGTGCAGCTCTGTCCTGCAACTGCCAATATGTCCACCATGGCACCTGGCATGCTCCGTGCCCCAAGGAGGCTCGTGGTCTTCCGGAATGGTGACCCGAA</span><br><span class="line">&gt;NM_001195662</span><br><span class="line">AAGCTCAGCCTTTGCTCAGATTCTCCTCTTGATGAAACAAAGGGATTTCTGCACATGCTTGAGAAATTGCAGGTCTCACCCAAAATGAGTGACACACCTTCTACTAGTTTCTCCATGATTCATCTGACTTCTGAAGGTCAAGTTCCTTCCCCTCGCCATTCAAATATCACTCATCCTGTAGTGGCTAAACGCATCAGTTTCTATAAGAGTGGAGACCCACAGTTTGGCGGCGTTCGGGTGGTGGTCAACCCTCGTTCCTTTAAGACTTTTGACGCTCTGCTGGACAGTTTATCCAGGAAGGTACCCCTGCCCTTTGGGGTAAGGAACATCAGCACGCCCCGTGGACGACACAGCATCACCAGGCTGGAGGAGCTAGAGGACGGCAAGTCTTATGTGTGCTCCCACAATAAGAAGGTGCTG</span><br><span class="line">&gt;NM_011283</span><br><span class="line">AATAAATCCAAAGACATTTGTTTACGTGAAACAAGCAGGTTGCATATCCAGTGACGTTTATACAGACCACACAAACTATTTACTCTTTTCTTCGTAAGGAAAGGTTCAACTTCTGGTCTCACCCAAAATGAGTGACACACCTTCTACTAGTTTCTCCATGATTCATCTGACTTCTGAAGGTCAAGTTCCTTCCCCTCGCCATTCAAATATCACTCATCCTGTAGTGGCTAAACGCATCAGTTTCTATAAGAGTGGAGACCCACAGTTTGGCGGCGTTCGGGTGGTGGTCAACCCTCGTTCCTTTAAGACTTTTGACGCTCTGCTGGACAGTTTATCCAGGAAGGTACCCCTGCCCTTTGGGGTAAGGAACATCAGCACGCCCCGTGGACGACACAGCATCACCAGGCTGGAGGAGCTAGAGGACGGCAAGTCTTATGTGTGCTCCCACAATAAGAAGGTGCTGCCAGTTGACCTGGACAAGGCCCGCAGGCGCCCTCGGCCCTGGCTGAGTAGTCGCTCCATAAGCACGCATGTGCAGCTCTGTCCTGCAACTGCCAATATGTCCACCATGGCACCTGGCATGCTCCGTGCCCCAAGGAGGCTCGTGGTCTTCCGGAATGGTGACCCGAA</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>提取fasta.name中名字对应的test2.fa的序列，并输出到屏幕。fasta.name文件内容如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">!cat <span class="string">&quot;./data/fasta.name&quot;</span></span><br><span class="line">NM_011283</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">aDict = &#123;&#125;</span><br><span class="line">seqFile = <span class="string">&quot;data/test2.fa&quot;</span></span><br><span class="line">nameFile = <span class="string">&quot;data/fasta.name&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(seqFile):</span><br><span class="line">    <span class="keyword">if</span> line[<span class="number">0</span>] == <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">        key = line.split()[<span class="number">0</span>][<span class="number">1</span>:] </span><br><span class="line">        aDict[key] = []  </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        aDict[key].append(line.strip())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(nameFile):</span><br><span class="line">    name = line.strip()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;%s\n%s&quot;</span> % (name, <span class="string">&#x27;&#x27;</span>.join(aDict[name])))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&gt;%s\n%s&quot;</span> % (name, aDict[name]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;NM_011283</span><br><span class="line">AATAAATCCAAAGACATTTGTTTACGTGAAACAAGCAGGTTGCATATCCAGTGACGTTTATACAGACCACACAAACTATTTACTCTTTTCTTCGTAAGGAAAGGTTCAACTTCTGGTCTCACCCAAAATGAGTGACACACCTTCTACTAGTTTCTCCATGATTCATCTGACTTCTGAAGGTCAAGTTCCTTCCCCTCGCCATTCAAATATCACTCATCCTGTAGTGGCTAAACGCATCAGTTTCTATAAGAGTGGAGACCCACAGTTTGGCGGCGTTCGGGTGGTGGTCAACCCTCGTTCCTTTAAGACTTTTGACGCTCTGCTGGACAGTTTATCCAGGAAGGTACCCCTGCCCTTTGGGGTAAGGAACATCAGCACGCCCCGTGGACGACACAGCATCACCAGGCTGGAGGAGCTAGAGGACGGCAAGTCTTATGTGTGCTCCCACAATAAGAAGGTGCTGCCAGTTGACCTGGACAAGGCCCGCAGGCGCCCTCGGCCCTGGCTGAGTAGTCGCTCCATAAGCACGCATGTGCAGCTCTGTCCTGCAACTGCCAATATGTCCACCATGGCACCTGGCATGCTCCGTGCCCCAAGGAGGCTCGTGGTCTTCCGGAATGGTGACCCGAA</span><br><span class="line">&gt;NM_011283</span><br><span class="line">[<span class="string">&#x27;AATAAATCCAAAGACATTTGTTTACGTGAAACAAGCAGGTTGCATATCCAGTGACGTTTATACAGACCAC&#x27;</span>, <span class="string">&#x27;ACAAACTATTTACTCTTTTCTTCGTAAGGAAAGGTTCAACTTCTGGTCTCACCCAAAATGAGTGACACAC&#x27;</span>, <span class="string">&#x27;CTTCTACTAGTTTCTCCATGATTCATCTGACTTCTGAAGGTCAAGTTCCTTCCCCTCGCCATTCAAATAT&#x27;</span>, <span class="string">&#x27;CACTCATCCTGTAGTGGCTAAACGCATCAGTTTCTATAAGAGTGGAGACCCACAGTTTGGCGGCGTTCGG&#x27;</span>, <span class="string">&#x27;GTGGTGGTCAACCCTCGTTCCTTTAAGACTTTTGACGCTCTGCTGGACAGTTTATCCAGGAAGGTACCCC&#x27;</span>, <span class="string">&#x27;TGCCCTTTGGGGTAAGGAACATCAGCACGCCCCGTGGACGACACAGCATCACCAGGCTGGAGGAGCTAGA&#x27;</span>, <span class="string">&#x27;GGACGGCAAGTCTTATGTGTGCTCCCACAATAAGAAGGTGCTGCCAGTTGACCTGGACAAGGCCCGCAGG&#x27;</span>, <span class="string">&#x27;CGCCCTCGGCCCTGGCTGAGTAGTCGCTCCATAAGCACGCATGTGCAGCTCTGTCCTGCAACTGCCAATA&#x27;</span>, <span class="string">&#x27;TGTCCACCATGGCACCTGGCATGCTCCGTGCCCCAAGGAGGCTCGTGGTCTTCCGGAATGGTGACCCGAA&#x27;</span>, <span class="string">&#x27;&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>不难看出，FASTA之所以在生物信息领域被广泛的接受，一方面，是历史原因造成的（FASTA程序的先发优势），更重要的是，FASTA格式非常的简单和容易被理解，易于传播和交流。</p>]]></content>
      
      
      <categories>
          
          <category> 生信のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 生物信息学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大学物理（2）通关指南(48学时-程运华)</title>
      <link href="/2024/07/05/phi_2/"/>
      <url>/2024/07/05/phi_2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>12-17期末真题A卷https://pan.baidu.com/s/1ygNfwb3hbMJ8018j3UxDMg?pwd=xray</p>]]></content>
      
      
      <categories>
          
          <category> 製薬のConcerto </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 期末 </tag>
            
            <tag> 合格 </tag>
            
            <tag> 大学物理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>物理化学通关指南(64学时-马彤梅)</title>
      <link href="/2024/07/05/phichem/"/>
      <url>/2024/07/05/phichem/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>物理化学作业是课后习题，有答案。 链接有作业答案和一些往年卷： <img src="/2024/07/05/phichem/image-8.png" alt="alt text">https://pan.baidu.com/s/1jZ2ASmoVO-yL3KVIhpNUwg?pwd=xray</p>]]></content>
      
      
      <categories>
          
          <category> 製薬のConcerto </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 期末 </tag>
            
            <tag> 合格 </tag>
            
            <tag> 物理化学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分析化学通关指南(48学时-王敏)</title>
      <link href="/2024/07/05/anachem/"/>
      <url>/2024/07/05/anachem/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>分析化学有时会有课前测。文件包括作业答案、课前测答案、老师给的复习题(有很多期末原题)、各种分析化学期末卷<img src="/2024/07/05/anachem/image-22.png" alt="预览">https://pan.baidu.com/s/1UuuthqEzoDJiY1Qu_fNFIQ?pwd=xray</p>]]></content>
      
      
      <categories>
          
          <category> 製薬のConcerto </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 期末 </tag>
            
            <tag> 合格 </tag>
            
            <tag> 分析化学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>有机化学通关指南(64学时-林东恩)</title>
      <link href="/2024/07/04/organchem/"/>
      <url>/2024/07/04/organchem/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><p>有机化学的作业是课本习题，包打听有答案。然后有机化学有期中考试。https://pan.baidu.com/s/1DC_eyuQk1bxa_nHW8whq2w?pwd=xray下载链接包含林老师的23年期中考试和各种有机期末往年卷。 <img src="/2024/07/04/organchem/cata1.png" alt="alt text"></p>]]></content>
      
      
      <categories>
          
          <category> 製薬のConcerto </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 期末 </tag>
            
            <tag> 合格 </tag>
            
            <tag> 有机化学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>帽子戏法</title>
      <link href="/2024/07/03/new2/"/>
      <url>/2024/07/03/new2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="帽子戏法">帽子戏法</h1><p>作者：北冰洋</p><p><em>本文收录于2023年浙江大学推理社刊《求是集录：案之卷》</em></p><figure><img src="/2024/07/03/new2/pt1.png" alt="test"><figcaption aria-hidden="true">test</figcaption></figure><figure><img src="/2024/07/03/new2/pt2.png" alt="test"><figcaption aria-hidden="true">test</figcaption></figure><h2 id="section">01</h2><p>“快看，前面那个不就是吗？跟明里发的照片一样。”萧彩萌指着手机屏幕。照片中，一栋庄严的别墅屹立在阴冷的森林中。更巧的是，车窗外的天气也同照片中那般死气沉沉，厚厚的云层将森林别墅罩得密不透风，几声凄冷的乌鸦啼鸣如同兽爪般抓挠着天空，积雪铺满道路，仿佛一脚踩不到底。</p><p>“重生庄，这名字听起来还挺有希望的，结果居然是这么恐怖的地方。”毕一宇坐在驾驶位上，身体微微前倾，凝视着车外的别墅。</p><p>看来这就是本次的目的地了，虽然与想象中的有些差异。毕一宇将车停在大门外的空地，刚熄火就连忙下车绕到副驾驶的车门前，为萧彩萌打开车门。萧彩萌双脚踏在松软的雪地上，鞋跟深深地扎进雪堆。</p><p>“服务真周到。”</p><p>“彩萌小姐，这是我的荣幸。”毕一宇装作绅士鞠了一躬。</p><p>“我看看，他们应该都到了吧，明里他们早上就出发了。”</p><p>“我们也是早上出发的呀，只可惜校区离这里实在是太远了，根本不在一个市。”毕一宇语气中带着抱怨，显然是被漫长的车程与曲折的山路折磨得筋疲力尽。“你看，现在都是下午了，过一会就要吃晚饭了吧。”</p><p>“所以，还是当地人好啊，也难怪明里会把重生庄建在这里，作为社团活动的地方。”</p><p>重生庄距离明里他们学校非常近，大约十分钟的车程，只不过沿途没有公交，只能自己开车，或者学校的专车送他们过来。眼前的停车处只有毕一宇的车，看来他们是坐专车一起来的。</p><p>“好冷，要不咱们先进屋？”萧彩萌指着那扇褐色的大门。</p><p>“当然，要是彩萌小姐感冒了我可不好交代。”话音未落毕一宇就踏出双脚，走在崭新的白雪上。</p><p>“喂，别走那么快啊。”</p><p>重生庄整体色调偏暗，房顶是纯黑的，墙壁也大多刷成褐色，二楼的玻璃被擦得雪亮。大门前立着两根石英柱，相隔大约四米，上面刻着看不懂的洋文，门前的台阶上的积雪已经被清理干净了，门口摆放着一辆轮椅。</p><p>两人走上楼梯，来到门前。</p><p>门是金属制的，散发着寒气。咚咚……毕一宇敲了敲门，食指和中指的骨关节像是被针扎般疼痛。</p><p>不一会便传来开门声。一张明朗的笑脸出现在眼前。</p><p>“啊啊，欢迎欢迎，你们来的也太慢了吧。”明里笑着欢迎两人，身上穿着纯白色的卫衣。</p><p>“久等了。”萧彩萌的语气并无歉意，更像是总裁赴宴时例行公事的问候。</p><p>“拖鞋在鞋柜最底层，我已经准备好了。”</p><p>“真是麻烦你了。”</p><p>鞋柜底下有两双毛绒拖鞋，萧彩萌选择了粉色的那双。</p><p>一进门便是客厅，沙发前的火炉已经点燃了，炽热的火焰将屋内空气烤得十分暖和。餐桌那边的吊灯已经亮了，两人循着灯光走过去。餐厅已经坐着其他成员了。</p><p>“哟，这不是萧彩萌小姐吗？今年也来我们的社团活动啦。”一个裹着黑皮衣红发青年朝他们挥着手，胸前挂着银色的十字架，大概就掌心大小。</p><p>“你是陆子雯吧，头发怎么染成红色了，我记得去年是……”</p><p>“别别别，去年是银色，小姐你总是说那是灰色，纠正你好几次了。”陆子雯摸了摸自己的红发。</p><p>“哈哈，没啥区别吧。”</p><p>“当然是有的啦，算了，已经解释了一年了，现在这红色总算够标志了吧。”</p><p>“那是，红色有什么寓意吗？”</p><p>陆子雯亲吻了自己的十字架，“红色这是我对主的绝对忠诚。”</p><p>不说还以为是玩摇滚的呢。</p><p>“话说，萧彩萌，你身边的男性的谁？巴布亚不来了吗？”坐在靠近楼梯的男生问道，他是副社长雨桐，胸前也挂着把大拇指大小的银色斧头。</p><p>“哦哦，这位是巴布亚在Z大推协的学弟，今天他代替巴布亚来保护我。”</p><p>毕一宇严肃地做了一番自我介绍。</p><p>“真好啊，大小姐的生活总是有保障，不像我们，只能祈祷，真好啊。”雨桐紧紧握住胸前的斧头。</p><p>明里端着茶盘缓缓走来，“大家，先喝点东西吧。”明里把盘中的咖啡摆到餐桌上，咖啡表面冒着滚烫的热气，像是沸腾般。</p><p>“彩萌小姐，小心烫。”毕一宇端了一杯咖啡给萧彩萌。</p><p>“萧彩萌小姐的衣服和雪如此般配，但是可别被黑咖啡玷污了。”一个男生左手拿着书，右手端着咖啡，说话时视线依旧停留在书页上。</p><p>“多谢安先生的提醒。”萧彩萌小心翼翼地抿了一口咖啡。</p><p>那个沉迷于书的男生姓安，平时说话文绉绉的，大家都喊他安先生，他也不反感。</p><p>“那么，所有人都到齐了。”明里郑重宣布。桌上的黑咖啡映着头顶光亮的吊灯。</p><p>“诶，”萧彩萌对明里的话感到疑惑，“那个，莱斯特今年没来吗？”</p><p>“来了呀，只不过好像去外面看雪了。真是的，那家伙明明腿受伤了还按捺不住好奇心。”</p><p>萧彩萌望着门口的轮椅。</p><p>“是的，那个轮椅就是莱斯特的，他说他上周骑摩托时撞到右腿了，现在行动得依靠拐杖和轮椅。”雨桐仿佛会读心术般回答道。窗外，雪丝毫没有喘息的意图。</p><h2 id="section-1">02</h2><p>明里，陆子雯，雨桐，安先生和莱斯特都是H大的大三学生，并且课外时间都加入了祈祷社。</p><p>祈祷社曾是H大的门面社团，每个渴望理想生活的人都会加入祈祷社，向自己心中的主祈祷，以求得健康、财运、学业上的发展。每年，祈祷社都会组织社员前往重生馆祈祷。重生馆里配有两层的祈祷室，一楼祈求灾祸的远离，二楼祈求幸运的降临。由于主不接受沾染世俗的信徒，所以必须在一楼除去世俗之恶后才能去二楼对主祈祷。也就是说祈祷室的祈祷活动必须从一楼开始进行，通过祈祷室的楼梯上二楼，这是祈祷社的宗旨，违背者将遭天谴。</p><p>至今，祈祷社已经有长达二十年的历史，当前的社长是明里，副社长是雨桐。社团内从不规定社员的主，就算社员们将偶像或者二次元视为主也无妨，祈祷社强调的是信仰，看重的是虔诚，而不是具体的人或物。</p><p>也因为这样，社员们常常为自己的主的神圣而针锋相对，社团内的矛盾不断激化，到今年为止，祈祷社也就仅剩这几个人了。今年的祈祷活动过后，祈祷社也将解散。</p><p>萧彩萌作为Z大的学生，却连续几年参加了H大祈祷社的活动，说是为自己的论文寻找灵感，渐渐地和社团内的人混熟了。萧彩萌自认为祈祷说不上有用，但也无害。</p><p>今年最后一届社团活动，面对明里的邀请，萧彩萌当然选择参加。</p><p>“巴布亚，这是祈祷社最后一次活动了，你真的不去吗？”萧彩萌对巴布亚的婉拒感到遗憾。</p><p>“没办法呀，和推协的事冲突了，抽不出时间了。”巴布亚坐在教室的座位上，双眼死盯着电脑屏幕。</p><p>“那今年我一个人去吗？”</p><p>“没事，可以让毕一宇陪你，他应该很乐意。”</p><p>“他人到是很顺从。”</p><p>“怎么，怕他保护不好你吗？”</p><p>“……他还是先保护好自己吧。”</p><p>萧彩萌看着明里发来的照片，那栋熟悉又陌生的别墅，用不了多久就会变成废墟吧。又或者，或被其他社团当做社活的场所吗？有的话也一定是什么试胆社吧。</p><p>教室外的雪不知什么时候停了，教学楼下有学生走动，留下一串串交错的脚印。</p><h2 id="section-2">03</h2><p>“真不好意思，本想在外面走一会的，谁知道路这么难走。”</p><p>重生庄的门口传来粗犷的男声，只见一个男人拄着右拐走了进来。</p><p>“莱斯特，进来记得关门……算了我来吧。”陆子雯站起身，朝莱斯特走去。</p><p>“哦，谢谢你，还有我的轮椅也帮忙推下过来吧。”</p><p>陆子雯从门外把轮椅搬了进来，轮椅看起来很重，但对于热爱健身的陆子雯来说问题不大。</p><p>关上门，屋内与屋外的极寒之地隔绝。“喏，坐着吧，”陆子雯把轮椅推到莱斯特的面前。</p><p>“上帝保佑你，你是个好人，陆子雯。”</p><p>“还是让上帝保佑你的右腿吧。”</p><p>餐桌那边传来一阵笑声，莱斯特操控着轮椅，向着餐厅移动。</p><p>“哦，亲爱的萧彩萌小姐，好久不见，雪白的衣服与白雪真般配！”莱斯特在献殷勤方面毫不吝啬。</p><p>“受伤也要来祈祷，真是辛苦你了。只是腿受伤的话就跳不起来了。”</p><p>“无伤大雅，最后一次参加社团活动了，就是头没了我也会来。”</p><p>大家对这个玩笑没有反应，空气像是窗外的雨雪一样结冰。</p><p>“那……我们差不多吃晚饭吧，晚上十二点要准时去祈祷室。”</p><p>萧彩萌看了看餐厅的时钟，差不多六点了。果然，冬天更容易饿呢。</p><p>“又能尝到明里做的饭菜，想想就不虚此行。”安先生盛赞道。</p><p>“最后在重生庄吃饭了，无论怎样都很难忘吧。”副社长雨桐感慨着。</p><p>不一会，明里就在餐桌上摆满了的菜。</p><p>“哇！”毕一宇是第一次品尝明里的菜，在视觉上已经先被折服了。</p><p>“很赞吧！”萧彩萌对毕一宇的反应表示习以为常。</p><p>“真的，感觉用筷子夹菜都是对菜的糟蹋。”</p><p>“话不能这么讲，”陆子雯撕下一只焦黄的烤鸭腿，“饭菜终究是吃的，不然跟模型没啥两样。”</p><p>“也是。”毕一宇拿起叉子，卷起一圈意大利面送进嘴里。伴着番茄酸的肉沫迅速在口里融化，还没来得及仔细咀嚼就迫不及待地咽下。</p><p>突然，古老的座钟发出了猛兽般的响声，游荡在重生庄中。这是六点钟的钟声。</p><p>“时间到了，开始吧。”</p><p>毕一宇一脸疑惑，“诶，开始啥？不是已经开始吃饭了吗？”</p><p>“笨蛋，”萧彩萌轻轻地拍了下毕一宇的肩膀，“晚上六点要做预备的祈祷啊，快放下叉子。”</p><p>毕一宇一头雾水地咽下嘴里剩余的食物，将叉子放回餐桌上。</p><p>“大家，双手十指紧扣，放于胸前。”明里命令道。</p><p>毕一宇用余光瞥着身边双目紧闭的萧彩萌，拙劣地模仿着祈祷的姿势。</p><p>“Uneasy lies the heads that wear hats……”</p><p>“诶，这是……”毕一宇在这一阵沉吟中不禁发出疑惑。</p><p>“笨蛋，那是咒语啦。”</p><p>作为第一次参与祈祷的新人，别说虔诚了，能完整进行仪式就是毕一宇此行最大的成功。</p><p>沉吟如同蜜蜂振翅般回响于餐厅，虽称不上震耳欲聋，但一词一句都那么铿锵有力。</p><p>沉吟结束，所有人都睁开双眼，双手恢复自由。“毕一宇先生是第一次参加吧，也是难为你了。”</p><p>毕一宇本想说一回生二回熟，但仔细一想已经没有下次了。</p><p>“那个，能问问这句话是什么意思吗？”</p><p>“那句英文啊，你可以理解为‘欲戴皇冠必承其重’。”安先生难得看着人讲话。</p><p>“这样啊，看来大家都肩负着某种责任呢。”毕一宇笑着摸了摸后脑勺。</p><p>“人生来就背着十字架，负重前行。每一次祈祷，都是让我们铭记肩上的责任，脚踏实地，方可仰望星空。”</p><p>毕一宇差点就为安先生的发言鼓掌了。</p><p>“大家，最后一次聚在重生馆，不要留下遗憾啊！一定要拿出平时百倍的虔诚，向我们的主展示信徒最忠诚的一面。”陆子雯举起桌上的酒杯。</p><p>毕一宇见状立马拿起酒杯，谁知杯中的酒没来得及刹车，溅到了明里的卫衣上。</p><p>“哇！”明里纯白色的卫衣上晕开一片紫红。</p><p>“啊抱歉抱歉！”毕一宇感觉抽了几张纸巾给明里。</p><p>但无论明里怎么擦拭，衣服上的大片污渍依旧很显眼</p><p>“算了，没事，反正晚上要换衣服。”明里宽容大量，符合社长的作风。只是身旁的萧彩萌向毕一宇投来了厌恶的眼神。</p><p>大家也都表达了自己的志愿，举起酒杯相敬。窗外的天空已被黑墨水涂满，幽静的森林里，重生馆是唯一的光源，从某种意义上来说，重生馆名副其实。窗外的雪渐渐停了，一眼望去，地上的雪被屋内的灯光照得锃亮。</p><h2 id="section-3">04</h2><p>酒足饭饱后，明里决定带大家参观一下重生馆。说是带大家，其实只是为了毕一宇这一个陌生人。</p><p>莱斯特以腿伤为由不跟随大家了。</p><p>“房间都安排好了吧，其他人都和去年一样，毕一宇先生的话，就住去年巴布亚住得房间吧，在二楼。”明里带着大家上了楼梯。</p><p>楼梯的顶上挂着一个中世纪的壁灯，灯光不亮，但氛围感十足。二楼的地板上铺满了雪似的白绒地毯，让人不忍心踩在上面。毕一宇小心地挪动脚步，跟着大家走。</p><p>从二楼栏杆望下去，可以看到一楼的客厅，火炉里的火依旧熊熊地烧着。</p><p>楼梯旁的第一间房间便是毕一宇的房间，毕一宇将自己的行李放了进去。要在这种氛围的别墅里住一晚，毕一宇竟有些激动。</p><p>“二楼的热水器在公用卫生间里，”明里指了指，“现在是关着的，想要洗澡的时候打开就可以了。”</p><p>所有人下了楼，接下来参观的是此行的重头戏——祈祷室。</p><p>明里打开一楼祈祷室的门。一进门，就是一排坐垫，坐垫前摆着一尊雕像，虽然灯光较暗看不清，但凭味道也能感受到生锈的迹象。黑暗中，看不见雕像的五官，甚至无法看清身体轮廓，只是视觉告诉自己雕像的存在，仿佛意味着神是无形的。</p><p>“这是地狱之神。第一层是用于驱散厄运的祈祷室，跪在地狱之神前祈祷，地狱之神会杀死祈祷者身上的厄运之鬼。”</p><p>毕一宇看着那几张坐垫，十几年来无数社员都曾跪在这，单薄的坐垫竟要撑起十几年间信徒的祷告。</p><p>“上楼吧，楼上才是天堂。”祈祷室里面有单独的楼梯，连通一楼和二楼。</p><p>二楼的祈祷室意外的敞亮，不过也说不上意外，毕竟是天堂。墙壁上挂满了灯，周围再无其他杂物，只有房间中央的一个圆台。圆台有点高，正常人站着是摸不到顶的。</p><p>“这个圆台是用来做什么的？”毕一宇问道。</p><p>“其实这个圆台是礼帽的帽盖。”副社长雨桐纠正了毕一宇的问法。</p><p>“帽盖加上地板，便是一顶礼帽。还记得六点时念的咒语吗？”</p><p>“Uneasy lies the heads that wear hats……啊原来如此!”</p><p>“我们祈祷时会将自己的信物放到帽顶上，如你所见，帽顶很高，正常来说还要跳一下才能放上去。”陆子雯解释道，并跳着把自己胸前的十字架放了上去。一头红发像是在空中飞舞的火焰。</p><p>“看，就是这样。也是某种程度上的uneasy吧哈哈。”</p><p>“二楼没有雕像什么的吗？”</p><p>“都说了，祈祷社不限定社员的主，大家只需要向自己心中的主祈祷就行了。”萧彩萌对毕一宇的健忘症感到丢脸。</p><p>毕一宇发现二楼的祈祷室有一扇门。门十分破旧，像是很久都没人打开过。</p><p>“彩萌小姐，这扇门是？”毕一宇的手向风烛残年的门把手伸去。</p><p>“打开这扇门就是重生馆的二楼了，可以去二楼的各个房间……诶你别，不是那样扭的！”</p><p>萧彩萌的警告已经来不及了，在毕一宇的胡乱扭动下，把手被扭掉了。</p><p>“怎……怎么办？”</p><p>把手连同锁芯一起脱落，毕一宇手拿着门锁的残骸，茫然地看着已经无法使用的门。</p><p>“想想怎么它插回去，快，明里他们还没注意到，真是，第一次来就搞破坏。”</p><p>毕一宇狼狈地把把手塞回去，虽然无济于事。</p><p>“这扇门已经开不了，这可是祈祷室的门啊！”</p><p>“抱歉抱歉，事后我会赔偿明里小姐的。还请先别告诉他们。”</p><p>“哎，都是最后一次了。”</p><p>最后一次参加社团活动，应当拿出平时百倍的虔诚。</p><p>毕一宇和萧彩萌跟着明里他们下了一楼，客厅里温暖的火炉与柔软的沙发恭候着他们。</p><p>“现在是六点四十五，大家，十二点钟集合就行，自由活动吧。”明里像是老师一样宣布下课，便回二楼房间了，脚步声消失在走廊深处。</p><p>萧彩萌看着失了神的毕一宇，“喂，我们也房间吧，休息一下就准备祈祷了。”</p><p>“啊？彩萌小姐也要回我房间吗？”</p><p>萧彩萌啪的一声拍了下毕一宇的后脑勺。</p><p>“笨蛋！我是说，我们回各自的房间，我房间也在二楼。”</p><p>还没等毕一宇做出反应，萧彩萌便走上楼梯，不一会背影消失了。</p><p>“等等我！”毕一宇快步走上二楼。</p><h2 id="section-4">05</h2><p>毕一宇躺在床上，思考着今天发生的事情。柔软的床仿佛将他吞噬。</p><p>“真倒霉啊，把明里小姐的衣服弄脏，还把祈祷室的门锁给搞坏了，哎……”</p><p>不过宽宏大量的明里一定会原他的吧，毕一宇幻想着。自从毕一宇见到为他们开门的明里时，毕一宇就被她的笑容所深深吸引，再加上品尝了明里的饭菜，一个完美妻子的形象在毕一宇的脑袋里勾勒出来。</p><p>如果明里是我的妻子就好了，肯定很多男生这样想吧，至少社员们都是。</p><p>“虽然Z大和H大离得有些远，但每周来一次也不会很麻烦吧。”毕一宇脑子里已经开始制定追求明里的计划了。</p><p>“首先，明里是祈祷社的社长，那她一定很喜欢与神、宗教有关的事物。嗯，我也得了解下才行，不然以后都没共同话题了。”</p><p>“还有，萧彩萌说，明里是H大医学部的学生，医学方面的知识我应该没问题，平时我可是看了很多医疗剧的。”</p><p>“不知道明里喜不喜欢看推理小说呢？”毕一宇没忘记自己是Z大推协成员的身份。“如果没看过要怎么给他推荐呢？应该看过吧，女生或多或少都看过东野圭吾的作品吧。”</p><p>“不行，我得亮出我资深推理迷的身份才行，一上来就列举各种冷门名著，各种理论，这样她就会崇拜我了。”</p><p>毕一宇脑子里的计划一步步构建起来。</p><p>“还需要萧彩萌来搭桥牵线，让她以后多邀请我参加他们的聚会，增加我和明里的接触机会。”</p><p>毕一宇想着未来各种约会的场景。温暖的咖啡厅，入口即化的提拉米苏；街灯下两人手牵着手，影子变短又拉长，一步、两步、三步……</p><p>咚咚咚！</p><p>什么声音，是心跳吗？</p><p>咚咚咚！</p><p>微弱的心跳，是离得太远了吗？</p><p>“毕一宇先生，您在房间里吗？”</p><p>毕一宇猛的从床上坐起身来。一看时间，已经七点半了。自己迷迷糊糊地睡了一觉。</p><p>“门外有人在叫我吗？”</p><p>毕一宇摇摇晃晃地走去开门。</p><p>门一打开，一个男子静静地守在门口。</p><p>“你是？”</p><p>“毕一宇先生，您忘记我了吗？我是祈祷社的副社长雨桐。”</p><p>毕一宇这才擦亮眼睛。雨桐回房间后换了一套新衣服，也难怪毕一宇没认出来。</p><p>“哦哦，有什么事吗，副社长？”</p><p>“嗯，进你房间说吧，如果你方便的话。”</p><p>毕一宇没有拒绝的余地。</p><p>两人走到房间的桌前坐下，毕一宇想给雨桐倒杯水，结果意识到自己一会房间就睡了，根本没有去烧水。</p><p>“毕一宇先生，”雨桐率先发话，“听说你是Z大推协的成员是吗？”</p><p>“嗯是的。”是萧彩萌告诉他的吗？</p><p>“我本是祈祷社的副社长，但你知道的，祈祷社要解散了。”</p><p>“嗯。”毕一宇点点头。</p><p>“平时我也对推理小说感兴趣，所以，想在废社之后加入我们H大的推协。”</p><p>“好啊，不错的想法。”</p><p>“这次来就是想向您请教下推理方面的问题。”</p><p>“我的荣幸。”</p><p>接下来的一段时间两人一直在房间里探讨推理，直到那件事的发生。</p><h2 id="section-5">06</h2><p>“那件事处理的怎么样了？”萧彩萌在和巴布亚通电话。</p><p>“本来就不是什么大事啦，刚刚已经到学校了。”</p><p>“跟你讲啊，毕一宇真是个笨手笨脚的家伙。”</p><p>“怎么说？”</p><p>“他呀，先是溅了明里一身酒，又把二楼祈祷室的门锁给搞坏了。”</p><p>“他肯定是紧张了，说不定，他喜欢明里呢。”</p><p>“真有可能！”</p><p>“好了好了，你不是九点就要去祈祷室了吗？还是休息一会儿吧。”</p><p>“是呀，亏你还记得。”</p><p>“那是，前几年不都是我陪你来的吗。”</p><p>“嗯，晚安啦。”</p><p>萧彩萌挂断了电话。</p><p>上次来这个房间还是一年前，房间依旧保持着原貌，可以想象得出祈祷社的成员对重生庄的保养十分用心。</p><p>萧彩萌调暗了床头的台灯，钻进温暖的被窝。窗外无言的白雪躺在地上，坚韧的树枝没被大雪压垮，远远望去，枝头像是涂满奶油般光滑。冬天的月光绝对可以用吝啬一词来形容，黑夜笼罩着重生庄。</p><p>事实上，静谧的美梦很快被敲门声打破了。</p><p>砰砰砰！</p><p>不知是谁在用力地敲门，不，用砸门更为贴切。</p><p>现在的时间是八点半。</p><p>从梦中惊醒的萧彩萌跑去开门。门外是一脸慌张的毕一宇，副社长雨桐也站在旁边。</p><p>“彩萌小姐，快！明里小姐她……”</p><p>“怎么回事？”</p><p>“明里小姐她不见了！”</p><p>“不见了？房间里没有吗？”</p><p>“准确来讲，不见的是明里社长的头。”雨桐显得格外冷静。</p><p>萧彩萌一行人连忙奔向明里的房间。房门已经打开，血腥味扑面而来。</p><p>“这是……”</p><p>床上躺着一具裸体的无头女尸，白色的床单已经被血染成红色，地毯上也是大片大片的血迹。有一道血迹穿过门，在走廊的雪白地毯上留下一条红线，更诡异的是，血迹拐弯朝二楼栏杆走去，随后消失不见。萧彩萌往楼下一看，血迹继续蔓延，朝着一楼的祈祷室蔓延。像是什么东西带着血从二楼栏杆一跃而下，然后进入祈祷室。</p><p>直觉告诉他们，这就是明里的头移动的痕迹。</p><p>“祈祷室那里有人吗？”</p><p>“其他社员已经去祈祷室了。”</p><p>三个人下到一楼，继续沿着栏杆下的血迹，走进祈祷室。</p><p>盘旋的楼梯让人感觉二楼异常的高。几位社员正呆呆地站在圆台旁，注视被摆上帽顶的头颅——明里安详的面孔注视着前方。</p><p>“怎么会……”陆子雯双腿无力地跪下，红发失去了光泽。</p><p>“难道真的要拿人头献祭才是绝对虔诚的表现吗？”安先生双手插兜，一副对真相了然于心的样子。</p><p>毕一宇走上前，想要跃起把明里的头颅拿下来，却被身后的雨桐制止了。</p><p>“万万不可，”雨桐坚定的眼神看着毕一宇，“这是仪式，有人斩下了明里社长的首级，摆在帽顶之上，是想实现最后的祈祷。”</p><p>“非要砍人头不可吗？”毕一宇语气中带着愤怒。</p><p>“Uneasy lies the heads that wearhats，凶手固然可恨，但咒语就是这样。还请毕一宇先生先不要报警，不然我们的祈祷活动会被打扰。”</p><p>毕一宇无法接受明里因为这样的原因而被斩首的事实。</p><p>“毕一宇，你是怎么发现明里小姐被斩首？”萧彩萌想起是毕一宇把自己叫醒。</p><p>“是这样，七点半时雨桐来我房间找我讨论问题，我和他都挺好奇重生庄未来会怎么样，我很想提议用来作为解谜游戏的场所，于是我和雨桐就去找明里了。”</p><p>“我们在路上看到了从房间中蔓延出来的血迹，意识到不对劲，就冲过去打开房门，结果就发现了这样的惨状。”</p><p>其他社员也是被二楼的动静所惊起，见状后就跑向一楼的祈祷室。</p><p>一道血迹越过二楼栏杆来到一楼，走进祈祷室，爬上蜿蜒的楼梯，何人跃起，将首级置于帽顶。犯人曾跪在这祈祷吗？毕一宇低头俯视着地板。可笑的是，明里竟是被虔诚之心所杀。</p><p>突然，耳边再次传来沉吟。毕一宇抬起头，看到社员们双手合十，闭着眼，嘴里念着什么。就连萧彩萌也跟着祈祷，毕一宇只好学着做动作。</p><p>什么主、信仰的，不是很扯吗？所爱之人死得如此荒唐，众人却仿佛置身事外，袖手旁观。毕一宇双手紧扣，指甲嵌入肉里。</p><p>“用推理为明里报仇吧！”毕一宇在心里壮烈地宣誓。</p><p>窗外的雪又下了起来，仿佛要将亡灵埋葬。</p><h2 id="section-6">07</h2><p>众人聚集在客厅里。火炉里的火摇曳着燃烧，发出响声。</p><p>“大家，方便的话，说说在明里小姐回房间后的行踪吧。”毕一宇肩负起侦探的责任。</p><p>坐在沙发上的安先生举起了手，“我先说吧。”</p><p>毕一宇从口袋里掏出随身携带的笔记本。</p><p>“六点四十五的时候，明里社长就回房间休息了。七点钟左右，客厅里的大家也都跟着回各自房间了。我在房间里睡了一会，就回餐厅去了。”</p><p>“回餐厅？你去那做什么？”</p><p>安先生举起自己手上的书。</p><p>“房间里的灯太暗了，我想在餐厅里吊灯下看会书。”</p><p>“你记得你看书的时间吗？”</p><p>“我到餐厅时是七点十五，之后我就一直在餐厅看书，八点半的时候听到二楼你们的喊叫。”</p><p>“好的，这期间你有看见过谁经过这吗？”</p><p>毕一宇明白，如果从二楼走楼梯把头运下来必须经过餐厅，这样的话就会被安先生看到。</p><p>“额，没有人，虽然视野范围只有餐厅前的过道，但我想我应该没有看漏。”</p><p>看来头真的是从二楼栏杆被扔下来，毕一宇知道这意味着什么。</p><p>“那么，下一个，莱斯特先生。”</p><p>莱斯特把轮椅转向毕一宇。</p><p>“你好，侦探先生，我能理解你对真相的热情，我对明里社长的死感到惋惜。”</p><p>“请问你在七点之后做了什么。”</p><p>“我的房间在一楼，你知道的，我爬楼梯要费很大力。我一直待在我的房间，七点十五的时候明里小姐来我的房间找过我。”</p><p>“什么？你是说七点十五明里小姐还活着是吗？”</p><p>“正是如此。”</p><p>“你们当时做了什么？”</p><p>“明里社长是想询问我之后的去向，祈祷社不是要解散了吗？社长很关心成员们的未来。”</p><p>“当时明里小姐有什么异常的吗？”</p><p>“异常？没什么异常，跟在餐桌上表现一样呀，衣服上还沾着你泼的酒渍呢，我想你不会忘记的。”</p><p>毕一宇本想警告他不要开玩笑，但仔细一想他也说的没错。</p><p>“嗯，我知道了，明里小姐走后你就一直呆在房间是吧。”</p><p>“正确，她大概带来三四分钟就走了。之后我就躺在床上休息，直到被你们的吵闹声吵醒。”</p><p>毕一宇挥舞着圆珠笔，在本子上记下。</p><p>“大侦探，您瞧瞧我这腿伤。”莱斯特指了指自己的右腿。“只能勉强走路。”</p><p>“这些问题我会最后统一询问。”毕一宇不想忽略任何一个嫌疑人。</p><p>陆子雯一副失了魂的样子，蜷缩在火炉前，像极了卖火柴的小女孩。</p><p>“陆子雯先生？”</p><p>毕一宇叫了他好几遍，他才慢慢把视线挪向毕一宇。</p><p>“好可怕，侦探，好可怕。”陆子雯颤抖吐出几个字，看来他被那场景吓得不轻。</p><p>“放轻松，你只要告诉我七点以后你在做什么就行了。”毕一宇安抚着嫌疑人，他身上的皮衣已经起皱了。</p><p>“我……我回到了我二楼的房间，然后……去了祈祷室。”</p><p>毕一宇瞪大眼睛，“你说你去了祈祷室？什么时候？为什么？”</p><p>“是七点半的时候，我……我发现我口袋里的一个东西不见了，心想是不是……在二楼祈祷室里跃起的时候……从口袋里飞出来了，于是……于是我就去二楼祈祷室寻找。”</p><p>“嗯，找到了吗？”</p><p>“找到了。”</p><p>“那你，”毕一宇有点犹豫，“那你那时候看到明里小姐的头颅了吗？”</p><p>“啊！！！”陆子雯尖叫了起来，他疯狂地抓着头，在地毯上打滚。</p><p>众人花了好长时间才让他冷静了下来，陆子雯眼珠充满了血丝。</p><p>“可以回答我的问题了吗？”</p><p>“没……没有看到，我找到东西就走了，没有看到明里社长的头……啊！”眼看陆子雯又要发疯了，众人赶紧把他按住。</p><p>“最后问一遍，你找到东西然后呢？”</p><p>“我……我在一楼和二楼的祈祷室里祈祷，一直到八点十五。”</p><p>“八点十五？”</p><p>“对……我看到祈祷室里的钟了。之后就回房间睡了一会……直到你们叫醒我。”</p><p>“好吧好吧，大家赶紧把他送回房间休息。”毕一宇命令道。</p><p>安先生放下手中的小说，和雨桐两人一前一后把陆子雯抬回房间。</p><p>“毕一宇，你有什么想法吗？”萧彩萌看着毕一宇一个人问了那么多话。</p><p>“还行吧，有点头绪，只是，我好渴啊！”毕一宇端起桌上的水一口闷了，唇焦口燥之时，水就像酒一样甘甜。</p><p>“这次你要好好表现哦，”萧彩萌站在毕一宇身旁，目光望着窗外，玻璃上映着两人的影子。</p><p>“为了明里。”</p><p>“嗯，我会找出凶手的。”毕一宇更像是对自己发誓道。</p><p>安先生和雨桐安置好陆子雯后回到了客厅。两人瘫软在沙发上，但毕一宇不想给他们喘息的机会。</p><p>“雨桐先生，虽然你七点半和八点半一直和我在一起，方便的话，可以告诉我你七点到七点半的行踪吗。”</p><p>“我直接回了房间，本来在床上睡了一两分钟，结果实在受不了身上的酒味，就去洗了个热水澡。”</p><p>“原来如此，在那之后你还见过明里小姐吗？”</p><p>“没，洗完澡后我就直接来找你了。”</p><p>这么说的话，最后一个见到明里的就是莱斯特吗？</p><p>“毕一宇先生应该能确保我在七点半到八点半的不在场证明吧？”</p><p>“话是这么说……”</p><p>毕一宇不知在纠结什么，他不停地在本子上写写画画，萧彩萌回想起自己在算圆锥曲线大题时的样子。</p><p>“顺便问下，彩萌小姐那段时间在做什么？”</p><p>萧彩萌怎么也想不到毕一宇竟会怀疑自己。</p><p>“我，我和巴布亚通了会电话就睡着了，最后被你的敲门声吵醒。”</p><p>“懂了，又是一个没有不在场证明的。”</p><p>萧彩萌一时分不清是不是玩笑话，总感觉，毕一宇好像认真起来了。</p><p>人头从二楼丢下，又被运上祈祷室的二楼，诡异的血迹，众人的证词，一股恐惧感笼罩着重生庄。除了陆子雯在房间休息其余人都在客厅，明明火炉还在燃烧，室内的空气却变得异常寒冷。安先生端着书，也不知道是否是在假装冷静。</p><h2 id="section-7">08</h2><p>毕一宇在客厅里到处徘徊，众人不敢出声，似乎在等他给出答案。已经是十一点半，离祈祷的时间只剩半个小时。雪已经堆满窗沿。</p><p>“不耽误大家时间了，我来说说我的推理吧，你们谁去把陆子雯叫起来？”</p><p>雨桐作为副社长承担起这个义务，他扛着半睡半醒的陆子雯做到沙发上。</p><p>毕一宇像是老师一样站在大家面前，沙发上的学生们屏息敛声。</p><p>“我希望我在推理的时候大家不要打断我，我做的只是从各位的证词中推理出真相，其他的我暂时不考虑。”</p><p>“首先，大家都承认自己的证词百分百准确没问题吧。”</p><p>社员们点了点头。</p><p>“如果真是这样的话，这不是很奇怪吗？明明大家的证词存在很大的漏洞。”</p><p>众人面面相觑。</p><p>“我们先从现场的情况来看，大家还记得那道血迹吧，凶手一定是砍下明里小姐的头后，将其从栏杆处扔到一楼。”</p><p>“但如果直接扔下的话，一定会引起很大的声响，很有可能引起别人的注意。而且，凶手就算将头从二楼扔下，自己也还是要走楼梯下一楼，这和自己拿着头走楼梯下一楼有什么区别呢？明明都存在下楼梯被别人看到的风险。我们不难推测，凶手之所以会选择从二楼栏杆处扔下，而不是自己走楼梯下去前往一楼的祈祷室，正是因为他知道前者的风险比后者小。其实，我想说的是，凶手把明里小姐的头从二楼扔下后，一楼的对应位置有人会帮他接住，之后再按照规定从一楼的祈祷室上到二楼的祈祷室。”</p><p>“也就是说，凶手有两个人。”</p><p>“接下来我将列出所有的凶手可能。”</p><p>“首先，我们要做的是证明社员四人中存在凶手。我们不妨把嫌疑人分为两组：安先生和陆子雯一组，记为第一组；莱斯特和雨桐一组，记为第二组。”</p><p>“在第一组中，我们需要证明存在凶手。我们由安先生的证词得出，七点十五到八点半无人经过餐厅前，即无人从二楼下来前往一楼的祈祷室。我们再看陆子雯的证词，住在二楼的他于七点半到八点十五前往二楼的祈祷室寻找遗失的物品并呆在那里祈祷。但是，二楼祈祷室的门锁被我不小心拧坏了，二楼的门根本就不能从外面打开，所以说，如果陆子雯的证词成立，那么他必须从二楼下到一楼的祈祷室，再通过祈祷室里面的楼梯上二楼。安先生确定七点十五到八点半这段时间内无人经过他的面前，而陆子雯声称的七点半到八点十五这段时间又包含在其中，安先生没有看到陆子雯，而陆子雯又确定从二楼下来穿过安先生的视线范围，即二者证词矛盾。”</p><p>“假设安先生是凶手，即陆子雯证词为真，安先生说谎，他那段时间在行凶，自然不知道陆子雯的行迹，那么我们的目的达成，成功在两人中找出凶手安先生；假设陆子雯是凶手，即安先生的证词为真，陆子雯说谎，那么他那段时间可能正在二楼斩首，根本没有下到一楼，所以他也不知道安先生在餐厅看书，我们的目的达成，在两人中锁定凶手陆子雯。”</p><p>“综上，安先生和陆子雯中有一人是凶手，且两人不可能同时是凶手，不然二人组的证词不会有矛盾。”</p><p>沙发上的两人露出紧张的表情。</p><p>毕一宇继续他的演讲：“同理，在第二组中，我们同样能锁定凶手。”</p><p>“根据雨桐的证词，他七点钟直接回房间洗澡了，于是我们推理出他并没有去公共卫生间开煤气，但事实上他洗的是热水澡，那么一定是有人提前开了煤气洗澡。住在二楼的我、萧彩萌、陆子雯都没有洗澡，那么只能是明里开了煤气洗澡。再看莱斯特的证词，他声称自己在七点十五时见到身穿沾着酒渍的白色卫衣的明里。这就很奇怪了，按照雨桐的说法，明里在他洗澡前已经打开煤气洗澡了，洗完澡后怎么还会穿着脏衣服去找莱斯特呢？证词出现矛盾。”</p><p>“我们在不考虑安先生和陆子雯的证词真假的情况下讨论。假设一，莱斯特是凶手，他的证词是假的，而雨桐的证词是真的，那么事实上莱斯特并没有和明里见面，他找了个死无对证的人做不在场证明，但住在一楼的他不知道二楼的煤气已被明里打开；假设二，雨桐是凶手，莱斯特的证词为真，七点到七点半那段时间雨桐并没有洗澡，正在参与杀人，并不知道这期间莱斯特与明里曾见过面。”</p><p>“综上，雨桐和莱斯特中必定有一个人是凶手，且根据证词矛盾，两人不可能同时为凶手。”</p><p>萧彩萌像是双腿被冻在地毯上一般，没想到毕一宇在这么短时间内已经推理到这种地步。</p><p>“别急，接下来才是重点。”毕一宇端起茶几上的茶杯又是一口闷。</p><h2 id="section-8">09</h2><p>“安先生和陆子雯中有且仅有一人是凶手，莱斯特和雨桐中有且仅有一人是凶手，再加上我之前凶手有两人的推论，我们不难得出以下的凶手组合：安先生和莱斯特、陆子雯和莱斯特、安先生和雨桐、陆子雯和雨桐。”</p><p>“如果按照排列组合，理论上四个人中可以找出的组合总共有六种，剩下的两种情况为安先生和陆子雯以及雨桐和莱斯特。但这两种组合都因内部证词矛盾而排除。”</p><p>“注意一个推理前提，我们在假设两人为凶手时，剩下两人的证词就是真证词，可以用来当做推理的材料。”</p><p>“首先，我们讨论安先生和莱斯特以及陆子雯和莱斯特的情况。既然参与杀人的有两人，职务分别为斩首和运首，我们自然要去推测凶手两人在此次案件中分别充当什么角色。对于莱斯特先生，我们注意到他的假证词——七点十五见过明里穿着脏衣服，而在莱斯特是凶手的情况下，雨桐的证词即为真，明里小姐已经打开煤气洗澡，所以那个时间不可能穿着脏衣服。而莱斯特如果是参与斩首，他不仅要将明里小姐的头斩下，还要将她的衣服脱光——别忘了我们进去时看到的是无头裸体女尸，也就是说，莱斯特一定是知道那时候明里小姐已经换了干净的衣服，那他又何必撒他本就知道不成立的谎话呢？所以在莱斯特是凶手的情况下，他不可能是参与斩首的那一方，他必定是参与运首。回顾案发现场，安先生和陆子雯之中的凶手将头从二楼丢下，莱斯特在一楼接住，接着进入一楼的祈祷室，通过里面的楼梯爬上二楼，最后成功将头颅置于帽顶之上。但不要忘记，帽顶很高，若要将首级放上去必须跳起，而对于右腿受伤的莱斯特来说，如果走路爬楼梯勉强可以的话，双脚离地跳起这种事是绝对做不到的。另一方面，莱斯特走楼梯上二楼并趁着明里小姐睡觉的时候将其斩首的可能性更大，也就是说，莱斯特参与杀人，由于他的身体缺陷，他应该是参与斩首的一方，但这又与他的证词矛盾——本应知道事实却说出不符事实的证词。”</p><p>“综上，在安先生和莱斯特、陆子雯和莱斯特的组合中，莱斯特既不能参与斩首，又不能参与运首，但凶手必须是两人，所以，含有莱斯特的凶手组合全部排除。”</p><p>毕一宇在空中比划了两个大叉。莱斯特如释重负地靠在椅背上，长舒一口气。</p><p>“接着，我们再来讨论安先生和雨桐的凶手组合。此时陆子雯和莱斯特的证词就是真证词，可以用来当做推理材料。根据陆子雯所陈述的事实，他七点半到八点十五在祈祷室里，所以这期间不可能发生杀人事件，否则前来运首的人一定会与陆子雯相遇，那么凶手两人的作案时间一定是在八点十五到八点半之间。但事实上，作为凶手的雨桐从七点半到八点半就和我在一起，我能证明他此时间段的不在场证明，所以这段时间他不可能参与斩首或运首。对了，你们可能想问，陆子雯是七点半到八点十五在祈祷室，难道七点到七点半这段时间不能行凶吗？从时间上来说确实可行，但别忘了，陆子雯在祈祷室并没有看到人头，即斩首和运首尚未开始，所以在陆子雯去祈祷室之前不可能行凶。”</p><p>“综上，在安先生和雨桐为凶手的情况下，雨桐不可能行凶，所以这一组并不是真正的凶手组合。”</p><p>毕一宇又在空中划了个大叉。此时的沙发上，除了莱斯特，所有人都仿佛忘记了呼吸。火炉里的火摇曳着。</p><p>“最后，只剩下陆子雯和雨桐的凶手组合，真相浮出水面。”</p><p>萧彩萌没想到真相来得这么快，刚想夸赞毕一宇时，谁知毕一宇又泼了自己冷水。</p><p>“诸君，排除法的推理虽然巧妙，但在享受真相的果实之前，不妨先鉴别一下口味，按照我之前的推理模板。”</p><p>“讨论陆子雯和雨桐的凶手组合，在此情况下，安先生的证词是真的，即七点十五到八点半我们发现尸体时没有人经过餐厅前，也就是说没有人从二楼下到一楼进入祈祷室，但事实上，雨桐和陆子雯都是住在二楼，两人中必有一个人要下楼在指定位置接住二楼扔下的首级，并运送至祈祷室。由此得知，凶手的作案时间应该是安先生到达餐厅看书之前，也就是七点到七点十五分。这段时间内，明里小姐已经被斩首杀害，但不要忘记，在雨桐是凶手的情况下，莱斯特的证词为真，也就是说，他在七点十五见过活着的明里小姐，并且交谈了两三分钟。由此得出，凶手二人并未在七点到七点十五杀害明里小姐。”</p><p>“综上，陆子雯和雨桐的凶手组合不成立。”</p><p>毕一宇在空中打上最后一个叉。时钟的时针还有五分钟指向十二点。</p><p>“这不就没有凶手了吗？”萧彩萌被毕一宇的推理搞得晕头转向。</p><p>“按照以上推理，是这样没错。”</p><p>“当然，前提是凶手在以上人员当中。”</p><p>话音未落，所有人的目光都齐刷刷地看向毕一宇。</p><p>“你是说，凶手可能是我们之外的人？”</p><p>“我想是这样没错。”</p><p>“时间不多了，我尽快说明。既然凶手不在四位社员之中，那四位社员的证词怎么会出现矛盾呢？原因很简单，实际上证词本身就是不矛盾的，关键在于时间。”</p><p>“事实上，现在距离我们到达重生庄的时候，已经过了一天，也就是说，我们最后一次见到明里，其实是在昨天。”</p><p>“大家不要忘记，明里小姐是学医的，有能力接触到各种药物，她给我们下了特殊的安眠药，让我们以为只是睡了一会儿，实际上睡了二十四小时以上。”</p><p>“这样一来，结合大家的证词，真实的情况是这样的：安先生于第一天晚上七点钟回房休息，于第二天的晚上七点十五起床去餐厅看书；陆子雯与第一天晚上七点半到八点十五前往祈祷室，接着从第一天晚上八点十五睡到第二天晚上的八点半；莱斯特先生于第一天晚上七点十五见到未洗澡更衣的明里小姐，此后便一直睡到第二天晚上八点半；雨桐一回到房间就睡着了，从第一天的晚上七点睡到第二天晚上七点，此时明里小姐早已在见过莱斯特后洗澡更衣，所以雨桐一起床就有热水。”</p><p>毕一宇将自己做的时间轴展示给大家：</p><figure><img src="/2024/07/03/new2/pt3.png" alt="text"><figcaption aria-hidden="true">text</figcaption></figure><p>“就是这样，在明里小姐已经洗完澡后你们睡觉的那段时间内，凶手将明里小姐斩首，将头从二楼抛下，而后自己经过祈祷室的楼梯爬上二楼，将头放于圆台之上。那时候大家都在睡觉，所以自然听不见人头落地的动静。根据以上时间表，凶手办案的时间应该是第一天晚上八点十五到第二天晚上七点。事成之后便逃之夭夭，大雪掩盖了他的足迹。”</p><p>窗外的雪飘荡在夜空中，在屋内的灯光照耀下翩翩起舞。</p><p>“那凶手是？”</p><p>“一切场外人员，总之，不是我们在座的各位。” 咚咚咚……</p><p>深沉的钟声如同老者的低语，每一声都重重地落在心中。已经是晚上十二点，按照规定，祈祷社的所有成员必须去祈祷室祈祷。</p><p>四名成员仿佛听到警报般立马站起来，朝着祈祷室迈着步伐。毕一宇和萧彩萌跟在他们后面。</p><p>推开一楼祈祷室的门，四个社员跪坐在垫子上，低着头，像是思考者雕像，嘴里不断念着听不懂的咒语。垫子还剩下一个，这显然是留给明里社长的，萧彩萌和毕一宇还是站在他们身后，低着头，双手合十，认真地祈祷。</p><p>祈祷完后，雨桐带头起身，领着大家走向二楼，光明一点点吞噬黑暗。</p><p>帽顶上立着明里的头颅。陆子雯奋力一跃，将自己的十字架放到顶部，随后雨桐也将自己的斧头挂架摆上去。待社员们摆好信物后，六个人围着大圆台站成一圈，开始最后的祈祷。</p><p>Uneasy lies the heads that wear hats.</p><p>沉吟之声填满整个祈祷室，流入明里的耳中。</p><p>“明里小姐，我的推理你听得见吗？”</p><p>毕一宇在心中默念着。</p><h2 id="section-9">10</h2><p>祈祷结束后，众人走出一楼祈祷室。时间已经来到凌晨一点，森林里没有邻居，只有重生庄亮着灯。</p><p>“毕一宇先生，谢谢你的推理，我们明天起床后就会离开重生庄，到时还请你把你的推理告诉警方。一定要将犯人绳之以法，一定。”雨桐坚定地握着毕一宇的手。</p><p>道别后，大家回到各自房间。只是萧彩萌却一直跟着毕一宇。</p><p>“彩萌小姐，你的房间不是在那边吗？”毕一宇指了指二楼深处的房间。</p><p>“毕一宇，你就别装了，其实，凶手并不是什么场外之人吧？”萧彩萌单刀直入。</p><p>“什么意思？”</p><p>“时间并没有多过一天哦，明里并没有给我们下什么安眠药。”</p><p>毕一宇冷笑了一声，冷风呼啸着击打窗玻璃。</p><p>“你是怎么发现的？”</p><p>“火啊，火炉里的火，我们来的那天确实是烧着的，但起床后回到客厅时火还在烧啊，如果多过了一天，火早就灭了。凶手该不会闲着没事杀完人还去加柴吧。”</p><p>毕一宇轻轻地鼓了鼓掌，“厉害，看来巴布亚没少教你。”</p><p>“喂，你也别装什么老师了，”萧彩萌推了下毕一宇的肩膀，“你打算怎么办，不找出凶手报仇了？还是说你根本就找不出？你自己的推理结果就是没有凶手。”</p><p>“是的，我在那四人中所作的推理确实没有凶手，但我依然认为凶手就是那四人其中的两人。”</p><p>“哦？那你推理出错了吗？”</p><p>“对，我其实已经知道那个错误点了，不过当时我想将错就错，先给出一个伪解答，让所有人都脱罪，这样才能顺利进行祈祷活动。”毕一宇看向窗外。</p><p>“这也算是帮明里小姐完成最后的心愿吧。”</p><p>“所以说，推理到底哪出错了？”萧彩萌丝毫不关心毕一宇的情话。</p><p>“首先，安先生和陆子雯、雨桐和莱斯特，这两组内部的证言是有矛盾的，这一点没有问题，将凶手分为那四种组合，这也没有问题，关键在于安先生和莱斯特、陆子雯和莱斯特那两组的否定。”</p><p>“我们通过推理确定了莱斯特是运首的，但却因为他的腿伤无法跳跃否定了这种情况。但事实上他真的腿伤了吗？”</p><p>“你是说，莱斯特是假装腿伤吗？”萧彩萌按捺住自己的惊讶，以免吸引其他人的注意。</p><p>“对，其实我从第一眼见到莱斯特时就知道他在假装腿伤。你别忘了，莱斯特声称伤的是右腿，但他却拄的是右拐，如果右腿伤的话应该是左拐才对。”</p><p>“原来如此，也就是说，他在说谎，莱斯特就是凶手，他能够参与运首工作。”</p><p>毕一宇做了个打响指的动作，故意没打出声来。</p><p>“这样的话，凶手的组合就是安先生和莱斯特或者陆子雯和莱斯特了，然后呢？”</p><p>“然后，去睡觉吧！”</p><p>“诶？”</p><p>“我是说，去睡觉，一觉醒来就知道了。”</p><p>萧彩萌心想，所有侦探不过是谜语人罢了。</p><p>“明天早上，去祈祷室二楼看一看就知道凶手组合了。”</p><p>“为什么？”</p><p>“因为Uneasy lies the heads that wearhats，heads是复数哦，如果要完成祈祷，凶手起码还要再杀一个人。”</p><p>“原来是这个意思。”</p><p>“首先，凶手组合中除了莱斯特的另外一人，也就是陆子雯和安先生中的凶手一人，我把他成为第二人。第二人知道莱斯特的腿伤，也知道我做出的推理漏洞，如果我把推理告诉警方的话，只要警方调查一下，凶手就很容易露馅了。所以，如果凶手要免除自己的嫌疑，同时又要继续斩首，会怎么做呢？”</p><p>“他会……把另外两个不是凶手的人杀了？”萧彩萌颤颤巍巍地说出自己的答案。</p><p>毕一宇朝她摇了摇食指，“不不不，这样不就在告诉警方自己是凶手吗？凶手二人，无辜者二人，你说最后活下来的两个人，警方会怎么想？”</p><p>“那，要怎么做呢？”</p><p>“你想，凶手既要活下来，又要免除嫌疑，还要杀人，那么如果他能通过杀人将包括自己的存活者二人伪装成绝对不可能犯罪的组合，他的目的就达成了。”</p><p>“不行，我要被你绕晕了。”</p><p>“你要站在凶手的角度思考这个问题。假设你是第二人，你已经知道侦探关于莱斯特推理的错误，但反过来说，你也确定侦探关于雨桐推理的正确。如果最后剩下的是你和雨桐，那么警方如何调查你都不会有嫌疑。”</p><p>“也就是说，第二人会杀了莱斯特以及陆子雯和安先生中剩下的无辜的人。这样的话，最后活着的两人就是第二人和雨桐，原本会和自己共享嫌疑的凶手莱斯特死了，而毕一宇关于第二人和雨桐的推理又是无懈可击的，对吧？”</p><p>毕一宇又在空中做出打响指的动作。</p><p>“去睡觉吧，明天起床去二楼的祈祷室看看，如果摆着安先生和莱斯特的头颅的话，那么凶手组合就是陆子雯和莱斯特；如果是陆子雯和莱斯特的头颅的话，凶手组合就是安先生和莱斯特。等我们离开重生庄后，我也会把我的推理告诉警方的。”</p><p>“我知道，那么明天早上见。”</p><p>萧彩萌一边挥手一边朝着自己房间走去。</p><p>“我一定会比你先知道结果的，晚安啦。”</p><p>萧彩萌关上房门。雪停了，为重生庄最后的夜晚而驻足。</p><h2 id="section-10">11</h2><p>晨风鼓起窗帘，清晨的阳光穿透玻璃，一缕缕洒在房间的地板上，像是光的地图。</p><p>萧彩萌迷迷糊糊地睁开双眼，已经是早上十点半了。</p><p>“完蛋，这么晚了！”萧彩萌赶紧换好衣服，连刷牙洗脸都顾不上，慌慌张张地跑下楼梯，直奔祈祷室。</p><p>“明明说要第一个知道真相的。”</p><p>推开祈祷室的门，空气中弥漫着新鲜的血腥味。萧彩萌知道，果然又有人被斩首了。</p><p>绕着螺旋的楼梯，一步步爬上二楼，萧彩萌的心情逐渐激动起来。</p><p>来到二楼，一片豁然开朗。萧彩萌目瞪口呆地站在圆台下，凝视着帽顶新出现的人头。</p><p>“没想到，你居然先来了。”</p><p>毕一宇的头颅面目狰狞地瞪着萧彩萌。</p>]]></content>
      
      
      <categories>
          
          <category> 推理のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 拙作 </tag>
            
            <tag> 推理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>斯坦福CS224W</title>
      <link href="/2024/07/02/CS224W/"/>
      <url>/2024/07/02/CS224W/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="参考资料">参考资料：</h2><p>原课程：https://web.stanford.edu/class/cs224w/index.html诸神佬的博客：https://blog.csdn.net/PolarisRisingWar/article/details/117287320b站中文：https://www.bilibili.com/video/BV1RZ4y1c7Co?vd_source=1a36db16e3fec3ccbe040303ff015aabb站讲解：https://www.bilibili.com/video/BV1pR4y1S7GA?vd_source=1a36db16e3fec3ccbe040303ff015aab## 1.图论基础 见离散数学。 1. Heterogeneous Graph (异质图)的例子： -社交网络图：一个人可以与多个人建立联系，每个人可能有不同的属性（如年龄、性别、职业等）。- 生物信息学中的基因调控网络：一个基因可以调控多个其他基因的表达。</p><ol start="2" type="1"><li>异质图和普通图的区别：<ul><li>普通图的边表示节点之间的连接关系，而异质图中的边可以表示不同类型的关系，如合作、竞争等。</li><li>普通图中的节点通常具有相同类型的属性，而异质图中的节点可以具有不同类型的属性。</li></ul></li><li>Bipartite Graph (二分图)的例子：<ul><li>学生与课程的关系图：一个学生可以选择多个课程，一个课程可以被多个学生选择。</li><li>城市与道路的关系图：一个城市可以有多个道路，一个道路连接两个城市。</li></ul></li><li>Directed Graph的例子：<ul><li>交通流量图：每条边表示一条路，边的权重表示车辆的流量。</li><li>电子邮件传递过程：每个节点表示一个人或组织，边表示邮件从一个节点传递到另一个节点的过程。</li></ul></li><li>设计本体图Ontology的方法：<ul><li>确定领域范围和概念：首先明确本体涉及的领域和概念，例如生物学、计算机科学等。</li><li>定义实体和关系：根据领域知识，定义实体（如人、物、事件等）和关系（如“属于”、“发生在”等）。</li><li>设计本体结构和语义约束：确定实体之间的关系类型（一对一、一对多等），并添加适当的语义约束以确保一致性和完整性。</li><li>使用本体编辑器或工具进行建模：可以使用专业的本体编辑器（如OWL、RDF等）或在线工具来创建和维护本体图。</li></ul></li><li>为什么要把图表示成矩阵？<ul><li>矩阵是一种高效的数据结构，适用于表示稀疏图（即边的数量远小于顶点的数量的平方）。在稀疏图中，大部分元素为零，因此使用矩阵可以节省存储空间和计算资源。</li></ul></li><li>从连通域的角度理解“六度空间”理论：<ul><li>“六度空间”理论指的是任何两个人之间最多只需要通过六个人就可以相互认识。这是因为在社交网络中，信息传播通常是通过朋友的朋友的朋友等间接途径进行的。当一个人想要认识另一个人时，他/她可以通过直接的朋友、朋友的朋友、朋友的朋友的朋友等途径将信息传递给目标对象。因此，最多需要经过六个中间人即可实现相互认识。</li></ul></li><li>为什么很多真实场景的图都是稀疏的？<ul><li>许多真实场景中的图形往往是由少量节点和边组成的，这就是所谓的稀疏图。这主要有以下原因：<ul><li>低度连接性：在许多情况下，节点之间的连接性较低，只有少数几条边存在。例如，社交媒体上的好友关系通常只涉及到一小部分用户。</li><li>长路径限制：许多图形结构具有限制路径长度的要求，因为过长的路径可能导致信息传输效率低下或产生冗余信息。例如，生物信息学中的基因调控网络中，某些调控因子可能会抑制与其直接相连的其他调控因子的影响。## 2.传统图机器学习方法 ### a.前言传统的图机器学习即人工特征工程+机器学习。而后面的深度学习GNN可以端到端自动学习特征。</li></ul></li></ul></li></ol><p>本章重点着眼于手工设计无向图三种数据层次上的结构特征，连接关系，做预测问题。### b.节点(node)层面的特征工程 ####找到能够描述节点在网络中结构与位置的特征 · 节点度数 · 节点重要度 ·聚集系数 · 定义的子图的数量 #### 度数缺点在于将节点的所有邻居视为同等重要的 #### 节点重要度 nodecentrality考虑了节点的重要性 - 1eigenvectorcentrality：认为如果节点邻居重要，那么节点本身也重要因此节点v的centrality是邻居centrality的加总。可用矩阵表示。 - 2betweennesscentrality：认为如果一个节点处在很多节点对的最短路径上，那么这个节点是重要的。（衡量一个节点作为bridge或transithub的能力。就对我而言直觉上感觉就像是新加坡的马六甲海峡啊，巴拿马运河啊，埃及的苏伊士运河啊，什么君士坦丁堡，上海，香港……之类的商业要冲的感觉）</p><p>意思就是如果一个链接图上，任意两个节点之间的通路，经过每个点的次数，次数最大的点其重要性最大。- 3closenesscentrality：认为如果一个节点距其他节点之间距离最短，那么认为这个节点是重要的$ c_{v}= $ <img src="https://img-blog.csdnimg.cn/20210528104341763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70">- 5clustering coefficient3：衡量节点邻居的连接程度描述节点的局部结构信息 #### graphlets有根连通异构子图就跟同分异构体一样。 #### 总结——节点特征 -节点在图中的重要性：如度数，centrality - 节点附近的拓扑属性如度数，聚集系数，异构图 #### 讨论就我的理解，大致来说，传统节点特征只能识别出结构上的相似，不能识别出图上空间、距离上的相似### c.边(link)的特征工程 #### 通过已知连接，补全未知连接 <img src="https://img-blog.csdnimg.cn/20210528125510955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70">#### 两种formulations - 1.静态客观图：蛋白质，分子 -2.时间动态预测图：社交网络，论文引用 ####基于相似性进行链接预测：计算两点间的相似性得分（如用共同邻居衡量相似性），然后将点对进行排序，得分最高的n组点对就是预测结果，与真实值作比#### distance-based feature：两点间最短路径的长度 <img src="https://img-blog.csdnimg.cn/2021052813134058.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70">这种方式的问题在于没有考虑两个点邻居的重合度the degree of neighborhoodoverlap，如B-H有2个共同邻居，B-E和A-B都只有1个共同邻居 #### localneighborhood overlap：捕获两节点的共同邻居数 <img src="https://img-blog.csdnimg.cn/20210528131513561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70">cn为共同好友数目 jc为交并比 a-ai为共同好友是不是社牛(好友的好友多)common neighbors的问题在于度数高的点对就会有更高的结果，Jaccard’scoefficient是其归一化后的结果。 Adamic-Adarindex在实践中表现得好。在社交网络上表现好的原因：有一堆度数低的共同好友比有一堆名人共同好友的得分更高。#### 全图邻居 local neighborhoodoverlap的限制在于，如果两个点没有共同邻居，值就为0。 <img src="https://img-blog.csdnimg.cn/20210528131745312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70">但是这两个点未来仍有可能被连接起来。所以我们使用考虑全图的globalneighborhood overlap来解决这一问题。 Katzindex：计算点对之间所有长度路径的条数计算方式：邻接矩阵求幂。邻接矩阵的k次幂结果，每个元素就是对应点对之间长度为k的路径的条数（离散数学里学过）<img src="https://img-blog.csdnimg.cn/20210528132827488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70">discount factor β 会给比较长的距离以比较小的权重。 ### d.全图的特征工程光用node不够的话，可以设置一个degreekernel，用bag-of-degrees来描述图特征 <img src="https://img-blog.csdnimg.cn/20210528142537566.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> - 1.Count the number of different graphlets in a graph即数每种节点组合类型的异构图数目 graphlet countvector：每个元素是图中对应graphlet的数量 <img src="https://img-blog.csdnimg.cn/20210528142911579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> <img src="/2024/07/02/CS224W/image.png" alt="alt text"> graphletkernel就是直接点积两个图的graphlet countvector得到相似性。对于图尺寸相差较大的情况需进行归一化 graphletkernel的限制：计算昂贵 - 2.Weisfeiler-Lehman Kernel：相比graphletkernel代价较小，效率更高。 用节点邻居结构迭代地来扩充节点信息实现算法：Weisfeiler-Lehman graph isomorphism test=color refinement <img src="https://img-blog.csdnimg.cn/20210528145050568.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> <img src="https://img-blog.csdnimg.cn/20210528145133506.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> <img src="https://img-blog.csdnimg.cn/20210528145208716.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> <img src="https://img-blog.csdnimg.cn/20210528145339688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> 经过k次迭代 <img src="https://img-blog.csdnimg.cn/20210528145538976.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> 大佬补充：这个colorrefinement方法与GNN的相似性我认为有二，一在都聚集了节点邻居信息，GNN详情见我撰写的后续课程笔记（就后面好几节课都讲了GNN）；二在在Lecture9中会讲的GIN。 ### e.Node Embeddings 随机游走的艺术-图嵌入表示学习 NodeEmbeddings即将节点映射为D纬向量 <img src="/2024/07/02/CS224W/D:/Blog\themes\butterfly\source\img\jieshi.png" alt="text"> ####前提 -embedding的相似性可以反映原节点在网络中的相似性，比如定义有边连接的点对为相似的点，则这样的点的embedding应该离得更近即矩阵相乘结果更大 #### Node Embeddings: Encoder and Decoder -节点嵌入：目标是将节点编码encode为embeddingspace中的向量embedding，使embedding的相似度（如点积2）近似于图中节点的相似度（需要被定义）- Encoder：将节点映射为embedding定义一个衡量节点相似度的函数（如衡量在原网络中的节点相似度） Decoder DEC将embedding对映射为相似度得分 d一般是64-1000维 <img src="https://img-blog.csdnimg.cn/20210531174822101.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"> -Z每列是一个节点所对应的embedding向量。v是一个其他元素都为0，对应节点位置的元素为1的向量。通过矩阵乘法的方式得到结果。这种方式就是将每个节点直接映射为一个embedding向量，我们的学习任务就是直接优化这些embedding。缺点：参数多，很难scale up3到大型图上。优点：如果获得了Z，各节点就能很快得到embedding。有很多种方法：如DeepWalk，node2vec等 - Encoder + Decoder FrameworkSummary - 节点相似的不同定义 本节课：随机游走random walk定义的节点相似度#### Random Walk Approaches for Node Embeddings P(v∣z_u) 是从 u uu开始随机游走能得到 v 的概率，衡量 u 和 v的相似性，用节点embedding向量相似性算概率。用于计算预测概率的非线性函数：softmax会将一组数据归一化为和为1的形式，最大值的结果会几乎为1。sigmoid会将实数归一化到(0,1) 上 - random walk embeddings - zu转至*zv ~= 点 u 和 v在一次随机游走中同时出现（点 v 在以 u 为起点的随机游走中出现）的概率 -log-likulihood目标函数：对这个目标函数的理解是：对节点 u，我们希望其表示向量对其random walk neighborhood N_R(u)的节点是predictive的（可以预测到它们的出现） - 具体函数如下： <img src="/2024/07/02/CS224W/img/image.png" alt="text"> - 优化random walkembeddings就是找到embedding z z 使L最小化但是计算这个公式代价很大，因为需要内外加总2次所有节点，复杂度达O(|V|^2)：- 为了解决这个分母，我们使用negativesampling的方法：简单来说就是原本我们是用所有节点作为归一化的负样本，现在我们只抽出一部分节点作为负样本，通过公式近似减少计算<img src="https://img-blog.csdnimg.cn/20210531193053831.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BvbGFyaXNSaXNpbmdXYXI=,size_16,color_FFFFFF,t_70" alt="text"></p><h4 id="embedding-entire-graphs">Embedding Entire Graphs</h4><p>任务目标：嵌入子图或整个图G，得到表示向量z_G 可用于： -分类有毒无毒分子 也可以视为对节点的一个子集的嵌入 -1：聚合（加总或求平均）节点的嵌入 - 2：创造一个假节点（virtualnode），用这个节点嵌入来作为图嵌入 - anonymous walk embeddings什么东西？？</p><h2 id="pagerank">3.PageRank</h2><p>PageRank是一种衡量网络中节点重要性的指标，主要思想是如果一个节点被很多重要节点<strong>指向(in-link)</strong>，那么该节点也很重要。可以从flow model / 线性方程组、power iteration（矩阵视角）、websurfer随机游走三种角度来看PageRank。 求解PageRank的方法：poweriteration。 在求解PageRank的过程中会遇到spider traps和deadends的问题，可以通过random teleport解决。 M / G是随机游走的概率转移矩阵。 ### intropagerank的历史地位：搜索引擎、信息检索、图机器学习、图数据挖掘“必读论文；线性代数的优雅应用典范</p><p>理解PageRank的五个角度： - 迭代求解线性方程组 - 迭代左乘M矩阵 -矩阵的特征向量 - 随机游走 - 马尔科夫链</p><h3 id="graph-as-matrix">Graph as matrix</h3><h4 id="相关概念">相关概念</h4><p>将图视为矩阵形式，可以通过随机游走的方式<em>定义</em>节点重要性（即PageRank），通过矩阵分解matrixfactorization(MF)来获取节点嵌入，将其他节点嵌入（如node2vec）也视作MF</p><p>在图中，我们想要定义节点的重要性importance，通过网络图链接结构来为网页按重要性分级rank。以下将介绍3种用以计算图中节点重要性的方法：- PageRank - Personalized PageRank - Random Walk with Restarts</p><p>in-link和out-link:更重要节点的in-links</p><p>这就成了一个递归recursive的问题——要计算一个节点的重要性就要先计算其predecessors的重要性，计算这些predecessors的重要性又要先计算它们predecessors的重要性……#### PageRank定义重要性与权重 - 链接权重与其source page的重要性成正比例- 如果网页i的重要性是r_{i}, 有d_{i}个out-links，那么每个边的权重就是r_{i}/d_{i} -网页j的重要性r_{j}是其in-links上权重的总和 <img src="/2024/07/02/CS224W/image-3.png" alt="alt text"> 从而得到各个r_{i} = ······</p><p>在直觉上我们好像可以用高斯消元法Gaussianelimination来解这个线性方程组，但这种方法不scalable。所以我们寻找更scalable的矩阵形式解法#### 矩阵表示 <img src="/2024/07/02/CS224W/image-4.png" alt="alt text"> ####与随机游走的关系 ## 4.图神经网络 ### Deep Learning for Graphs如果数据集中没有节点特征，可以用指示向量indicatorvectors（节点的独热编码）7，或者所有元素为常数1的向量。有时也会用节点度数来作为特征。set up： - 邻接矩阵 - 节点特征：独热编码，度数等</p><p>将节点映射为d维向量，两个向量的距离表示两个节点的相似程度节点向量特征： - 低纬 - 连续 - 稠密 表示学习：从数据中提取最少必要信息图嵌入、节点表示学习：把节点映射为低维连续稠密向量</p><p>计算图深度一般是二，不用太深。</p><p>我们不能将邻接矩阵和特征合并直接在深度神经网络上使用。主要是因为节点的顺序不像图片和文本那样固定。 #### Graph ConvolutionalNetworks通过节点邻居定义其计算图，传播并转换信息，计算出节点表示（可以说是用邻居信息来表示一个节点）核心思想：通过聚合邻居来生成节点嵌入 <img src="/2024/07/02/CS224W/image-5.png" alt="alt text"> 基础方法：从邻居获取信息求平均，再应用神经网络或者：deep encoder的数学公式：</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习のEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python面向对象编程 (上)</title>
      <link href="/2024/07/01/oop/"/>
      <url>/2024/07/01/oop/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="写在前面">写在前面</h1><p>参考视频(推荐1.5倍速食用)：https://www.bilibili.com/video/BV1A4411v7b2?p=31&amp;vd_source=1a36db16e3fec3ccbe040303ff015aab参考博客：https://blog.csdn.net/qq_41872653/article/details/109256914 #Chapter1、面向对象基本概念 ## 1、什么是面向对象编程？面向对象编程（Object-OrientedProgramming，OOP）是一种常用的编程思想，它强调<strong>万物皆对象</strong>，因此在编程时我们可以将现实世界中的事物抽象成程序中的对象，从而更好实现软件的设计与开发。与传统的基于函数的编程不同，面向对象编程注重于将数据与行为封装在一起，即对象既包含数据状态，还包含可调用的行为方法。</p><p>面向对象编程的特点在于，它具有<strong>封装、继承和多态</strong>三大特性。封装意味着将对象的状态和行为进行封装，使其对外只暴露必要的接口，从而提高了安全性和可维护性；继承指的是某个对象可以继承另一个对象的特性，从而快速构建具有相似属性的对象；多态是指同一种行为在不同的对象上具有不同的表现形式，即在不同的情境下，同一个方法可以被不同的对象进行调用。</p><p>总之，面向对象编程是一种强大的编程方式，它具有高度封装性、灵活的继承性和强大的多态性，通过使用对象作为程序的基本处理单元，实现了数据和行为的有机结合，可以使程序更加高效、结构清晰，并方便管理和扩展。## 2、对象和类的关系对象可以抽象出某个具体的类，类可以实例化成某个具体的对象。</p><h1 id="chapter2类的基本语法">Chapter2、类的基本语法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>:</span><br><span class="line">    d_type = <span class="string">&quot;京巴&quot;</span> <span class="comment">#属性，类属性，类变量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">say_hi</span>(<span class="params">self</span>): <span class="comment">#方法，第一个参数必须是self  self代表实例本身</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;my type is&quot;</span>,self.d_type)</span><br><span class="line"></span><br><span class="line">d=Dog()<span class="comment">#生成一个实例</span></span><br><span class="line">d.say_hi()<span class="comment">#实例、方法</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(d.d_type)<span class="comment">#实例、属性</span></span><br></pre></td></tr></table></figure><h2 id="类的命名要求首字母大写">1、类的命名要求首字母大写。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Money</span>:</span><br><span class="line">    <span class="built_in">print</span>(Money.__name__)<span class="comment">#打印Money类的类名</span></span><br><span class="line">    xxx=Money<span class="comment">#Money作为变量赋值给xxx</span></span><br><span class="line">    <span class="built_in">print</span>（xxx.__name__） <span class="comment">#打印结果还是Money类名</span></span><br></pre></td></tr></table></figure><h2 id="属性相关">属性相关</h2><h3 id="属性相关概念">2、属性相关概念</h3><p>变量是可以改变的量值；属性是“属于某个对象的特性”。变量根据访问位置的不同，分为全局变量和局部变量；属性只能通过对象来访问，所以必须先找到对象————而对象又通过变量名来访问，故也遵循访问权限。### 3、属性添加 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">p = Person()<span class="comment">#创建对象</span></span><br><span class="line">p.age = <span class="number">18</span><span class="comment">#添加属性</span></span><br><span class="line"><span class="built_in">print</span>(p.__dic__ )</span><br></pre></td></tr></table></figure> ### 4、属性修改 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">p = Person()<span class="comment">#创建对象</span></span><br><span class="line">p.age = <span class="number">18</span><span class="comment">#添加属性</span></span><br><span class="line">p.age = <span class="number">123</span><span class="comment">#修改</span></span><br><span class="line"><span class="built_in">print</span>(p.__dict__ )</span><br></pre></td></tr></table></figure>当我们修改没有创建过的属性时： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(p.sex) </span><br><span class="line">报错AttributeError:</span><br></pre></td></tr></table></figure> ### P13、属性删除<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">p = Person()</span><br><span class="line">p.age = <span class="number">18</span></span><br><span class="line"><span class="keyword">del</span> p.age</span><br><span class="line"><span class="built_in">print</span>(p.age)<span class="comment">#AttributeError:</span></span><br><span class="line">先删除属性，再删除引用的变量。</span><br></pre></td></tr></table></figure> ### P14、注意事项 不同对象的属性不能互相访问。 ###P15、类属性-增加属性 万物皆对象，类也可以是一个对象。注意，当我们创建一个类的时候，我们实际上也创建了一些类的内置属性（<strong>name</strong>,__module__等）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Money</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">Money.count = <span class="number">1</span> <span class="comment">#Money看做对象，Money增加count属性</span></span><br><span class="line"><span class="built_in">print</span>(Money.count)</span><br></pre></td></tr></table></figure> ### P17、类属性查询 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Money</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Test</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">one=Money()</span><br><span class="line">one.__class__=Test</span><br><span class="line">最后one只能访问到Test的类属性</span><br></pre></td></tr></table></figure><strong>注意</strong>：一个对象，如果要去访问某个属性，它会优先查找自己有没有这个属性，有就返回；若没有，则在类中找。都没有就报错AttributeError：### P18、类属性修改 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Money</span>:</span><br><span class="line">age=<span class="number">28</span></span><br><span class="line">    count=<span class="number">1</span></span><br><span class="line">    num=<span class="number">666</span></span><br><span class="line">    </span><br><span class="line">Money.age=<span class="number">22</span> <span class="comment">#通过类名-属性修改</span></span><br><span class="line"><span class="built_in">print</span>(Money.age)</span><br></pre></td></tr></table></figure> 注意：不可通过对象修改！one是一个对象，<strong>one.age=99是给one对象增加一个age指向99的属性</strong>，而不是修改类的属性。### P19、类属性删除 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> Money.age</span><br></pre></td></tr></table></figure> 注意：不能通过对象来删除。</p><h4 id="总结类属性操作"><strong>总结类属性操作</strong></h4><p>增、删、改类属性都只能通过类。查询可通过对象和类操作。</p><h3 id="p20类属性的内存存储">P20、类属性的内存存储</h3><p>1）one访问某个属性，实际上访问的是生成的对象里面__dict__字典的值。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Money</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">one=Money()</span><br><span class="line">one.__dict__=&#123;<span class="string">&#x27;age&#x27;</span>:<span class="number">99</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(one.age)</span><br><span class="line">&gt;&gt;&gt;<span class="number">99</span></span><br></pre></td></tr></table></figure> 2）<strong>类</strong>的__dict__属性不能被写，只读。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Money</span>:</span><br><span class="line">    age=<span class="number">20</span></span><br><span class="line"></span><br><span class="line">Money.__dict__=&#123;<span class="string">&#x27;sex&#x27;</span>:<span class="string">&#x27;男&#x27;</span>&#125;</span><br><span class="line">&gt;&gt;&gt;报错</span><br></pre></td></tr></table></figure> 反过来讲，对象的dict可以随便改www ###P21、类属性会被各个对象所共享 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Money</span>:</span><br><span class="line">    age=<span class="number">20</span></span><br><span class="line"></span><br><span class="line">one=Money()</span><br><span class="line">two=Money()<span class="comment">##均指向类的age=20，因为自身没有age属性</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(one.age,two.age)</span><br><span class="line">&gt;&gt;&gt;都是<span class="number">20</span></span><br></pre></td></tr></table></figure> ###P23、限制对象属性的添加__slots__ <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    __slots__ = [<span class="string">&quot;age&quot;</span>]<span class="comment">#限制对象不能添加age属性</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">p=Person()</span><br><span class="line">p.age=<span class="number">6</span></span><br><span class="line">&gt;&gt;&gt;报错</span><br></pre></td></tr></table></figure></p><h2 id="方法相关">方法相关</h2><h3 id="p25概念和作用">P25、概念和作用</h3><p>1.描述一个目标的行为动作2.和函数非常类似，都封装了一系列动作，都可以被调用之后执行一系列行为动作，最主要的时调用方式<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>：</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eat2</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">3</span>)</span><br><span class="line">p = Person()</span><br><span class="line">p.eat2()</span><br></pre></td></tr></table></figure> ### P26、类、对象、类对象、实例对象、实例的叫法规范 ###P27、方法的划分 · 实例方法：第一个参数接受实例 ·类方法：第一个参数接受类 · 静态方法：non划分的依据：方法的第一个参数必须接受的数据类型 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eat2</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;这是一个实例方法&#x27;</span>,self)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">leifangfa</span>(<span class="params">cls</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;这是一个类方法&#x27;</span>,cls)</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">jiangtaifanfa</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;这是一个静态方法&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Person.eat2()</span><br><span class="line">&gt;&gt;&gt;TypeError <span class="comment">#确少self</span></span><br></pre></td></tr></table></figure> ### P28、方法的储存 (1)函数也是对象(2)方法也保存在类的__dict__中，没有在实例当中的 ### P29、要求<strong>使用注意</strong>： 1.语法 2.不同类型的方法的规则3.不同方法的调用 ### P30、实例方法 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#标准调用</span><br><span class="line">class Person:</span><br><span class="line">    def eat(self,food):</span><br><span class="line">        print(&quot;在吃饭&quot;,food)</span><br><span class="line"></span><br><span class="line">p=Person()</span><br><span class="line">p.eat(&quot;potato&quot;)#只需要传一个参数</span><br><span class="line">----------------------------------</span><br><span class="line">class Person:</span><br><span class="line">    def eat(): #报错，因为以为没有要求传self，但p.eat实例调用时硬塞了一个</span><br><span class="line">                实例参数self</span><br><span class="line">        print(&#x27;在吃饭&#x27;)</span><br><span class="line"></span><br><span class="line">p.eat()</span><br></pre></td></tr></table></figure> ### P31、类方法<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line"><span class="meta">    @classmethod </span><span class="comment">#装饰器的作用：在保证原函数不变的情况下，直接给这个函数增加一些功能</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">leifangfa</span>(<span class="params">cls,a</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;这是一个类方法&quot;</span> , a)</span><br><span class="line">        </span><br><span class="line">Person.leifangfa(<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line">p = person()</span><br><span class="line">p.leifangfa(<span class="number">666</span>)</span><br><span class="line"></span><br><span class="line">func = Person.leifangfa</span><br><span class="line">func(<span class="number">111</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure> ### P32、静态方法 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line"><span class="meta">    @staticmethod </span><span class="comment">#装饰器的作用：在保证原函数不变的情况下，直接给这个函数增加一些功能</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">jingtai</span>(<span class="params">cls</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;这是一个类方法&quot;</span>)</span><br><span class="line">        </span><br><span class="line">Person.jingtai()</span><br><span class="line"></span><br><span class="line">p = Person()</span><br><span class="line">p.jingtai()</span><br><span class="line"></span><br><span class="line">func = Person.jingtai</span><br><span class="line">func()</span><br><span class="line"></span><br></pre></td></tr></table></figure> ###P33、不同类型的方法中访问不同类型的属性的权限问题 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    age = <span class="number">0</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">shilifangfa</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(self)</span><br><span class="line">        <span class="built_in">print</span>(self.age)</span><br><span class="line">        <span class="built_in">print</span>(self.num)<span class="comment">#可访问到对象属性</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">leifangfa</span>(<span class="params">cls</span>):</span><br><span class="line">        <span class="built_in">print</span>(cls)</span><br><span class="line">        <span class="built_in">print</span>(cls.age)</span><br><span class="line">        <span class="built_in">print</span>(cls.num)   <span class="comment">#不能通过类访问实例属性</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">jingtaifangfa</span>():</span><br><span class="line">        <span class="built_in">print</span>(Person.age) <span class="comment">#可以通过类访问类属性</span></span><br><span class="line">P = person()</span><br><span class="line">P.num = <span class="number">10</span></span><br></pre></td></tr></table></figure> ###类相关补充 ### P34、补充-元类 类也是由类创建出来的，这个类就是元类。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">num = <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(num.__class__)  <span class="comment">#输出int</span></span><br><span class="line">%------------------------------------------</span><br><span class="line">s = <span class="string">&quot;abc&quot;</span></span><br><span class="line"><span class="built_in">print</span>(s.__class__)   <span class="comment">#输出str</span></span><br><span class="line">%------------------------------------------</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line">p = Person()</span><br><span class="line"><span class="built_in">print</span>(p.__class__)  <span class="comment">#输出Person</span></span><br><span class="line">%------------------------------------------</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">int</span>.__class__)  <span class="comment">#输出type</span></span><br><span class="line"><span class="comment">#其实也是num.__class__.__class___</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>.__class__)<span class="comment">#依然输出type</span></span><br></pre></td></tr></table></figure> <strong>type</strong>即为元类 ###P35、补充-类对象的创建方式 可以class直接创建 也可以调用type函数创建<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">print</span>(self)</span><br><span class="line">xxx = <span class="built_in">type</span>(<span class="string">&quot;Dog&quot;</span>,(),&#123;<span class="string">&quot;count&quot;</span>:<span class="number">0</span>,<span class="string">&quot;run&quot;</span>:run&#125;)</span><br><span class="line"><span class="built_in">print</span>(xxx)</span><br><span class="line"><span class="built_in">print</span>(xxx.__dict__)</span><br><span class="line"></span><br><span class="line">d.xxx()   <span class="comment">#不是d.Dog</span></span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line">d.run()</span><br></pre></td></tr></table></figure> ### P36、类对象创建时，元类的查找机制1.检测类对象是否有明确的__mateclass__属性。2.检测父类中是否存在__mateclass__属性。3.检测模块中是否存在__mateclass__属性。4.通过内置的type这个元类来创建这个类对象 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">查找一般是现在自己里面找，没有就去父类，父类没有就往上找模块，模块没有就是<span class="built_in">type</span></span><br><span class="line"><span class="comment">#1模块级别的指定</span></span><br><span class="line">__metaclass__ = xxx </span><br><span class="line"><span class="comment">#2</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment">#3</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>(<span class="title class_ inherited__">Animal</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="comment">#4</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>:</span><br><span class="line">    __metaclass__ = xxx</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure> ###P37、补充-类的描述 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    关于这个类的描述，类的作用，类的构造函数等等；类属性的描述</span></span><br><span class="line"><span class="string">    Attributes:</span></span><br><span class="line"><span class="string">    count: int 代表人的个数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, disance, step</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        这个方法的作用效果</span></span><br><span class="line"><span class="string">        :param distance:blahblah</span></span><br><span class="line"><span class="string">        :param step:blahblah</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;跑步&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span>  distance,step</span><br><span class="line"><span class="built_in">help</span>(Person)  <span class="comment">#</span></span><br></pre></td></tr></table></figure> ### P38、生成注视文档 ### 属性相关补充### P39、补充-私有化属性的概念和意义 限定属性的访问的方法 ###P40、补充-访问权限测试区域划分 ### P41、补充-访问权限测试区域划分注意：python并没有真正的私有化支持，但是，可以使用下划线完成伪私有的效果。如_y、__z。一个_为保护，两个_为私有化 ### P41、私有化属性-共有属性1.类的内部访问，也就是类的实例方法中 2.子类(延伸类)内部访问3.模块其他位置访问 * 1.类访问（父类，派生类） *2.实例访问（父类实例，派生类实例 4.跨模块访问 import/from xxx import*</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>:</span><br><span class="line">    x = <span class="number">10</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(Animal.x)</span><br><span class="line">        <span class="built_in">print</span>(self.x)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">%----------------------</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>(<span class="title class_ inherited__">Animal</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test2</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(Dog.x)</span><br><span class="line">        <span class="built_in">print</span>(self.x)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">a = Animal()</span><br><span class="line">a.test()<span class="comment">#类的内部访问，通过类内部定义的函数访问</span></span><br><span class="line"></span><br><span class="line">d = Dog()</span><br><span class="line">d.test2()<span class="comment">#延伸类的访问（通过延伸类内部定义的函数访问）</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(Animal.x)<span class="comment">#模块的其他部分</span></span><br><span class="line"><span class="built_in">print</span>(Dog.x)</span><br><span class="line"><span class="built_in">print</span>(a.x)</span><br><span class="line"><span class="built_in">print</span>(b.x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xxx              <span class="comment">#模块的其他部分访问</span></span><br><span class="line"><span class="built_in">print</span>(xxx.a)</span><br><span class="line"><span class="keyword">from</span> xxx <span class="keyword">import</span> *</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure><h3 id="p42私有化属性-受保护的属性">P42、私有化属性-受保护的属性</h3><p>_y:一个下划线 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>:</span><br><span class="line">    _x = <span class="number">10</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(Animal._x)</span><br><span class="line">        <span class="built_in">print</span>(self._x)</span><br><span class="line">     <span class="keyword">pass</span></span><br><span class="line"><span class="comment">#--------------------</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>(<span class="title class_ inherited__">Animal</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test2</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(Dog._x)</span><br><span class="line">        <span class="built_in">print</span>(self._x)</span><br><span class="line">     <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">a = Animal()</span><br><span class="line">a.test()<span class="comment">#类的内部访问</span></span><br><span class="line"></span><br><span class="line">d = Dog()</span><br><span class="line">d.test2()<span class="comment">#延伸类的访问</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(Animal._x)<span class="comment">#模块的其他部分,可以强行访问，有警告</span></span><br><span class="line"><span class="built_in">print</span>(Dog._x)</span><br><span class="line"><span class="built_in">print</span>(a._x)</span><br><span class="line"><span class="built_in">print</span>(b._x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xxx              <span class="comment">#模块的其他部分访问,不可访问</span></span><br><span class="line"><span class="built_in">print</span>(xxx.a)</span><br><span class="line"><span class="keyword">from</span> xxx <span class="keyword">import</span> *</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br></pre></td></tr></table></figure> 一般只能在类内部访问，或者子类内部访问。### 43、私有化保护-私有属性 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>:</span><br><span class="line">    __x = <span class="number">10</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">self</span>):         <span class="comment">#定义一个实例方法</span></span><br><span class="line">        <span class="built_in">print</span>(Animal.__x)</span><br><span class="line">        <span class="built_in">print</span>(self.__x)</span><br><span class="line">     <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>(<span class="title class_ inherited__">Animal</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test2</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(Dog.__x)</span><br><span class="line">        <span class="built_in">print</span>(self.__x)</span><br><span class="line">     <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">a = Animal()</span><br><span class="line">a.test()<span class="comment">#类的内部访问，可以访问</span></span><br><span class="line"></span><br><span class="line">d = Dog()</span><br><span class="line">d.test2()<span class="comment">#延伸类的访问，不可以访问</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(Animal.__x)<span class="comment"># 模块的其他部分,不可访问</span></span><br><span class="line"><span class="built_in">print</span>(Dog.__x)</span><br><span class="line"><span class="built_in">print</span>(a.__x)</span><br><span class="line"><span class="built_in">print</span>(d.__x)</span><br><span class="line"></span><br><span class="line">a = <span class="number">1</span></span><br><span class="line"><span class="keyword">import</span> xxx              <span class="comment">#模块的其他部分访问,不可访问</span></span><br><span class="line"><span class="built_in">print</span>(xxx.a)</span><br><span class="line"><span class="keyword">from</span> xxx <span class="keyword">import</span> *</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br></pre></td></tr></table></figure> ###45、补充-私有属性的应用场景 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="comment">#作用：当我们创建好一个实例对对象之后，会自动调用这个方法，来初始化这对象</span></span><br><span class="line">    <span class="comment">#init是单词初始化initialization的省略形式</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>)</span><br><span class="line">    self.__age = <span class="number">18</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setAge</span>(<span class="params">self,value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(value,<span class="built_in">int</span>) <span class="keyword">and</span> <span class="number">0</span>&lt;value&lt;<span class="number">200</span>:</span><br><span class="line">        self.__age = value</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;您输入的数据有误，请重新输入&quot;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getAge</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__age</span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line">p1 = Person()</span><br><span class="line">p1.setAge(<span class="number">20</span>)</span><br><span class="line">p2 = Person()</span><br><span class="line"><span class="built_in">print</span>(p1.getAge())   <span class="comment">#访问age</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(p1.__age)      <span class="comment">#报错，只能在类内部访问</span></span><br><span class="line"><span class="built_in">print</span>(p2.__age)</span><br><span class="line"></span><br></pre></td></tr></table></figure> ### P48、只读属性-方案1<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init</span>(<span class="params">self</span>): <span class="comment">#初始化方法，通过方法设置属性</span></span><br><span class="line">        self.__age = <span class="number">18</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getAge</span>(<span class="params">self</span>): <span class="comment">#部分公开，通过方法实现</span></span><br><span class="line">        <span class="keyword">return</span> self.__age</span><br><span class="line"> p1 = person()</span><br><span class="line"><span class="built_in">print</span>(p1.getAge())</span><br></pre></td></tr></table></figure> ### P49、只读-方案一优化 这节讲得真好，承上启下。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 49-python-面向对象-只读属性-方案一的优化</span></span><br><span class="line"><span class="number">1.</span> ```python</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.__age = <span class="number">18</span></span><br><span class="line">     <span class="comment"># 主要作用：可以以使用属性的方法来使用这个方法</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self</span>):   <span class="comment">#部分公开，通过方法实现</span></span><br><span class="line">        <span class="keyword">return</span> self.__age</span><br><span class="line">p1 = person()</span><br><span class="line"><span class="built_in">print</span>(p1.age())</span><br></pre></td></tr></table></figure> ### P50、property的作用property的作用:将“一些属性的操作方法”关联到另一个属性，间接地管理私有属性。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">C</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getx</span>(<span class="params">self</span>): <span class="keyword">return</span> self._x</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setx</span>(<span class="params">self,value</span>): self._x = value</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delx</span>(<span class="params">self</span>): <span class="keyword">del</span> self._x</span><br><span class="line">    x = <span class="built_in">property</span>(getx, setx, delx)</span><br><span class="line"><span class="comment">#此时，x就是一个属性，可以直接调用x的属性来调用方法</span></span><br></pre></td></tr></table></figure> ### P51、经典类和新式类 - 经典：没有继承object -新式：继承objectPy3中，定义一个类，已经隐式地继承object，默认下已经是一个新式类。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(Person.__bases__)  <span class="comment">#查看父类（基类）</span></span><br></pre></td></tr></table></figure> ### P52、property在新式类中的使用</p><ul><li>property函数方法 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.__age = <span class="number">18</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_age</span>(<span class="params">self</span>):</span><br><span class="line">        ruturn self.__age</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_age</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.__age = value</span><br><span class="line">    age = <span class="built_in">property</span>(get_age, set_age)</span><br><span class="line">    </span><br><span class="line">p = Person()</span><br><span class="line"><span class="built_in">print</span>(p.age)</span><br><span class="line"></span><br><span class="line">p.age = <span class="number">30</span></span><br><span class="line"><span class="built_in">print</span>(p.age)</span><br><span class="line"><span class="built_in">print</span>(p.__dict__) <span class="comment">#输出只有_person__age: </span></span><br></pre></td></tr></table></figure></li><li>装饰器方法 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">       self.__age = <span class="number">18</span></span><br><span class="line"><span class="meta">          @property</span></span><br><span class="line">          <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self</span>):</span><br><span class="line">              <span class="keyword">return</span> self.__age</span><br><span class="line"><span class="meta">          @age.setter</span></span><br><span class="line">          <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self, value</span>):</span><br><span class="line">              delf.__age = value</span><br><span class="line"></span><br><span class="line">   p = Person()</span><br><span class="line">   p.age = <span class="number">20</span>    <span class="comment">#既可以读取也可以设置</span></span><br><span class="line"></span><br></pre></td></tr></table></figure> ### P53、property在经典类中的使用放弃吧，都用新式类叭！ ### P54、只读属性-方案二 总之就是，__age只不过是把他改了个名字，改成_ 类名 __age，你知道他的新名字的话你当然可以改。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">   <span class="comment">#当我们通过实例.属性 = 值，给一个实力增加一个属性，或者修改属性的时候，就会自动调用这个方法，</span></span><br><span class="line">   <span class="comment">#在这个方法内部才会正真地把这个属性，以及对应的数据存储到__dict__字典里面</span></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__settter__</span>(<span class="params">self, key, value</span>):</span><br><span class="line">       <span class="built_in">print</span>(key, value)</span><br><span class="line">       <span class="comment">#1.判定，key，是否是我们要设置的只读属性</span></span><br><span class="line">       <span class="keyword">if</span> key = <span class="string">&quot;age&quot;</span> <span class="keyword">and</span> key <span class="keyword">in</span> self.__dict__.keys():<span class="comment">#只能新增属性，不能修改属性</span></span><br><span class="line">          <span class="built_in">print</span>(<span class="string">&quot;这个属性是只读属性，不能设置数据&quot;</span>)</span><br><span class="line">       <span class="comment">#2.如果不是只读属性，就给他添加到实例里面去</span></span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">          <span class="comment">#self.key = value  #这样会陷入死循环</span></span><br><span class="line">          self.__dict__[key] = value</span><br><span class="line"></span><br></pre></td></tr></table></figure> ###P55、常用内置属性</li></ul><ol type="1"><li>类属性：<ul><li><strong>dict</strong>:类属性</li><li><strong>bases</strong>:类的所有父类构成元组</li><li>__doc__类的文档字符</li><li>__name__类名</li><li>__module__类定义所在模块</li></ul></li><li>实例属性</li></ol><ul><li><strong>dict</strong>:类的实例</li><li><strong>class</strong>:实例对应的类</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h3 id="内置方法">内置方法</h3><p>内置方法的作用；完成一些特定的功能 ### P57、信息格式化操作-* __ str__ * <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n,a</span>):</span><br><span class="line">        self.age = a</span><br><span class="line">        self.name = n</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;name is %s , age is %s . &quot;</span>%(self.name,self.age)</span><br><span class="line"></span><br><span class="line">p=Person(Ray,<span class="number">18</span>)</span><br><span class="line"><span class="built_in">print</span>(p)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>name <span class="keyword">is</span> Ray, age <span class="keyword">is</span> <span class="number">18.</span>    </span><br></pre></td></tr></table></figure></p><h3 id="p58信息格式化操作--__-repr-__">P58、信息格式化操作-* __ repr __*</h3><p>主要面向开发者 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span><span class="string">&quot;repr&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>如果没有定义__str__,那么str也返回的是__repr__的内容。触发__str__的方法： - 直接打印：print(p1) - str方法：s=str(p1) print(s)触发__repr<strong>的方法： - s=repr(p1) print(s) -在交互模式里面将对象名称写出，敲回车 ### P60、* </strong> call __ *__call__的作用：使得对象具有当作函数来调用的能力(将对象变为可调用对象)。当你把对象写出调用函数的形式，就会自动去找call<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;xxx&quot;</span>)</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">p = Person()</span><br><span class="line">p()            <span class="comment">#调用__call__函数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure> ### P61、call的使用例子 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PenFactory</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, p_type</span>):</span><br><span class="line">        self.p_type = p_type       <span class="comment">#这个类只有一个属性</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, p_color</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;创建了一个%s类型的画笔，他是%s颜色的&quot;</span>%(self.p_type, p_color))</span><br><span class="line">gangbiF = penFactory(<span class="string">&quot;钢笔&quot;</span>)       <span class="comment">#创建一个对象</span></span><br><span class="line">gangbiF(<span class="string">&#x27;红色&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure> ### P62、索引操作需要一个字典属性，才可以对对象进行索引操作 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.cache = &#123;&#125;              <span class="comment">#定义cache属性，为一个字典</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setitem__</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        self.cache[key] = value</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">return</span> self.cache[key]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__delitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">del</span> self.cache[key]</span><br><span class="line">p = Person()</span><br><span class="line">p[<span class="string">&#x27;name&#x27;</span>] = <span class="string">&#x27;sz&#x27;</span>  <span class="comment">#执行这行代码的时候，会调用第一个方法</span></span><br><span class="line"><span class="built_in">print</span>(p[<span class="string">&#x27;name&#x27;</span>])  <span class="comment">#调用第二个方法</span></span><br></pre></td></tr></table></figure> ###P63、切片操作 没听懂orz <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.items = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]  <span class="comment">#定义了一个items属性</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setitem__</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(key,silce):</span><br><span class="line">        self.items[key] = value           <span class="comment">#注意切片操作只能修改，不能新增</span></span><br><span class="line">        <span class="comment">#self.items.[key.start: key.stop: key.step] = value  #这样赋值也可以</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">return</span>(key.items[key])            <span class="comment">#这里可能有错</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__delitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">del</span> self[key]</span><br><span class="line">p = Person()</span><br><span class="line">p[<span class="number">0</span>: <span class="number">4</span>: <span class="number">2</span>] = [<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(p.items[<span class="number">0</span>: <span class="number">4</span>: <span class="number">2</span>])</span><br></pre></td></tr></table></figure> ### P64、比较操作 映射的内置方法<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, age, height</span>):</span><br><span class="line">        self.age = age</span><br><span class="line">        self.height = height</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__eq__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> self.age == other.age   <span class="comment">#指定相等的比较通过哪个属性比较，</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__ne__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> self.age != other.age   <span class="comment">#指定相等的比较通过哪个属性比较，</span></span><br><span class="line">p1 = Person(<span class="number">18</span>, <span class="number">180</span>)</span><br><span class="line">p2 = Person(<span class="number">19</span>, <span class="number">183</span>)</span><br><span class="line"><span class="built_in">print</span>(p1 == p2)</span><br><span class="line"><span class="comment">#类似的还有：</span></span><br><span class="line"><span class="comment">#gt &gt;</span></span><br><span class="line"><span class="comment">#ge &gt;=</span></span><br><span class="line"><span class="comment">#lt &lt;</span></span><br><span class="line"><span class="comment">#le &lt;=  </span></span><br><span class="line"><span class="comment">#可以通过调换参数的方式定义比较方法，进而简化代码</span></span><br></pre></td></tr></table></figure> ### P65、比较操作 注意到p1 &lt; p2，等价于p2 &gt; p1。如果对于反向操作的比较符，只定义了其中一个方法，但使用的是另外一种比较运算，那么，解释器会采用调换参数的方式进行调用该方法。### P66、比较操作-方案2（通过装饰器自动补全）解决小于等于，大于等于的反向操作。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="meta">@functools.total_ordering      </span><span class="comment">#此装饰器会自动补全所需要的方法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__lt__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__eq__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure> ### P67、上下文布尔值此方法使对象可以被作为一个布尔值使用。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__bool__</span>(<span class="params">self</span>):    <span class="comment">#通过bool值判定实例是True或False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span>       <span class="comment">#这里也可以是一个返回布尔值的语句</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">p = Person()</span><br><span class="line"><span class="keyword">if</span> p:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;xx&quot;</span>)</span><br><span class="line">&gt;&gt;&gt;不打印</span><br></pre></td></tr></table></figure> 结合比较操作<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.age=<span class="number">20</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__bool__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.age &gt;= <span class="number">18</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">p = Person()</span><br><span class="line"><span class="keyword">if</span> p:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;已成年&quot;</span>)</span><br></pre></td></tr></table></figure> ### P68、遍历操作-<strong>getitem</strong> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.result = <span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        self.result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.result &gt;=<span class="number">6</span>:   <span class="comment">#不满足时，跳出循环</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration(<span class="string">&quot;停止遍历&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> relf.result</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">p = person()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p:    <span class="comment">#当执行for循环时，自动进入__getitem__方法，使用这个方法的返回值作为数据</span></span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"></span><br></pre></td></tr></table></figure>### P69、遍历操作-<strong>iter</strong> iter优先级高于getitem<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.result = <span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        self.result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.result &gt;=<span class="number">6</span>:   <span class="comment">#不满足时，跳出循环</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration(<span class="string">&quot;停止遍历&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> relf.result</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;hfkjasdf&quot;</span>)</span><br><span class="line">p = person()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p:    <span class="comment">#当执行for循环时，自动进入__geritem__方法，使用这个方法的返回值作为数据</span></span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>首先调用<strong>iter</strong>,返回一个迭代器，然后调用__next__方法；<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.result = <span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        self.result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.result &gt;=<span class="number">6</span>:   <span class="comment">#不满足时，跳出循环</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration(<span class="string">&quot;停止遍历&quot;</span>)</span><br><span class="line">        <span class="comment">#return iter([1,2,3,4])    如果返回是迭代器，则自动进入迭代器的__next__方法   </span></span><br><span class="line">        <span class="keyword">return</span> relf.result</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        self.result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.result &gt;=<span class="number">6</span>:   <span class="comment">#不满足时，跳出循环</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration(<span class="string">&quot;停止遍历&quot;</span>)    </span><br><span class="line">        <span class="keyword">return</span> relf.result</span><br><span class="line">p = person()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p:    </span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>总之就是，遍历对象时，先去找有没有iter，如果有的话，再去找next看他的输出，如果可以输出则迭代，如果输出停止不能输出了就停止迭代。### P70、便利操作-直接next遍历 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.result = <span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        self.result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.result &gt;=<span class="number">6</span>:   <span class="comment">#不满足时，跳出循环</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration(<span class="string">&quot;停止遍历&quot;</span>)</span><br><span class="line">        <span class="comment">#return iter([1,2,3,4])    如果返回是迭代器，则自动进入迭代器的__next__方法   </span></span><br><span class="line">        <span class="keyword">return</span> relf.result</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        self.result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.result &gt;=<span class="number">6</span>:   <span class="comment">#不满足时，跳出循环</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration(<span class="string">&quot;停止遍历&quot;</span>)    </span><br><span class="line">        <span class="keyword">return</span> relf.result</span><br><span class="line">p = person()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(p))   <span class="comment">#直接进入__next__方法</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(p))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(p))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(p))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(p))   <span class="comment">#抛出异常，停止遍历</span></span><br><span class="line"></span><br></pre></td></tr></table></figure> ###P71、便利操作-迭代器的复用 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.age = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        self.age = <span class="number">1</span>   <span class="comment"># 如果没有这行命令，那么迭代器只能使用一次</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        self.age += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.age &gt;=<span class="number">6</span>:   <span class="comment">#不满足时，跳出循环</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration(<span class="string">&quot;停止遍历&quot;</span>)    </span><br><span class="line">        <span class="keyword">return</span> relf.age</span><br><span class="line">    </span><br><span class="line">p = person()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"><span class="keyword">import</span> collection</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">isinstance</span>(p, collection.Iterator))  </span><br><span class="line"><span class="comment">#返回值为True，表明确实是一个迭代器，需要同时有两个方法__iter__、__next__</span></span><br><span class="line"><span class="built_in">next</span>(p)  <span class="comment">#只要有一个方法__next__就可以访问</span></span><br></pre></td></tr></table></figure>通过item里面的age归位，调为初始值。否则第一次迭代后age就变为终止值了，不满足迭代的条件。### P72、遍历操作-迭代器-可迭代的判定依据 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collection</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">isinstance</span>(p, collection.Iterable))<span class="comment">#判定是否为可迭代对象，只要一个方法__iter__就可以 </span></span><br><span class="line"></span><br></pre></td></tr></table></figure>一个可迭代对象一定可以通过for in访问，可以通过forin访问的不一定是可迭代对象。 ### P73、遍历操作-iter()的使用我超这一点都不便利www ### P74、描述器概念和作用：描述器是一个对象，可以描述一个属性的操作；其作用是对属性的操作做验证和过滤，如对一个人的年龄赋值时，不能赋值为负数，这是需要验证和过滤，但由于属性数量多，不能在赋值前进行验证，所以用到描述器，每次验证时就会进入描述器中进行相关操作### P75、描述器-定义方式1-property <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.__age = <span class="number">10</span></span><br><span class="line">        </span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__age</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @age.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self, value</span>):</span><br><span class="line">        <span class="keyword">if</span> value &lt; <span class="number">0</span>:</span><br><span class="line">            value = <span class="number">0</span></span><br><span class="line">        self.__age = value</span><br><span class="line">        </span><br><span class="line"><span class="meta">    @age.deleter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">del</span> self.__age</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">p = Person()</span><br><span class="line">p.age             <span class="comment">#注意：这里的age是方法里面的age，不是属性的age</span></span><br><span class="line"><span class="keyword">del</span> p.age</span><br><span class="line"></span><br></pre></td></tr></table></figure> ###P76、描述器-定义方式2-封装 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Age</span>:        <span class="comment">#描述器类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self, instance, owner</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;get&quot;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set__</span>(<span class="params">self, instance, value</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;set&quot;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__delete__</span>(<span class="params">self, instance</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;delete&quot;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:     <span class="comment">#主类</span></span><br><span class="line">    age = Age()   </span><br><span class="line">    </span><br><span class="line">p = Person()</span><br><span class="line">p.age = <span class="number">10</span></span><br><span class="line"></span><br></pre></td></tr></table></figure> ### P77-P79、调节细节 ###P80、调节优先级 - 资料描述器 get set - 非资料描述器 仅仅实现了get -资料&gt;实例&gt;非资料 ### P81、数据存储问题弹幕：这么理解吧，age=Age(),本身这个就是在建立相同的对象，就是self打印的地址一样，instance就是self下的小单元，操作这个每个对象才有不同值<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Age</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self, instance, owner</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;get&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> self.v</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set__</span>(<span class="params">self, instance, value</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;set&quot;</span>)</span><br><span class="line">        self.v = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__delete__</span>(<span class="params">self, instance</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;delete&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    age = Age()</span><br><span class="line"></span><br><span class="line">p = Person()</span><br><span class="line">p.age = <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(p.age)</span><br><span class="line">&gt;&gt;&gt;<span class="built_in">set</span></span><br><span class="line">get</span><br><span class="line"><span class="number">10</span></span><br><span class="line">--------------------------------------------------</span><br><span class="line">p2 = Person()</span><br><span class="line">p2.age = <span class="number">11</span></span><br><span class="line"><span class="built_in">print</span>(p2.age)</span><br><span class="line">&gt;&gt;&gt;<span class="number">11</span></span><br><span class="line">这时候如果再打印p的话</span><br><span class="line">&gt;&gt;&gt;<span class="number">11</span></span><br><span class="line">因为都是储存在age里，也就是Age只有一个对象self，即age</span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">如果绑定在instance上的话：</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Age</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__get__</span>(<span class="params">self, instance, owner</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;get&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> instance.v</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__set__</span>(<span class="params">self, instance, value</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;set&quot;</span>)</span><br><span class="line">        instance.v = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__delete__</span>(<span class="params">self, instance</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;delete&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    age = Age()</span><br><span class="line"></span><br><span class="line">就可以分别打印，分别存储</span><br></pre></td></tr></table></figure> ### P82、装饰器-类函数引入：在不改变某个def函数本身的情况下，增加这个函数的功能，如何？</p><p>注意层级，deffashuoshuo()是函数并不是方法,fashuoshuo接收了check，所他自己就是check实例了<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">check</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;登录成功&quot;</span>)</span><br><span class="line">        func()</span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@check</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fashuoshuo</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;发说说&quot;</span>)</span><br><span class="line"></span><br><span class="line">fashuoshuo()</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="string">&quot;登录成功&quot;</span></span><br><span class="line"><span class="string">&quot;发说说&quot;</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> PythonのEtude </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《论文复现:SenseXAMP》</title>
      <link href="/2024/07/01/SenseXAMP/xxx/"/>
      <url>/2024/07/01/SenseXAMP/xxx/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h1 id="fuse-feeds-as-one-cross-modal-framework-for-general-identification-of-amps">Fusefeeds as one: cross-modal framework for general identification ofAMPs</h1><p><a href="https://doi.org/10.1093/bib/bbad336">SOTA</a> <a href="https://github.com/William-Zhanng/SenseXAMP/blob/main/README.md">README</a># 论文阅读</p><h2 id="摘要">摘要</h2><p>在这项研究中，我们提出了SenseXAMP，一个跨模态框架，通过利用输入<strong>序列的语义嵌入</strong>和<strong>蛋白质描述符</strong>（PDs）来提高AMPs识别性能。SenseXAMP包含一个多输入对齐模块和跨表示融合模块，以探索两种输入特征之间的隐藏信息，更好地利用融合特征。</p><p>为更好地解决AMPs识别任务，我们累积了最新的标注AMPs数据，形成了更大规模的基准数据集。此外，我们通过增加AMPs回归任务来扩展现有的AMPs识别任务设置，以满足抗菌活性预测等更具体的需求。实验结果表明，SenseXAMP在包括常用AMPs分类数据集和我们提出的基准数据集在内的多个AMPs相关数据集上，均优于现有的最先进模型。此外，我们进行了系列实验，证明传统PDs和蛋白质预训练模型在AMPs任务中的互补性。我们的实验结果显示，SenseXAMP可以有效结合PDs的优势，提高蛋白质预训练模型在AMPs任务中的性能。</p><h2 id="介绍与前人工作概述">介绍与前人工作概述</h2><h3 id="传统机器学习方法">传统机器学习方法</h3><ul><li><strong>机器学习方法的应用</strong>：近年来，基于机器学习的方法已成为计算识别抗菌肽（AMPs）的主流。这些方法通常依赖于蛋白质描述符（PDs）作为输入，这些描述符通过计算工具捕获蛋白质序列的物理、化学和组成特性。</li><li><strong>常用的分类器</strong>：传统的机器学习方法中，常用的分类器包括支持向量机（SVM）、随机森林（RF）、极端梯度提升（Xgboost）和模糊K近邻（fuzzyKNN）。</li><li><strong>已开发的流行方法</strong>：一些基于机器学习的流行方法包括AntiBP、AntiBP2、CAMP、IAMPE和ClassAMP。这些方法利用一种或多种传统机器学习算法，建立了AMPs识别模型。</li></ul><h3 id="深度学习方法">深度学习方法</h3><ul><li><strong>特征工程简化</strong>：深度学习方法简化了特征工程过程，近年来深度神经网络（DNN）模型已成为AMPs识别任务的主导方法。</li><li><strong>基于卷积神经网络（CNN）的方法</strong>：例如，APIN、DeepAmPEP30和GRAMPA利用CNN作为识别AMPs的骨干网络。</li><li><strong>基于双向长短期记忆（Bi-LSTM）的方法</strong>：如AMPScanner和Deep-ABPpred，使用Bi-LSTM构建序列模型。</li><li><strong>基于BERT微调的方法</strong>：如AMP-BERT，随着自然语言处理研究的进展，基于大规模序列数据库预训练的蛋白质语言模型在多种生物信息学任务中显示出了巨大潜力，包括蛋白质结构预测和功能注释。最新的模型之一是ESM-1b（EvolutionaryScale Modeling），基于Transformer架构并在Uniref50上训练。</li></ul><h3 id="传统pds的潜力">传统PDs的潜力</h3><ul><li><strong>对传统PDs的再评估</strong>：尽管深度学习模型在AMPs任务中显示出色，但传统PDs在AMPs识别任务中的巨大潜力仍然值得探索。García-Jacas等人进行了一项综合评估，比较了仅使用传统特征描述符训练的浅层模型和DNN模型在AMPs预测任务中的表现。实验结果表明，浅层模型在某些情况下具有优势，至少与深度学习模型相当，这与之前基于小规模数据集得出的结论相反。</li><li><strong>传统PDs的应用实例</strong>：例如，SMEP使用传统PDs进行大规模AMP筛选的湿实验结果进一步展示了传统特征描述符在AMP预测任务中的巨大潜力。</li></ul><h3 id="数据集的规模和平衡问题">数据集的规模和平衡问题</h3><ul><li><strong>小规模和平衡数据集的局限性</strong>：大多数AMPs识别研究通常使用相对较小且平衡的数据集，单一目标为AMPs分类。然而，在实际场景中，大多数来自自然来源的候选序列不是功能性AMPs。在这种情况下，训练在平衡数据集上的模型可能在实际应用中会出现过拟合问题。</li><li><strong>增加回归任务的必要性</strong>：在候选库较大且用户对肽的抗菌活性有具体要求的情况下，仅进行分类任务可能不足。因此，研究如何从大规模、不平衡的候选库中识别潜在的AMPs，并考虑抗菌活性的具体要求，是必要的。</li></ul><h3 id="综合任务和模型融合">综合任务和模型融合</h3><ul><li><strong>综合AMPs筛选任务</strong>：本研究提出了一种更具代表性的AMPs筛选任务组合，结合传统的AMPs分类任务和AMPs回归任务。相关研究表明，回归任务可以通过预测MIC值来辅助AMPs的细粒度筛选。</li><li><strong>模型融合的局限性和创新</strong>：在对基于传统PDs的模型和预训练模型的错误样本分析中，发现两者的错误样本有很大比例不重叠，难以通过简单的模型融合技术（如堆叠法）纠正所有错误样本。因此，作者提出SenseXAMP模型，通过在特征级别上融合蛋白质预训练模型和传统PDs，显著提高了AMPs任务的性能。</li></ul><h3 id="总结">总结</h3><p>前人的工作展示了基于传统机器学习和深度学习方法在AMPs识别任务中的成功应用，尤其是在特征提取和模型构建方面。然而，这些方法在处理大规模、不平衡数据集和复杂任务组合方面仍存在局限性。SenseXAMP通过在特征级别融合传统PDs和预训练模型的信息，克服了这些局限性，并在多个AMPs相关数据集上展示了卓越的性能。</p><h2 id="数据集">数据集</h2><p>论文的“数据集”部分详细介绍了用于AMPs筛选任务的数据集构建过程以及这些数据集的组成部分。以下是该部分的详细描述：</p><h3 id="数据集构建背景">数据集构建背景</h3><p>AMPs筛选的实际场景中存在样本不平衡的情况，其中在大量候选肽中只有少量具有抗菌活性。为了构建数据分布更接近实际AMPs筛选场景的数据集，作者整合并清理了现有的AMPs识别相关数据集，形成了多个更大、更综合的AMP数据集。此外，考虑到更精确预测AMPs抗菌活性的重要性，作者还包括了AMPs回归数据集。</p><h3 id="数据集组成">数据集组成</h3><p>数据集主要由以下几部分组成：</p><ol type="1"><li><strong>AMPs分类数据集</strong>：<ul><li><strong>平衡数据集</strong>：用于AMPs二分类任务。正负样本的长度和数量一致。</li><li><strong>不平衡数据集</strong>：更接近现实情况，正负样本之间存在不平衡，挑战更大。</li></ul></li><li><strong>AMPs回归数据集</strong>：主要用于预测AMPs的抗菌活性，以最低抑菌浓度（MIC）表示。选择了常用的两种细菌菌株作为目标菌株：<ul><li><strong>大肠杆菌（E.coli）数据集</strong>：主要由对大肠杆菌具有抗菌活性的AMPs和一批非AMPs组成。</li><li><strong>金黄色葡萄球菌（S.aureus）数据集</strong>：主要由对金黄色葡萄球菌具有抗菌活性的AMPs和一批非AMPs组成。</li></ul></li></ol><h3 id="数据集构建过程">数据集构建过程</h3><ol type="1"><li><strong>数据收集和清理</strong>：<ul><li>收集了11个前人工作的AMP相关数据集。这些序列来自多个知名的公开数据库，如抗菌肽数据库（APD）、抗菌肽数据存储库（DRAMP）、YADAMP（YetAnother Database of AMPs）、CAMP（Collection of AMPs）和DBAASP（Databaseof AMPs with Mainly SyntheticPeptides）。GRAMPA数据集提供了AMPs回归数据集的重要信息。</li><li>删除重复序列后，获得总计35,016个AMPs和175,341个非AMPs。</li></ul></li><li><strong>数据清洗</strong>：<ul><li>删除包含特殊氨基酸（B、J、O、U、X和Z）的序列，仅保留长度在6到50之间的序列，因为较长的肽可能不稳定且有毒，而较短的肽不太可能具有抗菌活性。</li><li>对于不同数据集中标签不一致的序列，视为数据噪声并删除。</li></ul></li><li><strong>相似序列去重</strong>：<ul><li>使用CD-HIT程序对正样本和负样本分别进行处理，去除高度相似的序列（相似度阈值为0.7）。处理后，正样本和负样本中不再存在超过70%相似度的序列。最终得到7,941个AMPs和28,021个非AMPs，用于创建不平衡分类数据集。</li><li>随机从28,021个非AMPs中选择7,941个，与AMPs的长度分布一致，创建正负比为1:1的平衡分类数据集。</li></ul></li><li><strong>回归数据集构建</strong>：<ul><li>从GRAMPA数据集中选择目标菌株为大肠杆菌和金黄色葡萄球菌的数据，保留仅包含“C-末端：AMD”注释且序列长度大于5的序列。</li><li>对于同一肽的多个实验条件下的MIC值，取平均值作为最终标签。</li><li>大肠杆菌回归数据集中包含1,724个正样本和8,620个负样本，负样本从经CD-HIT过滤的非AMPs数据集中随机采样，正负比为1:5，以模拟实际场景。</li><li>金黄色葡萄球菌回归数据集类似地包含1,678个正样本和8,390个负样本。</li><li>标签设置与GRAMPA和SMEP数据集一致，所有非AMPs的MIC值设为log10(8196) ≈3.91，因此所有AMPs的标签小于此值。</li></ul></li></ol><h3 id="数据集概览图">数据集概览图</h3><p>论文中的图1展示了数据集形成的流程，详细描述了数据收集、清洗、去重和构建分类及回归数据集的步骤。<img src="/2024/07/01/SenseXAMP/xxx/!%5Balt%20text%5D(image-1.png)" alt="figure 1">通过上述数据集构建过程，论文形成了更加综合和具有代表性的AMPs分类和回归数据集，为后续的模型训练和评估提供了坚实基础。这些数据集的构建考虑了实际应用中的样本不平衡和抗菌活性预测需求，使得模型的评估更加接近实际使用场景。## 提出的方法</p><p>在本研究中，我们提出了一种用于AMPs识别任务的全新端到端方法，名为SenseXAMP。该方法包含三个主要组件：</p><h3 id="方法概述">方法概述</h3><p>SenseXAMP由以下三个主要模块组成： 1.<strong>特征提取模块</strong>：将序列输入提取为两种模态的特征，包括蛋白质预训练模型和传统PDs计算工具。2.<strong>多输入对齐模块</strong>：提取并压缩两种模态特征的维度，以便进行有效融合。3.<strong>跨表示融合模块</strong>：结合两种模态的隐藏信息，以获得更全面的输入序列表示。</p><h3 id="特征提取模块">特征提取模块</h3><p>在特征提取模块中，使用自监督蛋白质预训练模型和传统的PDs计算工具提取两种模态的特征，如图2a所示。自监督蛋白质预训练模型使用ESM-1bTransformer将序列输入转换为氨基酸残基级别的嵌入。每个序列的嵌入维度为 ([, ])，其中 () 是序列的长度，()对于ESM-1b是1280。我们还使用计算工具计算输入序列的伪氨基酸组成（PseAAC）、组成/转移/分布（CTD）等物理化学特征。该工具能够为给定输入序列生成676个物理化学特征。这些特征作为氨基酸残基级别嵌入的补充信息。</p><h3 id="多输入对齐模块">多输入对齐模块</h3><p>在获得序列的两种模态特征后，SenseXAMP的多输入对齐模块进一步提取并对齐两种模态特征的维度，以进行后续的融合过程。如图2b所示，我们使用自注意力块从ESM-1b获得的嵌入中提取特征。该模块类似于Transformer编码器，由N个相同的层堆叠而成。每个层由多头自注意力和前馈神经网络（FFN）组成，每个子层都有残差连接。形式上，我们将输入序列嵌入表示为(E(x) ^{ND})，其中N是序列中的标记数，每个标记的嵌入维度为D（这里为1280）。</p><p>多头自注意力是该模块的核心，它是缩放点积注意力的改进版。具体来说，输入序列嵌入的表示为(E(x))，其计算公式如下：</p><p>[ Q = E(x)W_q, K = E(x)W_k, V = E(x)W_v ] [ (Q, K, V) = ()V ] [ (Q,K, V) = (_1, , _h)W_O ]</p><p>自注意力块的输出表示为 (F_{})，与输入序列嵌入的维度相同。</p><p>对于通过PDs计算工具计算的PDs特征，特征提取器由若干层全连接网络（FCN）组成，用于将其维度映射到与嵌入相同的维度D。形式上，我们将映射后的PDs特征表示为(F_{} ^D)。</p><h3 id="跨表示融合模块">跨表示融合模块</h3><p>SenseXAMP的跨表示融合模块起到了关键作用。多输入对齐模块进一步提取特征后，特征的维度已经对齐，可以进行特征级别的融合。如图2c所示，跨表示融合模块的核心类似于自注意力块，由多头注意力和FFN组成。需要注意的是，Q是从(F_{}) 计算的，而K和V是从 (F_{})计算的。在此过程中，融合特征不断更新，而PDs特征保持不变。通过有效地整合和融合多种模态的信息，该模块可以提高分类和回归模型的准确性和鲁棒性。</p><h3 id="损失函数">损失函数</h3><p>跨表示融合模块获得的最终融合特征具有强大的表示能力，通过输入到最终任务特定的头部（如回归、分类等）进行输出预测。在模型训练过程中，从多输入对齐模块获得的(F_{}) 和 (F_{})特征，以及最终融合特征，分别输入到预测头部以获得相应的预测结果，然后用于计算损失函数。为了提高特征对齐过程中嵌入特征和PDs特征的提取性能，我们认为有必要监督每个模态特征的预测结果。通过简单地修改模型末端使用的预测头部，SenseXAMP可以方便地适应多种任务，如分类、回归等。在本研究中，我们使用二元交叉熵（BCE）作为AMPs分类任务的损失函数，对于AMPs回归任务，我们使用均方误差（MSE）作为损失函数：</p><p>[ (y, ) = - <em>{i=1}^{n} ] [ (y, ) = </em>{i=1}^{n} (y_i - _i)^2]</p><p>最终损失是所有头部预测损失的组合：</p><p>[ L = r_1 L_1 + r_2 L_2 + r_3 L_3 ]</p><p>其中 (r_1, r_2) 和 (r_3)是权衡各损失项对整体损失贡献的可调超参数。</p><h3 id="模型性能评估指标">模型性能评估指标</h3><p>对于AMPs分类任务，我们使用五个量化指标评估模型性能：准确率（ACC）、特异性（Sp）、敏感性（Sn）、马修斯相关系数（MCC）和F1分数。在实际场景中，非AMPs数量远多于AMPs，研究人员通常希望尽可能筛选出所有潜在的AMPs。因此，在这些评价指标中，综合评价指标如F1分数、MCC和反映正样本识别准确性的指标如Sn更为重要。</p><p>[ = ] [ = ] [ = ] [ = ] [ = ]</p><p>对于AMPs回归任务，我们主要使用topK-mse评估模型性能。序列的MIC值越小，抗菌性能越好。我们选择多个尺度的MSE全面评估模型性能，包括top10-mse、top30-mse、top100-mse、pos-mse和mse。topK-mse评估模型对具有最佳抗菌性能的前K个序列的MIC预测误差，pos-mse评估所有AMPs的MIC预测误差：</p><p>[ = _{i=1}^{K} ( <em>i - y_i )^2 ] [ = </em>{i=1}^{N} ( _i - y_i )^2]</p><p>其中K是选择评估性能的最佳抗菌性能序列数，N代表数据集的总AMPs数。</p><p>在AMPs筛选的背景下，非AMPs数量远多于AMPs，AMPs回归数据集模拟了这种不平衡的样本场景，这意味着如果模型预测所有序列的MIC为(_{})，则可以获得足够低的MSE。然而，我们的最终目标是识别具有良好抗菌活性的AMPs，因此高性能模型不仅应关注MSE，还应关注反映AMPs（正样本）抗菌活性预测质量的指标，如pos-mse和topK-mse。这并不意味着模型仅优化与正样本相关的MSE而忽视整体MSE的增加，因为回归模型仍需保留区分非AMPs的能力。在这种任务设置中，我们认为一个好的回归模型应在不显著牺牲整体MSE的情况下，拥有较低的正样本相关指标值，如topK-MSE和pos-MSE。<img src="/2024/07/01/SenseXAMP/xxx/image-2.png" alt="alt text"> ## 实验与结果</p><p>在这一部分，作者通过一系列实验评估了SenseXAMP模型在AMPs分类和回归任务中的性能。以下是这一部分的简要描述：</p><h3 id="预训练模型与传统pds模型的互补性分析">预训练模型与传统PDs模型的互补性分析</h3><p>为评估预训练模型（MPTM）和传统PDs模型（MPD）的互补性，作者在收集的不平衡分类数据集（包含7941个AMPs和28021个非AMPs）上进行了实验。结果表明，两种模型在错误样本上的重叠较少，表明它们在预测不同样本方面各有优势。因此，作者提出了融合预训练模型嵌入和PDs的合理方法，以解决单一输入模型无法解决的错误样本。</p><h3 id="模型级集成分析">模型级集成分析</h3><p>作者训练了一个XGBoost分类器，使用PDs作为输入，判断给定序列由哪种模型（MPTM或MPD）预测更准确。然而，XGBoost分类器的最终性能不理想，表明简单的模型级集成不足以显著提高整体预测性能。</p><h3 id="与堆叠方法的比较">与堆叠方法的比较</h3><p>作者还进行了额外实验，通过堆叠方法集成两种不同模态的模型。结果表明，堆叠方法在提高灵敏度（Sn）方面有所帮助，但在其他指标上不如SenseXAMP。</p><h3 id="与其他方法的比较">与其他方法的比较</h3><p>作者在多个数据集上比较了SenseXAMP与其他最新的AMP分类模型和回归模型。结果显示，SenseXAMP在综合指标（如准确率、MCC和F1分数）上显著优于其他模型，特别是在处理大规模和不平衡数据集时表现尤为突出。</p><h3 id="特征级融合效果验证">特征级融合效果验证</h3><p>通过对错误样本的详细分析，作者发现SenseXAMP能够准确分类单独使用预训练模型或PDs模型无法正确分类的样本。这表明，SenseXAMP有效地结合了多种模态的信息，显著提高了预测性能。</p><h3 id="总结-1">总结</h3><p>实验结果表明，SenseXAMP在AMPs分类和回归任务中的性能优于现有的最先进模型，特别是在处理大规模和复杂数据集时。特征级融合方法展示了广泛的适用性，并避免了灾难性遗忘。</p><p>通过这些实验和结果，作者证明了SenseXAMP在AMPs任务中的有效性和优势，展示了其在实际应用中的巨大潜力。</p><h1 id="论文复现">论文复现</h1><h2 id="配置环境">配置环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># clone project</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/William-Zhanng/SenseXAMP.git</span><br><span class="line"><span class="built_in">cd</span> SenseXAMP</span><br><span class="line"></span><br><span class="line"><span class="comment"># create conda virtual environment</span></span><br><span class="line">conda create -n torch1.7 python=3.8 </span><br><span class="line">conda activate torch1.7</span><br><span class="line"></span><br><span class="line"><span class="comment"># install all requirements</span></span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="准备数据集">准备数据集</h2><ul><li>ori_datasets</li><li>esm_embeddings</li><li>stc_info</li><li>stc_datasets <em>注意：“stc_csv”数据集版本主要用于 SMEP等比较方法，对于使用 SenseXAMP 不是必需的。</em> ## 下载modelcheckpoints 按照README的步骤与给的脚本 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> structure_data_generate.cal_pep_des <span class="keyword">import</span> cal_pep_fromlist</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># generate structured data</span></span><br><span class="line">    data_dir = <span class="string">&#x27;./datasets/ori_datasets/AMPlify&#x27;</span></span><br><span class="line">    files = os.listdir(data_dir)</span><br><span class="line">    out_dir = <span class="string">&#x27;./datasets/stc_datasets/AMPlify&#x27;</span></span><br><span class="line">    os.makedirs(out_dir,exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        data_file = os.path.join(data_dir,file)</span><br><span class="line">        data = pd.read_csv(data_file, encoding=<span class="string">&quot;utf-8&quot;</span>)  </span><br><span class="line">        sequence = data[<span class="string">&#x27;Sequence&#x27;</span>]</span><br><span class="line">        labels = data[<span class="string">&#x27;Labels&#x27;</span>]</span><br><span class="line">        <span class="comment"># labels = data[&#x27;MIC&#x27;]</span></span><br><span class="line">        peptides_list = sequence.values.copy().tolist()</span><br><span class="line">        out_path = os.path.join(out_dir,file)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;output path: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(out_path))</span><br><span class="line">        cal_pep_fromlist(peptides_list,output_path = out_path, labels=labels)</span><br></pre></td></tr></table></figure>结果报错，说找不到'./datasets/ori_datasets/AMPlify'，我检查了我的目录结构，确实是和他给的一样的。反思认为是./只能访问当前目录，返回上级目录应该是../，故修改，得之。 ##Generate esm-1b embeddings using our scripts这一步的脚本根本就没写全，而且生成的AMPlifydataset有sequence缺失，所以我将ori_datasets的目标数据先写入一个txt文件，然后脚本读取这个文件，修改esm_emb_gen.py脚本如下<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> esm_project <span class="keyword">as</span> esm</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EmbeddingProcessor</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate esm embeddings for all proteins.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.pretrain_model, _ = esm.pretrained.esm1b_t33_650M_UR50S()</span><br><span class="line">        alphabet = esm.Alphabet.from_architecture(<span class="string">&quot;roberta_large&quot;</span>)</span><br><span class="line">        self.batch_converter = alphabet.get_batch_converter()</span><br><span class="line">        self.pretrain_model = self.pretrain_model.to(device)</span><br><span class="line">        self.all_seqs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_seqs_from_list_file</span>(<span class="params">self, seq_file: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Get all sequences from a file</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            seq_file: path to file containing sequences</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(seq_file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.all_seqs = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines()]</span><br><span class="line">        self.all_seqs = <span class="built_in">set</span>(self.all_seqs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate_embeddings</span>(<span class="params">self, outdir, mode=<span class="string">&#x27;all&#x27;</span>, fname=<span class="string">&#x27;esm_embeddings.h5&#x27;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Generate embeddings for all sequence.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            outdir: path to embedding file save</span></span><br><span class="line"><span class="string">            mode:</span></span><br><span class="line"><span class="string">                all or pooling.</span></span><br><span class="line"><span class="string">            fname: name of embedding file</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> (mode == <span class="string">&#x27;all&#x27;</span>) <span class="keyword">or</span> (mode == <span class="string">&#x27;pooling&#x27;</span>) <span class="keyword">or</span> (mode == <span class="string">&#x27;cls_token&#x27;</span>)</span><br><span class="line">        os.makedirs(outdir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        self.max_len = <span class="built_in">max</span>(<span class="built_in">len</span>(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> self.all_seqs)</span><br><span class="line">        max_len = <span class="number">64</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;all&#x27;</span>:</span><br><span class="line">            max_len = self.max_len</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Max length: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(self.max_len))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> h5py.File(os.path.join(outdir, fname), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> hf:</span><br><span class="line">            <span class="keyword">for</span> seq <span class="keyword">in</span> tqdm(self.all_seqs):</span><br><span class="line">                data = [(seq, seq)]</span><br><span class="line">                _, _, batch_tokens = self.batch_converter(data, max_length=max_len)</span><br><span class="line">                batch_tokens = batch_tokens.to(device)</span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                    results = self.pretrain_model(batch_tokens, repr_layers=[<span class="number">33</span>], return_contacts=<span class="literal">True</span>)</span><br><span class="line">                token_representations = results[<span class="string">&quot;representations&quot;</span>][<span class="number">33</span>]</span><br><span class="line">                <span class="keyword">if</span> mode == <span class="string">&#x27;pooling&#x27;</span>:</span><br><span class="line">                    embedding = token_representations.mean(<span class="number">1</span>).squeeze(<span class="number">0</span>)  <span class="comment"># [1280]</span></span><br><span class="line">                <span class="keyword">elif</span> mode == <span class="string">&#x27;cls_token&#x27;</span>:</span><br><span class="line">                    embedding = token_representations[:, <span class="number">0</span>, :].squeeze(<span class="number">0</span>)  <span class="comment"># cls token</span></span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># mode = &#x27;all&#x27; (SenseXAMP use this type)</span></span><br><span class="line">                    embedding = token_representations.squeeze(<span class="number">0</span>)  <span class="comment"># [676,1280]</span></span><br><span class="line">                embedding = embedding.cpu().numpy()</span><br><span class="line">                hf.create_dataset(seq, data=embedding)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;A script to calculate esm_embeddings version of datasets&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--seq_file&#x27;</span>, default=<span class="string">&#x27;C:/Users/LENOVO/Desktop/SenseXAMP/all_sequences.txt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;path to file containing all sequences&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--fname&#x27;</span>, default=<span class="string">&#x27;AMPlify.h5&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;name of output file name, name it xxx.h5&#x27;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    processor = EmbeddingProcessor()</span><br><span class="line">    processor.get_seqs_from_list_file(args.seq_file)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Number of sequences to embed: <span class="subst">&#123;<span class="built_in">len</span>(processor.all_seqs)&#125;</span>&quot;</span>)</span><br><span class="line">    processor.generate_embeddings(<span class="string">&#x27;D:/SenseXAMP/datasets/esm_embeddings/all&#x27;</span>, mode=<span class="string">&#x27;all&#x27;</span>, fname=args.fname)</span><br></pre></td></tr></table></figure> ## Run SenseXAMP ### 训练SenseXAMP <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ast <span class="keyword">import</span> arguments</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># For DDP</span></span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> Config,Logger</span><br><span class="line"><span class="keyword">from</span> Ampmm_base.runner <span class="keyword">import</span> Runner</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;Training SenseXAMP benchmark&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--config&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;train config file path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--mode&#x27;</span>, default=<span class="string">&#x27;train&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;train or test&#x27;</span>)</span><br><span class="line">    <span class="comment"># for ddp</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--local_rank&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">42</span>, <span class="built_in">help</span>=<span class="string">&#x27;random seed&#x27;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seed</span>(<span class="params">seed_value=<span class="number">42</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Set seed for reproducibility.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    random.seed(seed_value)</span><br><span class="line">    np.random.seed(seed_value)</span><br><span class="line">    torch.manual_seed(seed_value)</span><br><span class="line">    torch.cuda.manual_seed_all(seed_value)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # for ddp</span></span><br><span class="line"><span class="comment"># parser.add_argument(&quot;--local_rank&quot;, default=-1, type=int)</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    args = parse_args()</span><br><span class="line">    local_rank = args.local_rank</span><br><span class="line">    <span class="comment"># ddp init</span></span><br><span class="line">    torch.cuda.set_device(local_rank)</span><br><span class="line">    dist.init_process_group(backend=<span class="string">&#x27;gloo&#x27;</span>)</span><br><span class="line">    <span class="comment"># set random seed</span></span><br><span class="line">    cfg = Config.fromfile(args.config)</span><br><span class="line">    cfg.local_rank = args.local_rank</span><br><span class="line">    <span class="comment"># create logger and work_dir</span></span><br><span class="line">    <span class="keyword">if</span> dist.get_rank() == <span class="number">0</span>:</span><br><span class="line">        cfg.work_dir = os.path.join(cfg.work_dir,cfg.benchmark_name,cfg.dataset_name,args.mode,</span><br><span class="line">                                    time.strftime(<span class="string">&quot;%Y-%m-%d_%H-%M-%S&quot;</span>, time.localtime()))</span><br><span class="line">        os.makedirs(cfg.work_dir,exist_ok=<span class="literal">True</span>)</span><br><span class="line">    logger = Logger(cfg.work_dir)</span><br><span class="line">    <span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">        logger.info(args)</span><br><span class="line">        logger.info(<span class="string">&quot;Running with config:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(cfg.text))</span><br><span class="line">        <span class="comment"># set random seeds</span></span><br><span class="line">        <span class="keyword">if</span> args.seed <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            logger.info(<span class="string">&#x27;Set random seed to &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.seed))</span><br><span class="line">            set_seed(args.seed)</span><br><span class="line">    runner = Runner(cfg,logger,args.local_rank,args.mode)</span><br><span class="line">    <span class="keyword">if</span> args.mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">        runner.run()</span><br><span class="line">    <span class="keyword">elif</span> args.mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        runner.test()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> args.local_rank == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Please ensure args.mode to be train or test&quot;</span>)</span><br><span class="line">            exit()</span><br></pre></td></tr></table></figure> ####在平衡分类数据集上训练 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node 1 run.py \</span><br><span class="line">--config ./configs/cls_task/benchmark_balanced_SenseXAMP.py --mode train</span><br></pre></td></tr></table></figure> 训练结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ 2024-07-10 11:44:20 ] Current best results:</span><br><span class="line"> &#123;<span class="string">&#x27;TP&#x27;</span>: 0.36375078665827565, <span class="string">&#x27;FP&#x27;</span>: 0.13971050975456262, <span class="string">&#x27;TN&#x27;</span>: 0.36249213341724357, <span class="string">&#x27;FN&#x27;</span>: 0.1340465701699182, <span class="string">&#x27;Acc&#x27;</span>: 0.7262429200755192, <span class="string">&#x27;Precision&#x27;</span>: 0.7225, <span class="string">&#x27;Recall&#x27;</span>: 0.7307206068268015, <span class="string">&#x27;Specificity&#x27;</span>: 0.7218045112781954, <span class="string">&#x27;F1_score&#x27;</span>: 0.7265870521684474, <span class="string">&#x27;MCC&#x27;</span>: 0.45253157041334263&#125;</span><br></pre></td></tr></table></figure> #### 测试<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node 1 run.py \</span><br><span class="line">--config ./configs/cls_task/benchmark_balanced_SenseXAMP.py --mode <span class="built_in">test</span></span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Resume &amp; Checkpoint setting</span></span><br><span class="line">Resume = <span class="literal">None</span> <span class="comment"># Resume from which ckpt to train</span></span><br><span class="line">ckpt_path = <span class="string">&#x27;C:/Users/LENOVO/Desktop/SenseXAMP/checkpoints/SenseXAMP_checkpoints/amp_cls/sensexamp_amplify.ckpt&#x27;</span> <span class="comment"># Checkpoint for test</span></span><br><span class="line"></span><br></pre></td></tr></table></figure> 可视化测试结果 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试结果数据</span></span><br><span class="line">results = &#123;</span><br><span class="line">    <span class="string">&#x27;TP&#x27;</span>: <span class="number">0.3633501259445844</span>, </span><br><span class="line">    <span class="string">&#x27;FP&#x27;</span>: <span class="number">0.18702770780856423</span>, </span><br><span class="line">    <span class="string">&#x27;TN&#x27;</span>: <span class="number">0.3243073047858942</span>, </span><br><span class="line">    <span class="string">&#x27;FN&#x27;</span>: <span class="number">0.1253148614609572</span>, </span><br><span class="line">    <span class="string">&#x27;Acc&#x27;</span>: <span class="number">0.6876574307304786</span>, </span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: <span class="number">0.660183066361556</span>, </span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: <span class="number">0.7435567010309279</span>, </span><br><span class="line">    <span class="string">&#x27;Specificity&#x27;</span>: <span class="number">0.6342364532019704</span>, </span><br><span class="line">    <span class="string">&#x27;F1_score&#x27;</span>: <span class="number">0.6993939393939393</span>, </span><br><span class="line">    <span class="string">&#x27;MCC&#x27;</span>: <span class="number">0.37962791273329644</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line">confusion_matrix = np.array([</span><br><span class="line">    [results[<span class="string">&#x27;TP&#x27;</span>], results[<span class="string">&#x27;FN&#x27;</span>]],</span><br><span class="line">    [results[<span class="string">&#x27;FP&#x27;</span>], results[<span class="string">&#x27;TN&#x27;</span>]]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制混淆矩阵</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">sns.heatmap(confusion_matrix, annot=<span class="literal">True</span>, fmt=<span class="string">&quot;.2f&quot;</span>, cmap=<span class="string">&quot;Blues&quot;</span>, xticklabels=[<span class="string">&#x27;Predicted Positive&#x27;</span>, <span class="string">&#x27;Predicted Negative&#x27;</span>], yticklabels=[<span class="string">&#x27;Actual Positive&#x27;</span>, <span class="string">&#x27;Actual Negative&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Predicted&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Actual&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制性能指标条形图</span></span><br><span class="line">metrics = [<span class="string">&#x27;Accuracy&#x27;</span>, <span class="string">&#x27;Precision&#x27;</span>, <span class="string">&#x27;Recall&#x27;</span>, <span class="string">&#x27;Specificity&#x27;</span>, <span class="string">&#x27;F1_score&#x27;</span>, <span class="string">&#x27;MCC&#x27;</span>]</span><br><span class="line">values = [results[<span class="string">&#x27;Acc&#x27;</span>], results[<span class="string">&#x27;Precision&#x27;</span>], results[<span class="string">&#x27;Recall&#x27;</span>], results[<span class="string">&#x27;Specificity&#x27;</span>], results[<span class="string">&#x27;F1_score&#x27;</span>], results[<span class="string">&#x27;MCC&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.bar(metrics, values, color=[<span class="string">&#x27;skyblue&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;purple&#x27;</span>, <span class="string">&#x27;brown&#x27;</span>])</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Performance Metrics&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Score&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure> <img src="/2024/07/01/SenseXAMP/xxx/Figure_1.png" alt="alt text"> <img src="/2024/07/01/SenseXAMP/xxx/Figure_2.png" alt="alt text"></li></ul>]]></content>
      
      
      <categories>
          
          <category> 論文のConcerto </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>青楼魅影</title>
      <link href="/2024/06/14/hello-world/"/>
      <url>/2024/06/14/hello-world/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\css\APlayer.min.css"><script src="\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\js\Meting.min.js"></script><h2 id="青楼魅影">青楼魅影</h2><p>作者：北冰洋</p><p><em>本文作为我社社刊废稿www</em></p><p>已经是入冬了，一同而来的还有新年。虽然小镇地处南方沿海，但今年的寒潮却凶猛得远超人们的想象。白天，家家户户都坚持着能不外出就不外出的原则，尤其是老人，一身老骨头可挨不了冻。居家休息的人们在屋内也生起了火，石头砌成一个小方格，底部石层留有缝隙通风，火在方格内烧着，当然，也不一定是方格。抵御寒冬，虽说用处不大。恰逢春节，偶尔有亲朋好友上门拜访，人一多，热闹起来，这才不觉得冷。所谓热闹是对抗寒冬的第一方法。</p><p>但小镇的热闹不属于白天，而属于夜晚。</p><p>夜晚，人们都走出家门，来到灯火通明的大街上，仿佛约定好一般。尽管街道并不那么宽广——加上沿街排队的小贩就显得更窄了——可人们似乎很享受这摩肩接踵的氛围。走在石板路上，木质的鞋底与地面发出摩擦与碰撞的声音，但很快淹没在人海中。在街灯红晕的光下，人们的影子互相重叠，又彼此分开。街边小贩吆喝着，不停向路人推荐自己的食物，可客人往往都是自己来的——追寻香味，耐不住食欲才来的。明明只是南方一个小镇，却能品尝到五湖四海的美食。</p><p>街边的房子鳞次栉比，但无一不亮着自己的光。放眼望去，茶馆、酒馆、肉铺，繁华的光景，倒映在街边的河面上，随着河水流淌。桥上，有人挑着担子，有人推着推车，艰难地爬上古桥，同街上乘着豪华马车的贵族形成鲜明对比。贵族们今晚有要到哪放纵？只有他们自己知道。马蹄踏着石板路，声音渐行渐远。不过，夜晚终究是属于每一个小镇居民的，在这块黑色的画布上，居民们可以恣意点染，无论是在灯红酒绿中潇洒一回，还是在茶馆听听戏唠唠嗑。酒的甘醇与茶的干涩纵然不同，但人们仍在共享着这个繁华的夜市。</p><p>说到茶，就不得不提到小镇特产的清耀茶了。小镇地处沿海，年降雨量充沛，温度适宜，太阳辐射弱，使得甘醇的清耀茶成为该小镇的响亮名牌。这也是小镇的主要经济作物。每年，有无数外地商人前来寻购茶叶，甚至有的外国商人不惜远洋东渡。有了家喻户晓的名茶，当地自然少不了茶馆了。小镇的茶馆遍地丛生，在这里，一群人，一壶茶，一叠花生，便是一日中的唠嗑，再加上严冬之日，白天大家又不愿意上街，所以现在的茶馆人满人寰。不过大家也都不害羞，桌上，无论是邻居，还是没打过照面的人，都能说上一天。要说最累的只能是茶馆的招待员了，不是这里茶喝光了，就是那里花生吃完了，在吆喝声中四处跑动，忙的不亦乐乎。</p><p>而能在这小镇上与茶馆相提并论，还得是青楼。</p><p>青楼，不仅是男人寻欢的场所，更是文人诗兴大发的宝地。</p><p>小镇的青楼只在夜晚开放。与装饰古朴的茶馆不同，青楼的气派豪华绝对是小镇夜景的一道风景线。夜晚，纵使月光如何皎洁明亮，小镇人们眼里，满是青楼的五光十色。男人们在酒馆小酌一口，便趁着酒意来到青楼。指定好自己中意的姑娘，她便会带你到她的闺房。当然，有的姑娘人气太旺，就只好排队了。忍不住寂寞咋办？那就只能加价。有的人为了今夜能见上自己心怡的姑娘一眼，不惜花重金。正因为有这样的男人在，小镇的青楼才能如此熠熠生辉。在遍地的青楼中脱颖而出的，便是妇孺皆知的月荣阁。</p><p>月荣阁的特别之处，在于它的地理位置。不同其他的青楼，月荣阁并不在热闹的小镇中心，而是在小镇的边缘地带，四周都是一些杂铺店，唯独有家隔街对望的茶馆与它共同肩负起了这篇区域的热闹。月荣阁的装修也并不算华丽，昏暗的门前吊着几排灯笼，风一吹便发出吱呀吱呀的响声，波浪似的翻滚着。门内到是宽敞明亮，木质地板上铺着毯子，让人在冬天走过时脚底一整暖意。一楼空间不大，几只蜡烛便把门内照得通亮。而二楼便主要是姑娘们招待客人的地方。二楼有很多房间，每个姑娘都有一间自己专属的房间，用来招待客人。房门配有锁，只能从屋内上锁，而锁的钥匙都是由房间的主人保管。最大的房间是属于“花魁”，装饰比一般房间要精致许多，木制的床装饰着雕花，房间内有两扇窗户，一扇面向正门，可以看到对面的茶馆，另一扇面向着青楼的后门，房内弥漫着淡淡的芳香。由于是冬天，每个房间都在方炉里生了火。</p><p>经常来到顾客都知道，一楼有一位老婆婆住着，貌似青楼好像是她家的祖上的遗产，后来因为儿子在外不争气，欠了人家很多钱，最后把这间房子拿去抵债，后来别人便将其修建成月荣阁。人们出于好心，便让这位老人住在月荣阁一楼小房间了，平时客人也会来找老婆婆问事，自然老婆婆也对月荣阁的姑娘和客人们非常熟悉。说到这，好像还并没有解释为什么月荣阁能够在小镇的青楼中独具一档。</p><p>如果一个人可以代表一座青楼的话，那必然是花魁。</p><p>月荣阁的花魁是小镇里最美丽的姑娘，没有一个男人不为她的美貌所折服。她的花名叫做美玖。对男人来说，就如同她的花名一般，她就像一瓶令人垂涎欲滴的美酒。自从人们知道月荣阁有一名倾国倾城的姑娘后，每天都会有无数男人前来寻欢，甚至也有女人来一睹芳容，想看看所谓小镇的绝世美颜到底是否名副其实。就这样，一传十十传百，整个小镇都知道了美玖和月荣阁的存在，最后传到京城官员到底耳朵里，官员们从京城南下，只为与美玖相见一面，事后便心满意足地回城。月荣阁也成为名震四方的第一楼。</p><p>追求者众多，自然也就不能满足每一个人。能够指名美玖的都不是一般的平民百姓，通常都是达官贵族，或是当地有威严的帮派首领。</p><p>小镇里的帮派活动也十分凶残，经常有帮派相约在某地决斗，刀光剑影间，便是血流成河。居民们很熟悉各个帮派的成员，有时走在街上遇见他们往往会避而远之，不敢招惹，生怕他们记住你的脸。</p><p>小镇里，有两股帮派势力最为猖獗，分别是玉龙帮与罡风帮。</p><p>玉龙帮的首领若森原本是隔壁镇上威名远扬的龙首帮首领的儿子，后因龙首帮内部分裂，加上外部势力的干扰，首领惨死于自己部下的手中，幸运的是若森逃到了一户农民的家里，后随他们来到了这个小镇上，才免遭一死。因为父亲的死，若森从小便痛恨背叛，他在小镇上集结朋友成立了玉龙帮，并对内部成员进行多次调整，有任何不忠之心的成员都被残忍杀害，玉龙帮延续龙首帮的做法，将所有死于自己手上的人的首级全部收集起来，这是若森在向他的父亲致敬，若森始终希望这众多首级之中能出现当年背叛龙首帮的人的头颅。</p><p>而罡风帮的首领是夏月，本是小镇当地的一个书生，因为天资聪颖，从小便被人们看好，都认为他以后一定能金榜题名，顺利前往京城当官。谁知后来因在京城做官的叔叔贪污，被中央下令灭门，而夏月当时正好远渡东瀛求学，才逃过一劫。回国之后，得知家里的人全被政府所杀害，夏月果断决定弃文从武，决心要打到政府，建立自己的政权，于是便在当地建立了罡风帮，多次向百姓宣传推翻政府的思想，并通过一系列武力斗争稳固了自己在小镇的地位。</p><p>罡风帮与玉龙帮整体处于相互斗争中，但却不发生大规模的战斗。同时，夏月与若森也是熟人，两人同病相怜，却又互不相让，无论是在势力上，还是在女人上。</p><p>没错，夏月和若森都在追求美玖。尽管美玖的追求者遍布九州，但无疑夏月与若森两人的竞争力最大。</p><p>记得不久前小镇上有传言，说若森与夏月要通过男人的决斗来赢得对美玖的追求权，输的一方必须放弃。期间一直有传闻说是若森赢了，但也有人说是夏月赢了，真相一直在人云亦云中扑朔迷离，人们也不敢直接去询问罡风帮或玉龙帮的成员。</p><p>所谓男人的决斗，无非就是打架，比剑之类的。一方认输后，另一方自然就是赢家。</p><p>在他们对决期间，美玖作为店里的头牌，依然在月荣阁招待着客人。无数达官贵族前来献殷勤，但都被美玖一一回绝。人们不免怀疑美玖已有心上人了，是否是在夏月和若森之中呢？每当有人问起，美玖只是浅浅一笑，微微低下头为客人倒酒，仿佛酒中就是她的全部回答，人们也便不再多问。</p><p>我虽然生活在这个小镇上，却从未与美玖见过一面，也从未想过与她相见，在这个将仰慕美玖当做思想标杆的小镇，我全然像个异邦人。不过偶尔在茶馆闲聊时，也能从别人的只言片语中勾勒出她的模样。据说，她祖上也是一个开茶馆的。</p><p>本以为我与她永远不会有联系，直到那个夜晚。</p><p>不知何时，雨突然下了起来，冲刷的小镇的傍晚。我坐在月荣阁对面的茶馆里，看着房檐上的雨滴缓缓落下，在馆外的石板路上溅起一圈涟漪。雨下得十分凶猛，丝毫没有喘息的意思。寒冬，黑夜来的比以往要早，傍晚六点时分，门外已是伸手不见五指。</p><p>随着雨势缓缓减弱，街上逐渐热闹了起来。一排排灯笼亮起，行人在街上信步游走。茶馆的人也多了起来，除了我旁边那桌老人是从早坐到现在的，其余几桌客人都换了一批又一批。</p><p>“老板，花生米又没咯！”那位披着军大衣的老人叼着牙签吆喝着。</p><p>“诶来了来了！”</p><p>“老板，大方点嘛，大伙儿都天天在这儿唠嗑呢。”</p><p>“哎呀，你们都在这儿喝了十几年了，我的小儿子都记住你们啦，来，阿刁，过来和姥爷们打声招呼。”</p><p>老板向坐在角落那桌的小孩挥了挥手，那是老板儿子阿刁，今年刚上小学。他手里攥着笔，眼神很认真，似乎在写着什么东西。</p><p>老板已过天命之年，传闻他家还有一个女儿，已经远嫁他乡，如今他和妻子经营着这家茶馆。在茶馆遍地的小镇，像他们这种装修简陋，地址偏僻的小店，实在没啥竞争力。唯一拿得出手的，就是传了几代的泡茶功夫。虽说清耀茶有其独特的沏茶方法，但这家茶馆的清耀茶却比别的茶馆的更加甘醇，茶香不仅悬于鼻腔，更是流于齿间。</p><p>自从几年前与朋友在此处饮过一会后，我便认定，没有其他任何茶馆对清耀茶的理解胜过这座茶馆了。此后几年，我习惯性地来这座茶馆，工作也好，休息也罢，看看书看看报，有时和隔壁的姥爷们唠唠嗑，甚至辅导老板的儿子做功课。平凡的日子的惬意如同清耀茶的余香萦绕心头。</p><p>看着阿刁在为眼前的功课烦恼时，我便懂事地走到他桌旁。</p><p>“阿刁，又有不会的题目啦？”我悄悄在他旁边坐下。</p><p>“碧雨叔，您可算来了。”果然，看到他对我的来访并不感到惊讶时，我就知道他已经在期待我的到来了。</p><p>“阿刁呀，小学生了，也要学会独立思考了哦。”</p><p>“可是……我就是看不懂呀。”</p><p>“哎，这不就是简单的加法嘛，你在仔细读读题，来，我帮你把关键的信息画出来。”</p><p>接过他的笔，我便在他的册子上画了几条横线。这样的互动我和阿刁已经再熟悉不过了，阿刁也想着只要把笔交给我，再难的题都不过只是白纸黑字。</p><p>“小雨，又在教阿刁学习呀。这个家伙，书怎么都念不进去。多谢了你哈。”老板娘从我身边经过，手上端着一叠花生米。</p><p>“哪里，我也是闲着。”</p><p>“哦？在等人吗？”</p><p>老板娘一眼就看穿我的心思。</p><p>“是啊，那家伙每次都要我等那么久。”我无奈地抱怨道。</p><p>窗外，雨后的天空也没想象中皎洁。月光将云层冲刷得浓淡不一，街对面的月荣阁依旧庄严地站立着，只是客人较往常稀少了许多。看来月荣阁已经只限于有权人士娱乐了，闲人甚至不能在门前停驻。</p><p>地上的积水映着来往的行人，行人踏着积水走走停停。</p><p>我回到的桌前。桌上的茶水马上见底，不得不叫老板再加一壶茶水了。</p><p>正当我准备朝老板挥手时，门帘处突然出现了个熟悉的身影。</p><p>“没让你久等吧，白碧雨你也是，每次都来这么早……看看你，茶都喝完了，老板再来壶茶。”</p><p>有点逆光，我看不清她的脸。但这声音准没错，就是萧绫女。</p><p>“绫女，是你每次都来太晚了吧……”</p><p>老板又端上一壶慢慢的热茶，香味沁人心脾。</p><p>萧绫女若无其事地在我对面坐下，圆框眼镜后的双目充满着无辜。</p><p>“绫女，你刚刚去哪了？”</p><p>“啊？你说啥呢，我从家里走过来的呀。刚下过雨嘛，我不敢走太快，所以就……”</p><p>“绫女呀，虽然你挺聪明的，但你还真不擅长说谎。”我嘲讽道。</p><p>萧绫女仿佛被我说穿心事一般，眼神开始闪躲……</p><p>“……怎么发现的。”</p><p>“你的眼镜啊。外面天那么冷，如果你是赶路进来的，眼镜上一定会起一层雾才对。而且，我是看着你从门帘进来的，你根本没有机会擦拭眼镜。”</p><p>“……”</p><p>“老实交代吧，你到哪去了？”</p><p>萧绫女已经完全放弃狡辩。</p><p>“好吧……还是你看得仔细。其实我刚刚在对面的月荣阁。”</p><p>“月荣阁？”我还是第一次从萧绫女口中听到这个和她身份完全不沾边的名词，“你去那干嘛？”</p><p>“那个老婆婆，就是住在一楼的那个，好像生病了，我买了点草药送过去。”</p><p>看来她还是个乖孩子啊。</p><p>“顺便……”</p><p>“顺便？”</p><p>“顺便想看看美玖小姐的样子。我早就久仰大名了，真想看看所谓的仙子长啥样。”</p><p>“今天人不多吗？”我想起了方才从茶馆望向月荣阁的情形。</p><p>“嗯。听婆婆讲，美玖说今天要接见几位大客人，就没安排其它姑娘了。除了客人们外，月荣阁就只剩婆婆和美玖小姐了。”</p><p>“所以你见到了吗？”</p><p>“哎好可惜，今天本来是最好的机会了，谁知我到那边时，美玖小姐已经带客人进房间了。”</p><p>“那你去房间找她呀。”我明知故问。</p><p>“这咋可以。而且按道理房间门应该是锁了的，钥匙都由她们自己保管。”</p><p>“看来你很熟悉的嘛。”</p><p>“那是，我和婆婆比较熟。好不容易从婆婆口中知道今天这个好机会，谁知……”</p><p>萧绫女拿起茶杯，喝了一口茶，仿佛刚刚的长篇大论已让她唇焦口燥。</p><p>寒气透过开敞开的窗侵入屋内，我逆着风的方向望向馆外，冷风迎面袭来。从风的缝隙中，我看到月荣阁，没有往日的熙熙攘攘，几只灯笼摇曳着。</p><p>“话说，你有听说美玖小姐要嫁人了吗？”萧绫女打断我的思绪。</p><p>“嫁人？”</p><p>“对，嫁人，就是要结婚了。据说是她家长辈的要求，说是希望她早日结婚，找个可靠的男子，以后就不再去青楼了。”</p><p>“这……”当然，一向对青楼与美玖漠不关心的我自然没啥惊讶。</p><p>“不过大家也不知道她结婚后会不会搬出小镇，也有人说她的父母长辈们都在外地，希望她结婚后能和她丈夫一起去那边。这样也好，结束了自己的青楼生涯，离开小镇，重新生活。真潇洒呀……”</p><p>“不是说那个帮派的首领要争夺美玖小姐吗？”我想起了罡风帮与玉龙帮首领的传闻。</p><p>“那个呀……谁知道呢，哎呀，我不是说我也是听说嘛。”</p><p>如果美玖要嫁给两个帮派首领的其中一人，离开小镇，那么势必有一方会放弃其在小镇的权利地位。这么说来，地位与女人，二者不可兼得啊。不知道美玖如何决定。</p><p>为了一个人，放弃一座镇，这个人究竟有多么重要？美玖，究竟又是怎样一个女人。</p><p>从和别人的对话中我听说，美玖自二十岁左右刚入青楼时就以是众星逐月的人物了，而到如今月荣阁已成名楼也已过了十年之久，期间美玖也遇见无数男人，无论是书生官员，还是权贵名流。我想能让美玖动心的，也一定是个好男人。</p><p>不知为何，明明与她未见一面，却自顾自地关心起她的未来了。</p><p>这时，茶馆的老板走了过来。似乎对我们的话题很感兴趣。</p><p>“你们在讨论美玖呀。”他笑着问道，两颗眼睛眯成一条线。</p><p>“是呀是呀。老板也听说了吗？”萧绫女热情地回答道。</p><p>“那当然，大伙不都在传嘛。据说呀，那两个人谁也不愿放弃呢。”</p><p>“那两个人？你是说，夏月大人和若森大人？”</p><p>“对呀，就是他两，他两不是争得不可开交吗？为了美玖。”</p><p>“谁知道呢，不过老板你觉得会是谁？美玖小姐最后选择的。”</p><p>“我觉得啊……还是夏月吧。”</p><p>夏月？为什么老板回这样认为？</p><p>“老板为什么会觉得是夏月君呢？”我问道。</p><p>“因为……夏月他虽然是帮派的首领，看起来是个只会用武力的家伙，实际上脑子很好使，以前是个书生嘛。美玖应该会喜欢那种吧哈哈哈。”老板乐呵呵地笑着，右手挠了挠后脑勺，害羞地走了。</p><p>窗外，黑夜似乎要将小镇吞没，街上零零星星地撒着几粒光。街对面的月荣阁，依旧是门前冷落鞍马稀。二楼有间房亮着灯光，窗户紧闭着，透过纱窗，可以看见几个人影。那就是美玖小姐接待客人的房间吧。</p><p>“黑夜呀，不要将我变成诗人。”萧绫女望着窗外，摇晃着茶杯里的茶水。</p><p>“绫女，你喝茶也不至于喝醉吧。”她又开始胡言乱语了。</p><p>“什么胡言乱语，我是说，这是个充满诗意的黑夜，我内心又充满无限的愁绪。”</p><p>“你能有啥愁绪呀？”</p><p>“当然是没能见到美玖小姐啦，这次见不到下次机会又不知道是何时，你看，明明今天很少……诶，快看！那边，好像有人……滚下来了！”</p><p>萧绫女指着月荣阁的方向。</p><p>我赶紧往月荣阁看去，视线穿过大门，看到一位娇小的女子躺在楼梯底部。</p><p>这么说的话……那个人是……</p><p>“绫女，你确定那个人是滚下来的吗？”我有点不知所措。</p><p>“是的，你刚刚没听到响声吗？物体滚落的声音。”</p><p>印象中确实有几声闷响。</p><p>“快，绫女！我们快过去，一定是发生什么事了！”情况紧急，来不及和老板道别，我将几两银子放在桌子上便匆忙离去。</p><p>我们飞速下楼，出了茶馆。茶馆旁边是间马棚，散发出一阵潮湿味，老马在里面耐心地嚼着草。我们踏着地面上的积水，来到月荣阁门前。</p><p>这是我第一次站在月荣阁门前。</p><p>月荣阁比我想象中的要小的许多。比起华丽，用庄严形容更加合适。门口的门帘被拉起，以至于我们在茶馆二楼的窗前便能透过门看清月荣阁一楼的部分。走进门后，出现的便是那位女子。那位我们在茶馆目睹的滚落的女子。</p><p>那位人们口中的美若天仙的女子。</p><p>美玖小姐……吗？</p><p>不，按照绫女的说法，今晚月荣阁只剩美玖和老婆婆，来的客人也应该都是男人。毫无疑问，面前横躺于楼梯底的是美玖。</p><p>我未曾想过与她相见。但这丝毫不影响我见到她时的震惊。</p><p>纤细的手指如同白玉一般搭在胸口，微弯的细眉下双目紧闭。她身穿白绿色的汉服，仰面躺在我的面前，后脑勺紧贴着地板，想必刚刚遭受了重重的撞击。烛光下，雪白的皮肤，像是雕刻家在大雪中勾勒出的仙女一般。</p><p>见我愣在原地，萧绫女摇了摇我的手。</p><p>“你愣着干嘛，快呀！快检查下美玖小姐的伤势啊！”</p><p>我这才反应过来，眼前的女子是刚刚从二楼楼梯滚落下来的。</p><p>突然，我听到二楼的房间不断传来响声。</p><p>二楼，还有人吗？是他们把……</p><p>“白碧雨你又怎么了？”</p><p>不行，还是先照顾美玖小姐吧。</p><p>我摸了摸她的脉搏。虽然不是第一次抓起女士的手，但唯独这次我却异常紧张。她的体温透过我的指尖传递给我，脉搏在跳动。还好，美玖小姐只是晕了过去。</p><p>我缓缓托起美玖小姐的头，想检查她头部的伤势。这时，我发现，比起她后脑勺的伤，她头部侧面的一处伤势更加严重。像是被什么重物敲打过，伤口不断渗着血。</p><p>“快，快去叫人来帮忙！”</p><p>“叫人……叫医生吗？可是这离医院有点远……”</p><p>“那就叫老婆婆过来，老婆婆呢？”</p><p>“啊，在一楼那个房间，我去问问。”萧绫女小跑走向内部左侧的那个房间，看起来她对那个房间十分熟悉。</p><p>咚咚咚……</p><p>“婆婆，你在吗？”</p><p>咚咚咚……</p><p>“婆婆，那我进来啦。”</p><p>萧绫女悄悄地转动把手，轻轻的打开一条门缝，蹑手蹑脚的走进去了。</p><p>我在门外了许久，隔着门，也不知道屋内在进行着怎样的谈话。</p><p>不一会，只见萧绫女从门缝中探出头来。</p><p>“可以了，你也进来吧，把美玖小姐也抱进来。”</p><p>老婆婆生病了，腿脚不方便，所以让我和美玖小姐去她的房间。</p><p>等等，把美玖小姐‘抱’进来。</p><p>我如同大腿灌了铅一般寸步难行。刚刚抚摸美玖小姐的手时都已如此紧张，更何况现在要抱起她。</p><p>“快啊，愣着干什么？一直开着门，冷气都进婆婆房间啦。快！”</p><p>不管了。我如履薄冰地用左手托起美玖小姐的腿，右手小心翼翼地托着她的头。抱起来时，裙子自然的下垂，花白的大腿一览无余。我正视着前方，一点一点的向老婆婆的房间挪动。</p><p>好不容易走到门口。屋内的暖气扑面而来。我缓缓打开房门，侧着身子钻了进去。美玖小姐的身体隔着衣服贴着我，我却能感受到她炽热的体温。</p><p>我慢慢地将美玖小姐放在屋内的地毯上，头部侧面的伤口还流着血。</p><p>“美玖……又是怎么了……”</p><p>一阵微弱的声音传进我耳朵，不，更像是使出混声力气从喉咙里挤出几口气来。</p><p>循声望去，萧绫女坐在床上，扶着旁边的那个老人。那位就是老婆婆吧。</p><p>“老婆婆……”</p><p>“孩子，美玖怎么了？”老婆婆又问道。</p><p>“啊，美玖小姐啊，美玖小姐她好像从二楼沿着楼梯滚了下来。我和绫女在茶馆那边发现了，这才赶了过来。”我急忙回应到，生怕老婆婆再多说一个字。“这样啊……”</p><p>只是，奇怪的是，美玖小姐的后脑勺的伤不是很严重，反倒是头部侧面的伤口，被重物击打的伤口。难道说，美玖在二楼被什么人袭击了，然后滚了下来？</p><p>袭击的目的是什么？是要杀了她吗？</p><p>疑惑与不安蔓延全身。</p><p>“那个，婆婆，你知道些什么吗？关于美玖小姐的。”</p><p>我开门见山地问了。</p><p>“喂，碧雨，”萧绫女插嘴道，“婆婆已经生病了，不要再让她说话了。”</p><p>“……没事，孩子，你是想听美玖的故事吧，我也老了，记得不是很清了……”</p><p>二楼房间里不断传来响声，像是有人在走动，找东西似的。美玖招待的客人还在里面做什么呢？屋外，细雨淋过的小街显得异常静谧，地上坑坑洼洼的水，在街灯的照耀下，使得小镇的街道看起来满是晶莹的补丁。月荣阁背后是一片泥地，新翻的泥土的气息弥漫在街道上。</p><p>婆婆说，月荣阁里的姑娘们被欺负已经是常事了，美玖也无法逃脱。为了不与官员权威作对，她劝我最好不要上楼找人理论。这也是美玖小姐对老婆婆的交代。</p><p>老婆婆眼含泪光，叙述起美玖小姐的故事。</p><p>老婆婆虽然在这住了快半辈子，但与美玖小姐相遇，还是在十年之前。那时的月荣阁还只是一座名不见经传的小楼。</p><p>那天，也是个雨夜，淅淅沥沥的雨流淌在小镇上。</p><p>那是婆婆身体还算健康，起码能自己走路。婆婆像往常一样坐在月荣阁门前，听着雨声，如同指尖叩击桌面的声音一般。</p><p>婆婆坐在藤椅上，望着白茫茫的雨中，突然出现了个人影。她还以为她老花眼了，只见一个衣衫褴褛的女孩趴在地上，慢慢朝月荣阁里爬去。</p><p>婆婆见状，连忙将女孩扶了起来，可她一个老人力气不大，她又吆喝店里的小妹们出来帮忙。最后几个人合力将女孩抬进了屋内。</p><p>众人给女孩擦干净了水，又换上了干净的衣服。</p><p>这时众人才回归神来，眼前的这个女孩，竟是如此美丽。吹弹可破的脸蛋，雪白的肌肤，虽然眼睛紧闭着，但这种神秘感让在场的所有女人都无语凝噎。</p><p>人们从未见过如此惊艳的容貌。</p><p>“……阿婆。”一个姑娘支支吾吾，她原本就是月荣阁的人。</p><p>“别说，我也知道。”</p><p>“阿婆！一定要把她留在月荣阁呀！”</p><p>“……这我知道……”婆婆有些犹豫。</p><p>“阿婆！这是位能改变我们月荣阁命运的仙女呀！”</p><p>“……可是，那几位大人怎么说？”婆婆口中的大人，就是她儿子的债主，也是月荣阁的创始人。</p><p>“哎呀，别管大人们了，要是能把她给留住，他们乐还来不及呢!”</p><p>“先别说了，去，去那块热毛巾来，别让她着凉了！”</p><p>听到命令后，一个姑娘立马奔去浴室。姑娘们都很听老婆婆的话。</p><p>“还有，谁去打碗姜汤过来，在厨房，我刚烧好的，本来打算留给晚上的客人喝。”</p><p>婆婆接过毛巾，先在那个女孩的身体上轻轻地擦拭，碧玉般的肌肤，让人不忍心用力。之后又将毛巾敷在了她的额头上。</p><p>之后，屋内的众人都在耐心地等待，等待女孩的苏醒。</p><p>“诶，你说，如果这个女孩留下，她一定是咱月荣阁的花魁吧！”床边的一个姑娘小声地说道。</p><p>“那还用说！别说咱们楼的花魁了，说是整个小镇的花魁也不为过！”另一个姑娘附和道，语气里带着些许骄傲。</p><p>“到时，咱们月荣阁一定会热闹起来吧。这身材容貌，让官人们从京城南下都不是说梦。”</p><p>床上的女孩双眼紧闭，鲜红饱满的嘴唇微微张开，均匀的喘息声让在场的所有人都屏住呼吸。</p><p>“你们几个姑娘啊，以后可要好好照顾她哦。我是说，如果她愿意留下来的话。”婆婆</p><p>露出了慈祥的笑容。</p><p>“这么说，婆婆愿意收留她了喽！”</p><p>“那也得看人家愿不愿意呀。”</p><p>床边的几个姑娘乐开了花，像是又多了个小妹妹一样。</p><p>突然，床上传来嘀咕声。</p><p>“我们家……真的什么都没了……”</p><p>女孩有意识了。</p><p>众人赶紧围在了床边，想听清她在说什么。</p><p>女孩慢慢张开了眼，水灵灵的大眼睛注视着床边的陌生人们。</p><p>“这里是……”</p><p>她迷茫地问向众人。</p><p>“这里是月荣阁，小妹，刚刚是婆婆发现你躺在门口，外面下着雨，所以就把你抱进来了。”</p><p>“……”</p><p>“小妹，你叫啥名呀？”婆婆问道。</p><p>“美……美玖，爸妈都叫我美玖。”</p><p>“美玖啊，好名字啊，大家都很喜欢美酒呢。”</p><p>“……”</p><p>“话说美玖妹妹，你是怎么到这里来的。月荣阁的地理位置算是偏僻的了。”床脚那边的姑娘问道。</p><p>美玖没有回答。还是说不愿意回答。</p><p>“那……你的父母呢？”</p><p>“父母……不知道了。”美玖对她的家事缄口不提。</p><p>众人也一时语塞。</p><p>“那……美玖，你想不想留在月荣阁？”婆婆开口问道。</p><p>“这样的话……那就拜托了。”没想到美玖竟无一丝犹豫。</p><p>“太好了！”屋内的姑娘们又欢庆起来。</p><p>“这下，咱们月荣阁前途明朗啦！”</p><p>“……”</p><p>“来，美玖，先把这碗姜汤喝了。”婆婆端着碗，美玖接过，捧在手心，像是许久未见这种温暖。</p><p>从此，美玖每天便在月荣阁里居住，婆婆照顾着她的生活。</p><p>由于小镇的学位已经满了，美玖每天都只能去隔壁小镇上的学校念书。从月荣阁出发，每天要走许久山路，大概早上四五点中婆婆就喊美玖起床了。那时的月荣阁还很平庸，也没钱让这位日后名满天下的花魁坐马车上学。那时的日子确实很辛苦，对婆婆和美玖都是如此。</p><p>等到美玖十五岁成年后，便安排她和其他几位姑娘一起工作。</p><p>期初，美玖还是一个害羞的姑娘，等到她熟悉这份工作后，她便轻松地当上月荣阁的花魁。客人都对她大加赞赏。月荣阁也越来越兴旺。</p><p>这几年来，婆婆都常常坐在门前，看着客人与姑娘们来往，直到最近才因为身体恶化离不了床。</p><p>婆婆和我们讲，之前有个男人经常性地来找美玖小姐，说是想把美玖小姐带回家。当然婆婆肯定是不同意的，但这也得问美玖的意思。</p><p>后来婆婆才知道，那个男人其实就是玉龙帮的首领若森。</p><p>听着婆婆将完美玖小姐的故事，我仿佛经历了一遍她的人生。充满谜团的人生。</p><p>为什么美玖小姐会出现在月荣阁门前？为什么她又同意留在月荣阁？她又为什么对家事缄口不提？</p><p>“婆婆，你还记得那天，就是发现美玖小姐倒在月荣阁门前那天，小镇上发生了什么吗？”我问道。</p><p>“那天的话……你这么一说，好像是有家茶馆起火了。”</p><p>起火？怪不得有股烟味……</p><p>等等，有烟味！</p><p>面前的萧绫女仿佛也察觉到异样，猛地吸了几下鼻子。</p><p>“碧雨，怎么有股烟味？”萧绫女张皇失措的问道。</p><p>着火了吗？</p><p>我环顾四周，又起身走向屋外。</p><p>“是二楼，快！美玖的那间房间！”我朝屋内大喊道。</p><p>紧接着，我冲上二楼。地板和台阶是木质的，走起来有些踉跄。冲到二楼，眼前是一扇庄严的木门。我拧了拧门锁，但是门锁得死死的，用力撞了几下后依然一动不动。凭我一己之力根本无法撞开这个门。</p><p>“绫女！快问问婆婆钥匙在哪？”</p><p>“婆婆说钥匙都是由美玖小姐自己保管的。”</p><p>没办法了，只能多叫些人来帮忙了。</p><p>“绫女，你和婆婆还有美玖小姐在房间里好好待着，关好房间门，别让火蔓延进来，我马上回来！”</p><p>我立马飞奔向茶馆，老板娘矮小的身影率先出现在我眼前。</p><p>“快……不好了！”我气喘吁吁。</p><p>“啥事呀这么慌张。”老板娘感到诧异。</p><p>“月荣阁……着火了……美玖小姐的房间。”</p><p>“什么？”</p><p>紧接着，我和老板娘一起呼喊茶馆里的人出来帮忙，大家听到后都仗义地冲出来帮忙。我实在跑不动了，跟在这一窝蜂后面。</p><p>看着眼前的帮手们都冲进了月荣阁，我加快脚步跟上。来到一楼，我先找到婆婆她们，打开房门，绫女正扶着婆婆坐着，而床上躺着美玖小姐，一动不动，虽然没有亲眼见过，但这场景一定与十年前一模一样。</p><p>一模一样的不只是昏迷的美玖小姐，还有火灾。</p><p>我紧接着上了二楼。二楼美玖小姐房间的已经打开，我检查了房门，发现完好无损。</p><p>难道，不是撞开的吗？</p><p>大家都挤在门口，不知所措地望着房间里的场景。</p><p>虽然房间里的火已经扑灭，但房间里有更令人害怕的东西。</p><p>房间里有两具尸体，两具男人的尸体。</p><p>突然有一个人抓住了我的肩膀，我感觉到了剧烈的摇晃。</p><p>“美玖！美玖呢？”那个人激动地质问着我。</p><p>我甩开他的手，定了神，才看清眼前的人——茶馆老板。</p><p>“……美玖小姐在一楼，早在我们发现火灾时就昏了过去，现在她……”</p><p>还没等我话说完，老板就冲下一楼了。</p><p>“喂，别太打扰她们了。”</p><p>为什么老板反应这么大，难不成，他是美玖小姐的狂热崇拜者吗？</p><p>回到眼前的凶案现场。我督促旁边的人赶紧报警，他们说刚刚已经报过了。</p><p>“警察说一会就到，让咱别破坏现场。”门口一个小胖子说道。他也是茶馆的老顾客了。</p><p>“对了，房门是怎么打开的，看起来不像是被撞开的。”我向他们问道。</p><p>“其实，我们来到这时，就已经发现老板进房间里了。”</p><p>“啊？”为什么，老板会这么快。</p><p>“他同咱们说，他在一楼找到了钥匙，就把门打开了。”</p><p>钥匙？钥匙不是由姑娘们自己保管的吗？</p><p>望向美玖小姐的房间。两具尸体，一具背靠墙坐着，腹部侧面插着把刀，另一具则跪趴着，脸埋进刚刚扑灭的火坑，身上有烧焦的痕迹，想必那就是火蔓延出火坑的途径。</p><p>我边从兜里拿出手套，边走进房间。</p><p>“喂，小伙子，警察说不要进案发现场。”门口的中年人对我警告道。</p><p>“我是侦探。”我亮出自己的身份。从前都是警方邀请我同他们一起调查案发现场，这次难得的比他们早到。</p><p>我首先检查了那具将头埋进火坑的尸体。尸体的面部已经被烧焦到不可辨别，仔细一看脸上还有刀割伤的痕迹，使得面部更加无法辨认了。掀起部分烧焦的衣服，腹部有一处刀伤，伤口上还有血迹。尸体跪在一片血泊中，看起来是死于失血过多。</p><p>紧接着我又走到面向茶馆的窗户。窗户紧锁着，我尝试打开，但其丝毫不动。第二具尸体就坐在这里，靠着墙。尸体的面部完整可辨，胸口处的衣服染成一片血红。我拨开他的衣服，发现他左胸处有一处刀伤。而刀现在正插在他的腹部侧面，看样子是被凶手连刺两刀。地上也是一滩血迹。</p><p>另外一扇面向后院的窗户打开着，下面是块泥地，由于刚下过雨，地上看起来光滑干净，没有脚印。</p><p>我环顾四周，试图找些东西。这时门口突然传来一阵骚动。</p><p>“哟，这不碧雨兄吗？又遇见你了。”以为警察走了进来。</p><p>他是小镇的警长，姓谢，也是我的发小。</p><p>“谢警长，这次我可是比你先到的。”我夸耀道。</p><p>“行行行，如果你能把案子解决了怎么说都行。听说这次死了两个大家伙。”</p><p>大家伙？</p><p>见我面露疑色，他问：“你不知道吗，刚刚有人报警说月荣阁死了两个人，分别是若森和夏月。喂，是谁报的警？站出来！”他朝门口的人群喊了一句。一个小个子走了出来。</p><p>“说，这两个人是不是罡风帮和玉龙帮的头儿？”谢警长命令道。</p><p>“是！这绝对错不了！我向您保证！窗边儿那个死人的脸就夏月的，而火坑的那个死人，虽然脸都看不清了，但这衣服还看得清，这翠绿色的花纹，错不了，就是若森的，是的！听说这是若森派人特意从京城那边做好送过来的，小镇上绝无第二条！我家里还有老婆孩子，我绝对不敢骗谢大人！”小个子畏畏缩缩，尽管双目坚定，但嘴唇却不自主地颤抖着。</p><p>“行了行了，知道就好。怎么样碧雨兄，没错吧！”</p><p>竟然死的是若森和夏月……</p><p>我想起了他们争夺美玖小姐的事……</p><p>对了！美玖小姐！</p><p>“谢警长，二楼先交给你，我一会上来！”我突然记起刚刚茶馆老板冲下去找美玖小姐的事。</p><p>我紧忙推开婆婆房间的门。一进门，就看见地上躺着个男人。</p><p>“茶馆老板……他怎么躺在地上？”</p><p>“是我干的，”萧绫女回答道，语气里带着些自豪，“刚刚看见有个男人冲进来，我就一招把他打倒，结果仔细一看才发现是老板啊。”</p><p>美玖小姐依旧一动不动躺在床上，婆婆坐在床边照顾着她。</p><p>“看样子……头是有点毛病了。”婆婆念道。</p><p>“婆婆，要不明天一早咱派人送美玖小姐到京城的医院去？”萧绫女提出建议。</p><p>“也只好这样了，咱小镇也没有中用的医师。”</p><p>为了不打扰到她们休息，我先把老板拖出房间。萧绫女下手真狠，老板已经不省人事了。</p><p>“碧雨兄，你那什么情况？”谢警官走下了楼梯。</p><p>“他们说是这个茶馆老板开的门。”</p><p>“哦？是他开的门？咋开的？快，把他叫起来。”</p><p>我顺便把刚刚目睹美玖小姐从二楼滚下来的事告诉了他。</p><p>旁边几个小伙子拍了拍老板的脸，见他没反应，便从厨房那舀了碗水，毫不犹豫地朝他脸上泼过去。</p><p>“美玖！”老板立马清醒，大喊了一声。</p><p>啪，谢警官一个巴掌拍在老板额头上。</p><p>“你喊啥呢？快说，是不是你开的门？”</p><p>“美玖小姐在房间里休息呢，明天一大早就送他去京城就医。”我插了一句。</p><p>“这样啊……啊，那个，是我开的门，钥匙我是在门口地板那边毯子下翻出来的。”老板冷静了下来。</p><p>“地板？毯子？你咋知道在那边的？”</p><p>“其实啊，我基本上就住在对面的茶馆里，上次偶尔瞟到，一个姑娘往地毯下塞什么东西，我就觉得是钥匙。这次我冲过来时找了一下，果不其然。”老板解释道。</p><p>“所以老板来的时候门也是锁着的？”我问道。</p><p>“是的啊……啊是你呀碧雨，又来当侦探了吗？我跟你讲，楼上死了两个人……”</p><p>“你也别废话了，碧雨兄问啥你就答啥。”谢警官命令道。</p><p>“如果是这样，那就是场密室杀人事件了。”</p><p>身后传来一声女人的声音。是萧绫女，她从婆婆房间走了出来。</p><p>“绫女，婆婆和美玖小姐那边没事吧。”</p><p>“嗯，她们在休息了。我们就别去打扰了。”</p><p>“不过你和我想的一样，这确实看起来像是密室杀人事件。”</p><p>“密室？杀人？喂碧雨兄，可别说这些稀奇的词了。”谢警官疑惑地摸了摸后脑勺。</p><p>“因为，在老板来之前门是锁着的，而房间里的两扇窗户，一扇面向茶馆的正门方向的窗户是锁死的；另一扇面向后院的窗户虽然打开，但地上的泥地却没有脚印，也就是没有犯人逃脱的痕迹。”</p><p>“原来如此。这就是密室杀人啊。没有凶手进出的痕迹。”谢警官若有所悟。</p><p>“诶，后院的窗户开着吗？我记得，一般都是关着的吧。现在大冬天的，窗户应该都是紧闭着的。”老板突然插嘴道。</p><p>“一般都是关着的吗？也就是说，凶手是从面向后院的窗户逃走的吗？但地上又没有足迹。”这依然是个密室。</p><p>我和谢警官决定上楼调查。</p><p>穿过聚集在门口的人群，好不容易挤进美玖小姐的房间。</p><p>扑面而来的烧焦味让人忍不住皱了皱了眉。谢警官走到若森的尸体那，仔细检查面部与伤口的情况。</p><p>“真狠心，凶手居然把他脸弄的那么令人反胃。要不是这衣服都认不出这是谁了。”谢警官清了清嗓子。</p><p>“凶手应该是把若森杀了后，便用刀划伤了他的脸，接着就把他的脸放到火坑里，使其烧焦成现在这个样子。”我说出了我的判断。</p><p>“那这具尸体呢？嘿，你可别说，夏月这小伙子长得还挺秀气的，没想到那么有威信的人竟是这般长相。”</p><p>“夏月的话，身上有两处刀上。一处在左胸，另一处是在腹部，也就是现在刀插着的位置。我想，致命伤应该是刀刺到了心脏。”我指着地上那一大滩血迹。</p><p>“原来如此。碧雨兄，你有什么看法吗？”</p><p>“什么看法?”</p><p>“是啊，你觉得凶手是怎么逃走的呢？”</p><p>我走到敞开向后院的那扇窗子。</p><p>“只是有一点头绪罢。”</p><p>“哦？说来听听？”谢警官投来期待的目光。</p><p>“首先，我们应该知道，凶手来到这个房间做了哪些事？”</p><p>“哪些事？不就是杀了两个人，然后不留踪迹的逃跑了吗？”</p><p>“这就是问题所在了。我是说凶手真的完整做了以上那些事吗？”</p><p>“哦!我知道了！”萧绫女不知何时走到我们跟前，眼睛里闪着光。</p><p>“凶手确实杀了人，但是，并没有逃跑。”萧绫女抛出了她的回答。</p><p>“没有逃跑？这是什么意思？”谢警官问道。</p><p>“就是啊，凶手还在这个房间里呀。在老板进入房间的时候并没有离开。”萧绫女解释道。</p><p>“没有离开？那……喂，你是当老板是瞎子吗？就算老板没看到，凶手也没机会趁乱逃出去呀，老板进来后紧接着茶馆的其他帮手也进来了。不可能在房间里呀。”</p><p>“但是啊谢警官，”她一副说教的模样，“如果老板说谎了呢？”</p><p>听到萧绫女这样回答道，我就明白她和我想一块去了。“是的，绫女应该也知道我要说什么了。凶手可能就是老板。他先……”</p><p>“诶别别别，让我来说，”萧绫女立马把我的话塞回我的嘴里，“首先，老板根本就没有出去，他杀了两个人后，把若森的脸划破，并埋入火坑。等火蔓延出火坑，烟味开始弥漫，引起了我们注意，那时碧雨不是冲到房间撞了撞门吗？他知道我们进不来一定会去对面人多的茶馆找帮手。接着，等你离开后，就打开了房门，装作自己刚刚到现场似的。”萧绫女干脆利落地说完了我想说的话。</p><p>“那这还等什么？犯人就在楼下，快，别让他跑了。”谢警官气冲冲地往楼下赶。</p><p>一楼，老板正畏畏缩缩地坐在地板上。旁边围了一群警察。</p><p>“冤枉啊！我没杀人啊！”老板的申冤想必谢警官已经听得耳朵起茧了快。</p><p>“别给我扯这些，现在立马承认，不然，待会在局子里审问有你受的。”谢警官巴不得立刻逮捕他。</p><p>老板看到我来了，像是看到曙光一般。</p><p>“碧雨啊，你看，我怎么会杀人啊！”</p><p>“老板，虽然我不想承认，但你今天确实很可疑，以及关于你进入房间的证词。”</p><p>“这没啥可疑的啊，我就是看到毯子下塞了钥匙。”老板还在顽强抵抗。</p><p>“还有，你那天的表现，为什么那么快就冲到了现场？”</p><p>“这是因为……”</p><p>“因为？”难道还有隐情？</p><p>“算了，老子不管了。我都说总行了吧！钥匙是美玖亲自给我的。”</p><p>“亲自？给你？”一旁的萧绫女惊讶地反问道。</p><p>“因为，她是我女儿嘛。”</p><p>在场的所有人都仿佛忘记了呼吸。月荣阁的大门敞开着，寒风呼啸直入，吹得人一身哆嗦。</p><p>许久，谢警官才支支吾吾地开口：“你说，美玖……小姐……是你的女儿？”</p><p>“正是如此啊警官。小的哪敢讲谎话。”</p><p>为什么美玖那天会倒在月荣阁门前？为什么老板又不忍承认美玖小姐是她女儿？老板望着门外，冰冷的石板路上仿佛冒着寒气。</p><p>起初美玖小姐本和老板住在一起，老板经营着祖上的茶馆，幸福美满的生活在小镇的繁华深处孕育。</p><p>而那天，严冬，雨夜，细雨如同针芒一般刺在房檐上。</p><p>“我们家……真的什么都没了……”这是老板的哀求，对闯入宅中的劫匪的哀求。</p><p>“要么，把你女儿留下；要么，我们就把这给烧光！”劫匪的目标不止是钱财。</p><p>老板抱着怀中的美玖，年仅十岁的美玖。而美玖的母亲早已逃离。</p><p>“那……那就烧光吧！”</p><p>“哼，你以为我们是给你条件来选的吗？我们不仅要烧光这，你的女儿也别想逃！”说罢，一个大个子劫匪便抽出了刀，指着老板的鼻子，刀的寒光令人不寒而栗。</p><p>突然，一阵黑影闪过。只听哐当一声，刀便飞到墙角边。</p><p>“你小子是谁？找死吗？”</p><p>一个年轻人前来救援，一脚将劫匪的刀踹飞。</p><p>“叔叔，你们赶紧逃，这边我来拖延。”只见眼前的年轻人又是一拳打在大个子劫匪的腹部。</p><p>老板一句话也不管多问。他抱着美玖，逃出了自己的老宅。</p><p>一路上，他不断喘着气，淋着冻得结冰的雨，始终不敢回头看。隐约中，背后似乎有炽热的火光。</p><p>老板一路奔跑，不知不觉中便跑到了小镇的边缘地带。</p><p>有家简陋的青楼。</p><p>“美玖啊，今后，你得靠你自己生活了。父亲就送你到这了。”</p><p>老板把美玖轻轻放在石板路上，雨还在凶猛地倾泻。</p><p>“我以后一定会回到你身边……哦不，那是你一定是个名满天下的花魁了吧，我有信心，我和你娘会回到你附近的，只是远远地看着你，好吗？”</p><p>大雨倾盆，冲刷石板路的响声早已掩盖住老板的告白。</p><p>“美玖，你快去吧。别念着我们了。”老板咬着牙站起身，扭头就往反方向去。纵使心如刀绞，也不再回头看一眼大雨中的女儿。脸上满是的，不知为雨还是泪。</p><p>第二天，整个小镇都知道了那座茶馆老宅着了火，现场发现了几具焦尸，已经无法辨认。</p><p>几年之后，月荣阁对面新建了一座茶馆，以其对清耀茶的独特沏法吸引了不少客人。而月荣阁也逐渐声名鹤立。</p><p>听完老板的叙述，大家又陷入沉默。</p><p>一旁的萧绫女已经在擦拭眼角的泪水了。她很容易共情。</p><p>“谢警官，我就是之前那座茶馆了主人，不信，我回去翻出祖上留的笔记来，总之，钥匙真的是女儿……美玖给的。”</p><p>现在大家都能理解老板那时的反应了。</p><p>“好吧，我相信你了。”谢警官扶起了他，“你先去那边休息吧。看来这案子还没完。”这话也是对我和萧绫女说的。</p><p>我和谢警官又陷入了迷茫。</p><p>刚刚我们的推理，是建立在房间一开始存在美玖小姐、夏月、若森、老板四个人的基础上，从而解开了密室之谜。但是现在老板证明他确实是凶案发生后进入房间的，</p><p>从而推翻了我们的推理。不过我们也可以以老板的证词进一步推理，凭老板的证词，他一开门就看见两具尸体，其中一具身上还起了火。他急忙在房间里寻找美玖小姐，结果一无所获。这也就说明了老板进入房间时里面确实只有两位死者。</p><p>但这并不意味着最初进房间的除了美玖小姐外只有夏月和若森两人。</p><p>“婆婆，很抱歉打扰了，您还记得今晚同美玖小姐进入房间的有几人吗？”我悄悄地推开门，木门发出吱呀吱呀的响声。</p><p>“这个……我不太清楚了。”</p><p>如果若森或夏月带着跟班来的呢？</p><p>“啊……”听完我的想法后，谢警官又发出惊讶与疑惑的叫声。</p><p>“如果夏月或若森有一个人带着跟班也不足为奇。”</p><p>“你是说，凶手是那个跟班吗？”</p><p>“不，我觉得，凶手应该是若森。”</p><p>面前的两个人瞪大着眼睛看着我。</p><p>“喂，碧雨，你在说什么呢？若森他不在这吗？”绫女指了指那具火坑旁的尸体。</p><p>“我没说错。犯人就是若森。我们判断尸体的依据不就是他的衣服吗——那件在小镇上独一无二的衣服。先不考虑美玖小姐，因为她在上面人还活着的时候——我们在一楼听到了动静——就已经滚了下来。如果，若森先将自己的衣服脱下，给夏月的跟班穿上，自己再穿上对方的衣服，接着把他做成无面尸，这样不就完成了伪装吗?”</p><p>四只眼睛凝视着我。</p><p>“所以，若森……杀了两人后，逃离了现场？”谢警官脸上写满了难以置信。</p><p>“是的，这也就很好的解释了为什么只有若森的脸被破坏的难以辨别。”</p><p>“但……但是，”萧彩萌开口说道，“密室之谜不是还没解决吗？既然凶手是若森，那他又是怎么逃出去的呢？”</p><p>“你说得对。”我肯定了萧绫女的反驳。</p><p>“所以，我认为现在还剩两种解答。”我仿佛宣布这场较量即将终结。</p><p>“首先，第一种解答，门根本没锁，凶手趁着我去茶馆找帮手时逃了出去。但是我又在闻到烟味时上楼拧了拧反锁的把手。也就是说，我在说谎。”</p><p>“不对不对？你在说啥呀碧雨兄。”谢警官瞪直了眼睛，仿佛听到京城被攻陷一般。</p><p>“你们肯定在想，老板不是都拿钥匙开门了吗？所以肯定是上锁了的呀。但是，老板开门只是将钥匙插进锁眼，扭动钥匙把门打开了而已。他先入为主地以为门一定是锁的，所以一进月荣阁就先在门口的地毯下翻出钥匙。”</p><p>“难道碧雨你……”萧绫女面露恐惧。</p><p>“但事实上我知道，我并不会说谎。”</p><p>两人长舒一口气，但接着又问：“还剩一种解答是什么？”</p><p>“没有凶手。”</p><p>两人再次瞪大眼看着我。</p><p>“没有凶手。”我又说了一次。</p><p>“碧雨……没有凶手是什么意思？”谢警官严肃地问着我。</p><p>“字面意思，这起案件可以收工了，没有凶手。毕竟，没有人能够逃离这密室吧。所以，没有凶手。”</p><p>我不犹豫的转过头，只留下坚定的背影。</p><p>第二天，美玖小姐被送往京城的大医院看病。医生说是脑震荡，头部还有一处擦伤。不知何时能醒过来。</p><p>我和萧绫女一同来到京城看望美玖小姐。医院的护士身着白色衣服，那种纯洁无瑕的白，让人不忍玷污。药水的味道扑鼻而来，也算不上难闻。走廊里，大家脚步都很轻，实际上也并没有多少人，有些患者被搀扶着艰难地迈出每一步。</p><p>“白碧雨，虽然我知道在医院里尽量不要讲话，但是我还是想问，你昨天的结论到底是啥？”萧绫女还在疑惑我的解答。</p><p>“字面意思。”我不痛不痒地答道。</p><p>“我其实大概懂你意思了，”萧绫女准备开始她的推理，“其实，凶手就是夏月吧，夏月杀了若森后畏罪自杀。”</p><p>她的解答似乎和我所说的“没有凶手”不沾边。</p><p>“绫女呀，”我停下脚步，“但这样夏月也是杀了人啊。我不是说没有凶手了吗？”</p><p>“难道你不认为夏月是凶手。”</p><p>“他当然不是凶手。绫女的说法我之前也考虑到了，但是有一点矛盾，如果若森是自杀，那么身上应该只有一处刀伤，也就是左胸的致命伤，可是，如今除了左胸的致命伤外，腹部侧面也有一处，而且刀还插在上面，把插在左胸的刀拔出再刺进腹部就显得不自然了。”</p><p>“还有，他又何必把若森做成无面尸呢？”在我一连串的问题下，萧绫女也渐渐放弃了自己的想法。</p><p>我们来到美玖小姐的病房前。她宛如被冰冻的女神一般，静静躺在床上，雪白的床单没有一丝褶皱。</p><p>我和萧绫女走进房间。美玖小姐依旧双目紧闭着，就像昨天晚上一样。</p><p>“绫女，”我突然郑重其事地喊了她一句，她好像有点被吓到。</p><p>“我待会跟美玖小姐讲几句话，你先不要打断我。”</p><p>“啊？可是她不是昏迷了……”</p><p>我将食指放在嘴唇上，示意她先保持安静。她微微地点了点头。</p><p>“美玖小姐，我是来自小镇上的一位侦探。虽然你听不见我们讲话，但有些事我无论如何都要传达给你。”</p><p>“昨天晚上，你和夏月、若森一起进了月荣阁，你嘱咐婆婆今晚不要再招待别的客人了。可能因为你们三有重要的事要解决。我的第一反应就是你的婚姻，之前有传闻若森和夏月要决斗，谁赢了谁就拥有对你的追求权，而那场决斗是若森赢了。那天你们三会面，就是解决这个问题，让你做出决定。”</p><p>“可是，你最后选择的是夏月。你爱夏月，因为他曾是你的救命恩人。十年前的雨夜，十年前的火灾，那个把你们一家从一无所有中解救出来的年轻人正是夏月。你后来从你父亲那得知了这消息，便决定死心塌地跟着他。”</p><p>“然而，面前的若森，才是那场决斗的胜者。你不能不嫁给若森，但愿意以身相许之人却是夏月，所以，你就决定以死来了结这纠纷。我的意思是，你决定和夏月殉情。”</p><p>“在若森的面前，你拿着刀，刺向了夏月的心脏，紧接着，你把刀拔出，准备自刎之时，若森制止了你。他用重物将你打晕，对他来说，他别无选择。你被打晕在地上，失去了意识，刀掉落在一旁。”</p><p>“以上都是你在苏醒后会有记忆的事，而接下来，便是发生在你昏迷中的故事，关于一个男人为你献上最后的爱意的故事。”</p><p>“若森把你扔下来楼，然后锁上了门。他的目的在于，让一楼的人发现你，并且明白楼上还有人活着。那时我们也确实发现了美玖小姐你从楼梯上滚落。”</p><p>“然后，若森捡起了地上的刀，准备自杀，将凶案伪装成自己杀了夏月后畏罪自杀，从而顶替了你的罪名。但是，他突然想起，自己玉龙帮的兄弟们。口口声声说不背叛的是自己，而今自杀的话，对玉龙帮来说，又何尝不是一种背叛呢？为了能让大家知道他还活着，作为玉龙帮的首领而活着，或者就算死也不能是自杀而死，他不能把案件伪装成畏罪自杀。”</p><p>“所以，若森打开了窗户，面向后院的窗户。接着，手紧握着刀，对着房间的镜子，在脸上划出一道一道刀口，纵使疼痛使他全身瘫软，他依然使出全力割着自己的脸。随后，往自己腹部捅了一刀，然后把刀插回夏森的尸体上，便用尽最后的气力，将脸埋入火坑。成功伪造出自己是无面尸的场景。”</p><p>“他明白，人们的第一想法一定认为尸体是他本人的，于是为了诱使我们做出无面尸诡计的判断，他打开了窗，造成人从窗外逃跑的假象。我们第一反应一定是有人杀了他们（若森和夏月）后逃跑了，但也有可能人们意识到这是个无面尸诡计，杀人逃走的其实是若森。这样，第一种情况，人们会认为那个莫须有的逃跑之人就是凶手，从而让美玖小姐你摆脱罪名，并把若森他自己伪装成被杀；另一种情况，人们识破这是无面尸诡计，最后是若森杀了人（夏月和跟班）逃跑了，再次摆脱了你的罪名，并且让世人知道自己还活着，即便不能再回到罡风帮，也能辩解为背负杀戮之罪而不是为了女人而背叛。”</p><p>“无论是若森设想的哪种解答，都将收束于美玖小姐你的无罪。但他不知地上是大雨冲刷后的泥地，而泥地上没有脚印。哪种解答都不能完美解决案件。”</p><p>“其实让我产生怀疑的，还是若森无面尸的情况。我把自己放在若森设计的解答中想了想，既然凶手最后打算把犯人的脸埋进火里做成无面尸的话，他为什么还要用刀割呢？他大可等着无面尸的脸烧到无法辨认再离开，而且我们是被火烧的烟味吸引来的，他也可以控制现场的火势，延长尸体发现时间。唯一的解释就是，制作无面尸的人不知道何时自己的脸才能被火烧的看不清，也就是说他马上要死了。在死之前能确认自己是无面尸的做法，就是用刀亲自将自己的脸割花，正好房间里有镜子。而火烧不过是保障罢了。”</p><p>“另外我感到疑惑的一点的就是，为什么夏月的致命伤是左胸刺穿心脏的刀伤，而腹部最后又插着刀呢？也就是说，为什么若森最后要把刀给插回去呢？我想，若森大概也是不希望夏月背上背叛的罪名吧，他不希望夏月像萧绫女刚刚所推理的那样，也被世人当做杀人后畏罪自杀的背叛者。”</p><p>“我想，如果昨天没有下雨，后院的小路上不是满布泥泞的话，事情真的会像他想象中那样，没有背叛兄弟，也没有辜负所爱之人。”</p><p>房间的窗户没关，风不请自来地把窗帘吹得膨胀，几缕迷路的阳光撒了进来。</p><p>“好了，美玖小姐，我的故事告一段落。虽然昏迷的你听不到，但我还是希望你能知道有一个人为你做的一切。当然，若森，夏月，美玖小姐，你们三人谁都没错，错的是时间罢，有人先来，自然有人落后。那么，我们就先告辞了。”</p><p>我拉着萧绫女的手，走出了房门。</p><p>在关上房门的最后一刻，透过门缝，看到美玖小姐静谧的脸上，多了几道无声的泪痕。</p>]]></content>
      
      
      <categories>
          
          <category> 推理のSonata </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 拙作 </tag>
            
            <tag> 推理 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
